<search>
    
     <entry>
        <title>谈编程语言</title>
        <url>https://xulizhao.com/blog/programming-language/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>dev</tag>
        </tags>
        <content type="html"> 今年是变化的一年，自己最大的收获就是认识到视野和选择远比努力重要。
打开视野后，感觉自己以前对于编程语言的理解还是太片面了，所以重新谈谈现在的认识。
一句话总结的话，还是那句老话：没有最好语言，只有最适合的语言。 语言只是解决问题的一个工具。
历程 回头看，之前对于编程语言还是带有太多主观感情色彩了，有点类似于Python是世界最好的编程语言。
大学学的C语言，可能是因为国内教材的毒害作用，加上天资不够，对于上机课一直兴趣不大。所以也没有深入理解这门经典编程语言的精髓，没打好基础。
刚毕业的头两年主要用Java，可是没有人带，没有好的入门书，对好的代码没有太多认识，更别提面向对象编程思想了。 正式买的第一本书是《Java编程思想》，应该说它真不适合入门，因为工作主要是维护现有的系统，自己学习的路程更多是照猫画虎，所以水平只能呵呵了。
后来换工作转到测试，要维护一个Perl写的系统，就买了经典的骆驼书来学习。不得说Perl这门语言真是太面向极客了，这种一个目标的N种实现，没有多少人受得了。
对我改变最大的当然是Python语言，当时热衷于阅读国外的技术博客，偶然看到了Mozilla的自动化测试实现，一下子开拓了视野。 记得买的第一本书是英文影印版的老鼠书《Leaning Python》，后来又买过好几本其他畅销书。
Python更接近自然语言，而且它强调一个目标只有一种实现（即所谓的Pythonic）。 所以自然爱上了这门语言，当时做自动化测试实现，性能测试实现都会优先选择Python生态，也确实取到了很好的效果。 记得当时选型Robot Framework时，国内还没有多少人在用。
凡事都有两面，因为喜欢Python而反感Java，虽然期间也维护或写了些Java的项目，但其实对Java的理解并不深入，应该说更多只是用用。
后来用Python做性能测试遇到瓶颈，因为性能本来是Python的弱项，直接用线程模型单机也就模拟3000~5000的用户量，加上用gevent这种异步库调试起来很痛苦，才有机会接触了Go.
因为自己是个Google粉，除了网络教程还买了《Go程序设计语言》用来学习，先是在一些新的小项目应用，效果很好。 后来干脆用Go重写了之前的工具，估计代码量只用了1/10，但单机模拟用户量能提升10倍。
今年下半年也开始重新学习和认识Java，虽然Spring Boot刚出来时就用过一点，但在深入学习了依赖注入、面向切面这些听起来高深的知识后，发现Java生态已早不是我印象中的Java。 比如Java8及新版本就改变很大，也有Guava、Netty等优秀的库框架支持，更不用说Spring生态提供了多少成熟的业务支撑。
做个对比，熟悉Spring后，实现同样的REST接口并不比Django、Flask等动态语言慢，而且业务需求复杂后明显Java项目可以更好的工程化。
这也告诉我们要以发展的眼光看待事物，心态要始终开放。
语言的选择 从更大的视角看，每个流行语言都有它的优缺点和适用场合。
 Java： 最丰富和成熟的生态，复杂的业务首选。 Python： 快速开发实现，新手入门、运维首选，数据科学标配。 Go： 性能第一位，基础设施工具、中间件首选。  总结 大部分的选择都有两面性/trade-off、取舍、平衡，推广到做事情，所谓舍得（有舍才有得），老子云：“福兮祸所依祸兮福所伏”，也可以解读为顺利时不盲目、不顺时要反思改进。
今年总结的另外一句话是：跳出舒适区，进入学习区，才能走进更大的舒适区。
此篇算作2019的年底总结吧。
</content>
    </entry>
    
     <entry>
        <title>DDD/领域驱动设计</title>
        <url>https://xulizhao.com/blog/ddd/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>dev</tag>
        </tags>
        <content type="html"> 之前了解到微服务、中台等实践的背后都和领域驱动设计紧密相关，上周从图书馆借了2本相关书来读，记点笔记加深理解。
领域驱动设计   核心域： 限界上下文被当作组织的关键战略举措进行开发时即为核心域。是组织的核心竞争力，需要最好的资源投入。
  A Big Ball of Mud/大泥球：指杂乱无章、错综复杂、邋遢不堪、随意拼贴的大堆代码。开发人员应时刻保持警惕，不断地通过设计和实现的优化来杜绝和延缓大泥球的形成。 演进式架构是一种有效手段，通过业务领域的划分不断地进行持续设计。
  有效设计： 是简洁而非冗余，它也需要不断地演进与优化才能趋于完美。
   “设计，让生活变得完美的艺术”是乔布斯的产品设计理念。首先意味着简洁的产品（开箱即用）、简洁的战略（产品的专注）和简洁的沟通（高效的沟通）。其次有效设计允许不完美。任何产品都始于不完美，只有通过不断试错和修正的迭代才可能逐步趋于完美。
 战略设计 在展开具体实现细节之前，需要优先完成宏观层面的战略设计。它强调的是业务战略上的重点，如何按重要性分配工作，已经如何进行最佳整合。
DDD 主要关注的是如何在明确的限界上下文中创建通用语言的模型。
先确定核心域，专注于业务复杂性（而非技术复杂性）。
限界上下文 Bounded Context.
限界上下文是语义和语境上的边界。模型是在限界上下文中实现的，需要为每个限界上下文开发不同的软件。
通用语言 Ubiquitous Language.
可以理解为团队（开发、业务专家等）的国际语言，使得所有人能收到表达的准确含义和约束条件。
核心域 应当使用一组具体场景来表达核心域，描述领域模型该如何工作，各种组件该做什么。
可以通过实例化需求技术创建验收测试。
可能使用的架构：
 端口和适配器/六边形架构 整洁架构/Clean Architecture 事件驱动架构、事件溯源 命令和查询职责分离/CQRS 响应式架构和Actor模型：每个Actor都可以看成一致性边界和一个独立的业务单元，和聚合对接。 具象状态传输/REST 面向服务的架构/SOA 微服务   CQRS: 区别于传统CRUD模式，把同一个模型的无副作用的查询操作和改变状态的修改操作（通常称为命令）分开。两部分分成不同的模块和服务实现。改变状态的命令经常会采用事件溯源来实现。 这种架构特别适合需要高性能且查询和命令的扩展性有不同需求的应用/服务。当然也会引入架构复杂性。
  Service Oriented Architecture/SOA是一个组件模型，它将应用程序分为的不同功能单元（称为服务），通过这些服务之间定义良好的接口和契约联系起来。 实际上微服务和SOA一脉相承，可被认为是SOA的一种特定的现代实现。微服务相对SOA更注重对独立业务单元的拆分来形成清晰的边界，并采用轻量级的通讯机制，以一种更加松耦合的方式进行集成， 来提供更好的扩展性和灵活性。借助devops和云平台，微服务可以有单个独立的小团队开发、部署和运维。是现代分布式系统的首选架构，也是遗留架构首选的演进和重构方向。
 子域 Subdomain. 处理遗留系统中无边界的复杂性.
子域是整个业务领域的一部分，负责为核心业务提供解决方案。限界上下文应该与子域一一对应。
项目中有三种主要的子域类型：
 核心域/Sub Domain：核心业务功能 支撑子域/Supporting Domain：定制开发 通用子域/Generic Domain：可采购、外包或内部实现  上下文映射 Context Mapping. 集成多个限界上下文.
Context Map/上下文映射图同时定义了两个进行集成的限界上下文之间的团队间关系及技术实现方式.
上下文映射本质是一种集成关系，持续集成的实践活动对上下文映射关系不可或缺。
映射的种类：
 合作关系/Partership:通过互相依赖的一套目标联合起来，需要联系紧密并经常同步 共享内核/Shared Kernel：共享小规模通用模型，常见方式是将通用模块以二进制依赖(Jar,链接库)方式共享 客户-供应商/Customer-Supplier:上下游关系。可采用消费者驱动契约(Consumer Driven Contract/CDC)实践，通过契约测试保持之间协作 跟随者/遵奉着/Conformist：上游过于强大，只能按约定集成 防腐层/Anticorruption Layer:下游团队在上下游通用语言模型之间创建翻译层。推荐实践。 开放主机服务/Open Host Service:REST服务是一种常见的实例 已发布语言/Published Language: 和开放主机服务结合，API&#43;XML/JSON 各行其道/Separate Way 大泥球：特征有  越来越多的聚合因不合理的关联和依赖而交叉感染 对一部分进行维护就会牵一发而动全身，解决问题像在打地鼠 只剩“部落知识”和“个人英雄主义”，唯一“讲”出所有语言的极个别“超人”方能扶大厦之将倾     防腐层是最常见的一种阻止外部技术偏好或领域模型侵入的设计模式。API网关就是一种防腐层的具体实现。 另外对遗留单块系统进行拆分时，防腐层也发挥着巨大作用。 有一种对付单块系统的重构方式叫做“抽象分支/Branch by Abstraction”,其中从要拆分的模块中提取出的抽象层就发挥着防腐层的作用，在重构的过程中抵挡着未拆分部分对重构工作的腐蚀。
 集成方式
 基于SOAP的RPC：现代RPC机制更友好的支持多编程语言，序列化协议(gRPC,Thrift)比XML更高效，传输协议更现代(HTTP/2) RESTful HTTP： 避免直接把模型中的聚合暴露成资源，服务端提供的资源必须具有客户端需要的样子和组成 消息机制  领域事件由聚合发布，感兴趣的订阅方都可以消费 消息机制应支持至少一次投递/Reactive来保证所有消息最终都会被收到 订阅方必须实现幂等接受者/Idempotent Receiver     Backoff/退避算法重试机制,发送者会在再次重试之前等待一个随机时间，避免多个发送者按相同的时间间隔重试产生的冲突。等待时间的随机范围通常采用一种策略和算法来计算，常用的有指数退避算法。
 战术设计 聚合 Aggregate模式.
 值对象/Value Object/值：对一个不变的概念整体所建立的模型，常用来描述、量化或测量一个实体。 实体：一个实体模型就是一个独立的事物，拥有一个唯一的标识符，可以将它的个体性和其他实体区分开。 聚合：由一个或多个实体组成，其中一个实体被称为聚合根（Aggregate Root）。也可能包含值对象。  每个聚合的根实体(Root Entity)控制着所有聚集在其中的其他元素。根实体的名称就是聚合概念上的名称。 每个聚合都会形成保证事务一致性的边界。只能在一次事务中修改一个聚合实例并提交。    业务规则最终决定在单次事务完成提交后，哪些对象必须是完整、完全和一致的驱动力。
聚合的实现应避免贫血领域模型（函数式编程除外），先为聚合根实体创建一个类，它继承于基类Entity。
聚合设计的四条基本原则
 在聚合边界内保护业务规则不变性 聚合要设计得小巧：符合SRP/单一职责原则 只能通过标识符引用其他聚合 使用最终一致性更新其他聚合。  领域事件 Domain Event.
领域事件是一条记录，记录着限界上下文中发生的对业务产生重要影响的事情。
领域事件类型的名称应该是对过去发生事情的陈述，即动词的过去式。比如ProductCreated,ReleaseScheduled.
领域事件通常由命令(一个方法/动作请求的对象形态)发布，命令可命名为CreateProduct。也可能由其他变化的状态引起，比如日期和时间。
消费事件的限界上下文要能识别出正确的因果关系，因果关系可以由领域事件类型本身表明，或由和领域事件关联的元数据表示，比如一个序列标识符或因果标识符。
事件溯源(Event Sourcing)
对所有发生在聚合实例上的领域事件进行持久化，把它们当做对聚合实例变化的记录。
可以在核心域上使用事件溯源，达到高吞吐量、低延迟和高伸缩性。性能最好的是缓存在内存中的聚合，另一种方式是使用快照(对聚合的增量状态的快照进行维护)。
辅助工具 事件风暴 使用Event Storming加速建模.
步骤：
 通过创建一系列写在便利贴上的领域事件，快速梳理出业务流程。 创建导致每个领域事件发生的命令。 把命令和领域事件通过实体/聚合关联起来，命令在实体/聚合上执行并产生领域事件的结果。实体就是命令执行和领域事件触发的数据载体。 在建模平面上画出边界和表示事件流动的箭头连线。 识别用户执行操作所需的各种视图(View)，以及不同用户的关键角色。  其他工具：
 引入&amp;quot;Given/When/Then&amp;quot;格式编写的可执行的高级需求说明/验收测试/实例化需求 影响力地图/Impact Mapping 用户故事地图/User Story Mapping  敏捷项目管理DDD  SWOT分析法(四象限矩阵)  优势/Strength: 领先于对手的业务或项目特征 劣势/Weakness： 落后于对手的业务或项目特征 机会/Opportunity：可以发挥项目优势的要素 威胁/Threat：存在于环境中并可能给业务或项目带来问题的因素   建模Spike和建模债务(类似技术债务)   Spike通过一系列的探索活动获取必要的知识，以降低技术方法的风险、更好的理解业务需求或提高用户故事的可靠性。 探索活动包括研究、设计、调查和原型等
  任务识别和工作量估算  最简单和最准确的估算方式之一：基于度量指标的方法。 按组件类型为每个组件在表格增加一行 填入每一复杂级别(简单、适中、复杂)所需的小时数，估算含设计、实现、测试工作量    扩展阅读  《领域驱动设计精粹》 《实现领域驱动设计》 服务拆分与架构演进 《REST实战》 “鱼变慢”还是“技术债”：适合国人口味的比喻 </content>
    </entry>
    
     <entry>
        <title>Spring实战</title>
        <url>https://xulizhao.com/blog/spring-in-action/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Spring5 学习记录。
SpringBoot刚出来时用过一点，从Spring Boot2回看，发现这个生态真是进步巨大。
起步 项目初始化 Initializr
 https://start.spring.io/ curl Spring Boot cli Spring Tool Suite IntelliJ IDEA VS Code &#43; 插件  依赖管理 名字包含starter的依赖并不包含实际的代码库，只是为了方便项目依赖版本管理。
运行  java -jar xxx.jar mvn spring-boot:run Spring Dashboard  学习笔记 Spring Boot带来的好处:
  starter dependencies
  autoconfiguration
  Actuator运行时信息监控
  灵活的环境配置
  增强的测试支持
  尽量使用Spring Boot,必要时显示声明Java样式的配置。
  components或叫做beans支持在Spring application context显式定义为Java或XML(旧格式)
  Component Scanning：用于自动发现并为Spring application context创建bean
  常用注解：
 @Controller @Component @Service @Repository  Model模型 MVC.
@ModelAttribute
View模板 不推荐使用后端模板引擎，建议前后端分离。
开发环境禁用缓存：
# application.propertiesspring.freemarker.cache=falsespring.thymeleaf.cache=falseFreeMarker
Mustache
Thymeleaf
这个项目代码上次更新还是一年前（2018年10月），还是远离这个模板的好。
@{…} 操作符代表一个context-relative路径
JSP
官方强烈不推荐JSP，因为它的依赖实现通常是容器做的（Tomcat,Jetty等），且默认只识别WEB-INF文件夹。
这意味着只支持war包的形式，使用将非常受限。
Controller 路由  @RequestMapping 用于类 @GetMapping等用于handler方法 返回的通常是视图的逻辑名  @Configurationpublic class WebConfig implements WebMvcConfigurer {@Overridepublic void addViewControllers(ViewControllerRegistry registry) {registry.addViewController(&amp;#34;/&amp;#34;).setViewName(&amp;#34;home&amp;#34;);}}数据类 Validation 字段验证：
 @NotNull @Size @NotBlank @Digits @Pattern 正则  Hibernate内置：
 @CreditCardNumber  添加在数据类前：
 @Valid  测试 pom.xml依赖于spring-boot-starter-test。
注: 2.0.9依赖于JUnit4, 但2.2.x分支已切换到JUnit5.
 @SpringBootTest @WebMvcTest  辅助工具  spring-boot-devtools  自动重启（类修改） ~/.spring-boot-devtools.properties 全局设置    扩展阅读  spring.io/guides Build a Simple CRUD App with Spring Boot and Vue.js spring boot demo </content>
    </entry>
    
     <entry>
        <title>matplotlib绘图库</title>
        <url>https://xulizhao.com/blog/matplotlib/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> Python库记录系列.
安装 pip install matplotlib# 会自动安装依赖numpy基本使用 常用格式 plt.plot(range(10), linestyle=&amp;#39;--&amp;#39;, marker=&amp;#39;o&amp;#39;, color=&amp;#39;b&amp;#39;)# 等价于 plt.plot(range(10), &amp;#39;--bo&amp;#39;)基本概念  Label/标签:标明指定数据类型或分组 Annotation/标注:对数据的补充说明信息 Legend/图例：数据列表的分类说明(以颜色等区分)  import matplotlib.pyplot as pltimport numpy as np#  plt.ylabel(&amp;#34;Values&amp;#34;)#  plt.annotate(xy=[1,1], s=&amp;#34;First Entry&amp;#34;)plt.annotate(label, # this is the text (x,y), # this is the point to label textcoords=&amp;#34;offset points&amp;#34;, # how to position the text xytext=(0,10), # distance from text to points (x,y) ha=&amp;#39;center&amp;#39;) # horizontal alignment can be left, right or center # Legend plt.legend([&amp;#39;First&amp;#39;, &amp;#39;Second&amp;#39;], loc=4)t2 = np.arange(0.0, 2.0, 0.01)fig, ax = plt.subplots()# 注意,的使用，l1是个Line2D实例 l1, = ax.plot(t2, np.exp(-t2))ax.legend((l1), (&amp;#39;exp&amp;#39;), loc=&amp;#39;upper right&amp;#39;, shadow=True)# 添加文本/text # 默认左对齐 plt.text(8,3,&amp;#39;This text ends at point (8,3)&amp;#39;,horizontalalignment=&amp;#39;right&amp;#39;)常用功能 支持中文标签 import matplotlib.pyplot as plt# 用来正常显示中文标签 plt.rcParams[&amp;#39;font.sans-serif&amp;#39;] = [&amp;#39;SimHei&amp;#39;] # 用来正常显示负号 plt.rcParams[&amp;#39;axes.unicode_minus&amp;#39;] = False numpy import numpy as np# 范围取值 np.arange(20, 120, 20)# 读取csv文件 data = np.genfromtxt(&amp;#39;result.csv&amp;#39;, delimiter=&amp;#39;,&amp;#39;, skip_header=True)# 交换二维数组 data1 = np.swapaxes(data, 0, 1)# 交换方式二 x = np.arange(4).reshape((2,2))# 转换/对调 np.transpose(x)扩展阅读  官方文档：常用绘图格式 官方示例 - 两个Y轴：参考 Plots with different scales legend demo  numpy
 开始使用numpy </content>
    </entry>
    
     <entry>
        <title>加解密算法学习</title>
        <url>https://xulizhao.com/blog/crypto/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>security</tag>
        </tags>
        <content type="html"> 关于SSL，TLS，对称加密，非对称(公私钥)加密等的学习笔记。
密钥交换算法 常用算法：
   名称 安全性 备注     RSA 低，有RSA私钥就可以解密 已有公私钥，只执行一次模幂   DHE 较高，RSA私钥泄露不影响 每次随机生成大素数，模幂两次   ECDHE 很高 每次生成大数，计算椭圆方程的乘法两次，得到公钥    说明：
 如果开启完全正向保密协议/perfect forward secrecy,客户端和服务端会使用Diffie-Hellman (DH)协商一个共享会话密钥; 服务端私钥只用来签名. 如果不支持完全正向保密协议(假定服务端使用RSA密钥), 客户端会使用服务端公钥加密共享会话密钥, 同理也就可以使用服务端私钥解密（被服务端或Wireshark）.  扩展阅读  []() </content>
    </entry>
    
     <entry>
        <title>Protocol Buffers协议笔记</title>
        <url>https://xulizhao.com/blog/protobuf/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 之前二进制序列化火热时Thrift和Protocol Buffers是最常用的协议，这次因为要写protobuf的Java程序，做些简单的记录。
常用数据序列化协议  JSON : 不用多介绍，Restful中最常用的，可读性好 Protocol Buffers：Google的开源RPC数据协议，最新版protobuf3 MessagePack : Locust二次开发用过，性能更好的类JSON二进制协议 Thrift：Facebook开源的跨语言数据协议  数据定义 下面用到的示例程序参考文末链接。
数据结构定义，album.proto：
syntax = &amp;#34;proto3&amp;#34;;option java_outer_classname = &amp;#34;AlbumProtos&amp;#34;;option java_package = &amp;#34;com.xulizhao.protobuf&amp;#34;;message Album {string title = 1;repeated string artist = 2;int32 release_year = 3;repeated string song_title = 4;}说明：repeated代表是一个List类型的字段,之后通常用AddAllXxx()或AddXxx()构造数据。
命令行使用 # 生成Java Codeprotoc.exe --java_out=. album.proto# 生成数据描述文件，Charles之类工具会用到protoc.exe -oalbum.desc album.protoJava代码解释 自动生成的Java代码实际包含了数据类定义和Builder方法等。
// 构造数据实例AlbumProtos.Album albumMessage = AlbumProtos.Album.newBuilder().setTitle(album.getTitle()).build();// 数据实例转化为二进制final byte[] binaryAlbum = albumMessage.toByteArray();// 二进制解析为数据实例AlbumProtos.Album copiedAlbumProtos = AlbumProtos.Album.parseFrom(binaryAlbum);参考  https://dzone.com/articles/using-googles-protocol-buffers-with-java </content>
    </entry>
    
     <entry>
        <title>sipp压测工具介绍</title>
        <url>https://xulizhao.com/blog/sipp/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>networking</tag><tag>testing</tag>
        </tags>
        <content type="html"> 把sipp这个性能测试工具的笔记独立出来，更多VOIP知识参考VOIP学习笔记。
测试工具sipp 官方介绍：
 SIPp包含基本的SipStone User Agent场景 (UAC and UAS)，支持测试的动态显示 (call rate, round trip delay, message statistics)
 安装 # CentOSyum install sipp# Ubuntusudo apt-get install -y pkg-config dh-autoreconf ncurses-dev build-essential libssl-dev libpcap-dev libncurses5-dev libsctp-dev lksctp-tools cmake libgsl-dev gitgit clone https://github.com/SIPp/sipp.gitcd sipp./build.sh --fullsudo cp sipp /usr/local/bin/命令行使用  sipp remote_host[:remote_port] [options]
  -sn 使用内置的场景，默认使用uac，即标准SipStone UAC -sd 导出内置场景 -sf 使用指定场景配置文件 -i 指定本地IP -p 指定本地端口，默认随机端口 -l 限制并行呼叫数，默认值： 3 * call_duration (s) * rate -m 在呼叫次数达到后退出 -r 场景执行速度，默认1秒10次 -r 10 -rp 5s 则限定为每5秒10 calls -rp (Rate Period,默认毫秒数) -s 设置请求地址的用户名部分，默认值&#39;service&amp;rsquo; -t l1 指定协议为TLS -rsa 指定远程收发消息的Proxy地址  # 示例sipp -h# 在同一台机器执行下面2条命令，Ctrl &#43; C 取消运行sipp -sn uassipp -sn uac 127.0.0.1# 导出某场景sipp -sd uac_pcap &amp;gt;&amp;gt; integrated_uac_pcap_scenario.xml场景配置 # 针对用户001执行5次sipp 192.168.1.100 -sf options.xml -m 5 -s 001&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;us-ascii&amp;#34;?&amp;gt;&amp;lt;scenario name=&amp;#34;Options&amp;#34;&amp;gt;&amp;lt;send&amp;gt;&amp;lt;![CDATA[OPTIONS sip:[service]@[remote_ip] SIP/2.0Via: SIP/2.0/[transport] [local_ip]:[local_port];branch=[branch]Max-Forwards: 70To: &amp;lt;sip:[service]@[remote_ip]&amp;gt;From: sipp &amp;lt;sip:sipp@[local_ip]:[local_port]&amp;gt;;tag=[call_number]Call-ID: [call_id]CSeq: 1 OPTIONSContact: &amp;lt;sip:sipp@[local_ip]:[local_port]&amp;gt;Accept: application/sdpContent-Length: 0]]&amp;gt;&amp;lt;/send&amp;gt;&amp;lt;/scenario&amp;gt;数据驱动  sipp &amp;hellip; -inf client.csv
 client.csv
SEQUENTIALtest0;192.168.178.98;[authentication username=test password=test0];音频编解码  G.711也称为PCM（脉冲编码调制），是ITU-T订定出来的一套语音压缩标准，主要用于电话。它主要用脉冲编码调制对音频采样，采样率为8k每秒。它利用一个 64Kbps 未压缩通道传输语音讯号。起压缩率为1：2，即把16位数据压缩成8位。G.711是主流的波形声音编解码器。G.711 标准下主要有两种压缩算法：U-law algorithm和A-law algorithm，其中，后者是特别设计用来方便计算机处理的。
 wav2rtp:
# Ubuntugit clone https://github.com/imankulov/wav2rtp.git# make distcleansudo apt-get install libortp-dev libsndfile1-dev libspeex-dev libpcap-dev libgsm1-dev autoconf./init.sh &amp;amp;&amp;amp; ./configure LIBS=&amp;#34;-lm&amp;#34; --prefix=/opt/wav2rtp &amp;amp;&amp;amp; makesudo make installsox 1minute.wav -r8000 1min.wav/opt/wav2rtp/bin/wav2rtp -f 1min.wav -t 1min.pcap -c PCMA扩展阅读  sipp： 配置文件基于XML pysipp : Python的sipp扩展 sippy_cup：Ruby开发的sipp扩展 sipp-3.5.1-1.el7.x86_64.rpm How to install SIPp testing tool on Ubuntu 18.04 How to decode SIP over TLS with Wireshark Cisco libSRTP sip-stress-testing-part-3 SIPp-IP-Telephone-Server-Performance-Testing 使用Sipp压测FreeSwitch实践 一些场景例子：1,2,3, rtpbreakr Kamalio Performance test kamailio registrations </content>
    </entry>
    
     <entry>
        <title>了解VOIP</title>
        <url>https://xulizhao.com/blog/voip/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>networking</tag>
        </tags>
        <content type="html"> VOIP简单说就是网络电话。
按：最近想找做个Java版的VOIP简单demo，发现官方居然没有个正经库。网上这方面的一些介绍文章也已经过时，特整理一份供大家参考。
名词解释  SIP ：Session Initiation Protocol/会话初始协议，互联网电话 RTP ：Real Time Protocol/实时传输协议 RTCP: 每发完一批RTP包的时候，就发一个RTCP包，告诉接收方我刚才发了多少RTP包，多少个字节 PBX ：程控交换机，集团电话  SIP是基于文本的应用层控制协议，用于创建、修改和释放一个或多个参与者的会话。支持tcp和udp传输，通常使用UDP协议。
SDP：Session Description Protocol/会话描述协议，描述终端设备的特点。用途之一是会话建立时，需要媒体协商，双方才能确定对方的媒体能力以及交换媒体数据。
SIP协议栈 拨号地址格式： sip/sip:username@ip_address[:port]
注： 端口为可选项，不提供使用默认端口5060。
Kamailio Kamailio/github仓库,是流行的开源的SIP Proxy。和早期的另一分支OpenSips同样出自SER(SIP Express Router)。
不同于PBX，Kamailio是个纯粹的SIP服务器，它可以作为Proxy、注册服务器、重定向服务器，也可作为简单的Presence服务器，其本身并不处理RTP，可能通过RTPProxy来处理RTP的NAT问题。
Kamailio最新5.2版本,通常与RTPEngine组合，kamailio (995 ★) &#43; rtpengine (311 ★)
# 安装# Debian/Ubuntu 仓库: https://deb.kamailio.org/wget -O- http://deb.kamailio.org/kamailiodebkey.gpg | sudo apt-key add -sudo apt updatesudo apt install mysql-serversudo apt install kamailio kamailio-mysql-modulessystemctl start kamailio# dumpkamcmd ul.dump# 添加subscriber用户kamctl add alice secretkamctl restart# 开启日志vi /etc/rsyslog.conf# 插入下面这行local0.* -/var/log/kamailio.logsystemctl restart rsyslog.service 更多信息参考:kamailio-install-guide-deb
RTPEngine rtpengine通常作为媒体代理（media proxy）。
rtpengine is a proxy for RTP traffic and other UDP based media traffic.
opensips opensips,同kamailio,用作SIP代理和控制信令。
现在主要为3.0/2.4两个版本分支，常见组合：OpenSIPS做sip proxy，FreeSWITCH做SBC和媒体网关，媒体网关也可选Asterisk。
opensips(619 ★) &#43; rtp proxy ( 208 ★)
RTP Proxy  是一个高性能而且开源的RTP流(RTP Stream)软件代理(Software Proxy). 其典型应用就是作为OpenSIP服务器的子模块, 为SIP Call 提供的Video/Audio RTP Stream的转发.
其他 Asterisk  is an Open Source PBX and telephony toolkit. C实现，0.7k star。
FreeSWITCH 
SIP/RTP开源实现  PJSIP: C语言实现的多媒体跨平台通讯库，支持SIP,RTP等多种协议 peers: Java实现 RTSP-Client-Server: Java的RTP实现  安卓客户端  Lumicall : 支持证书  brew install yasmbrew install ffmpeg测试库 两个Java实现
 sipunit simulap-plugin-sip  本地开发 git clone https://github.com/BelledonneCommunications/linphone-desktop.git安装QT5 http://download.qt.io/official_releases/qt/5.9/
不再维护的库  官方的JMF 半官方的JSIP/JAIN-SIP doubango  客户端 Yate SIP客户端 支持跨平台的开源客户端，下载
MicroSIP MicroSIP ,Windows客户端的一种选择。
Linphone Mumble Mumble,C&#43;&#43;实现，2.7k star
为游戏设计的语音聊天软件，基于Qt 和 Opus，包含client和server端。
音视频处理 WebRTC WebRTC是一个支持网页浏览器进行实时语音对话或视频对话的开源项目,它提供了包括音视频的采集、编解码、网络传输、显示等功能。 但需要配合其他开源server项目。
Jitsi Jitsi 开源的多人视频会议系统,配合WebRTC。
Java实现,2k star。
janus WebRTC Server janus,C实现，2.9k star
扩展阅读  Learning VoIP, RTP and SIP 最全实时音视频开发要用到的开源工程汇总   pjsip.org peers RTSP-Client-Server </content>
    </entry>
    
     <entry>
        <title>JMeter基础笔记</title>
        <url>https://xulizhao.com/blog/jmeter/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>jmeter</tag>
        </tags>
        <content type="html"> JMeter的使用不能说最频繁，但是性能测试之前多次使用过，每次都有些时间间隔。
汇总下之前零散的笔记供参考.
基础组件 原理 为每个虚拟用户启动一个线程，每个线程从上到下执行样本。当没有更多样本sampler或没有循环loop可执行时关闭。
ThreadGroup/线程组  所有的 Thread Groups默认并行运行 (可勾选”独立运行每个线程组”或函数测试模式) Ramp-Up时间指启动所有线程的等待时间, 对于大的压力需要足够长时间. Ultimate Thread Group : 提供增强的线程组启动模式  Listeners/监听器 通常用来保存结果。常用的有：
 View Results Tree: 方便本地调试，RegExp Tester或Debug Sampler调试 Aggregate Report: 汇总报告 Generate Summary Results: 在控制台或日志定期输出汇总结果 Backend Listener: 通常与InfluxDB等相结合  取样器/Sampler  Java Request Sampler : 可使用变量,性能最好 (一个class指定一个测试) JSR 223 JUnit Sampler: 可以在一个class指定多个测试类型 (不能提供变量) BeanShell Sampler : 最快速的实现,适用于一次性调用 (功能有限且不灵活)  Java Sampler 部署: 打包成jar, 然后放在 lib/ext目录.
JSR233 支持Groove等脚本，可用于调试。
def topic = vars.get(&amp;#34;topic&amp;#34;)log.info(&amp;#34;Topic from the response is ${topic}&amp;#34;)Post Processors/后置处理器 处理输出等
Extractor  Regular Extractor: 使用正则表达式匹配，方便在response调试。模板通常为$1$ Boundary Extractor: 需提供匹配值的左右边界字符串，基于indexOf方法实现。简单匹配比正则快。  Assertion/断言 通常用来判断输出是否符合预期
常用组件 逻辑控制器  While : 只判断true或false If Controller配合Flow Control Action使用  Stop Now意味着立即停止不管是否执行成功 偶尔可以用BeanShell的方式：SampleResult.setStopTestNow(true);    Timers/定时器 Timer 被添加为子节点。注：timer先于sampler执行，如果存在多个timer，会被先于sampler顺序执行
 Synchronizing Timer: 在生成指定数量线程后同时释放 Constant Throughput Timer：保持确定的RPS 高斯定时器：等价于 Math.abs((this.random.nextGaussian() * 300) &#43; 100)，偏差100，固定延迟偏移300 Synchronizing Timer： 使用集合点（rendezvous point）作用是：阻塞线程，直到指定的线程数量到达后，再一起释放，可以瞬间产生很大的压力  Config Element/配置元件  Counter CSV Data Set Config: 读取外部数据，每个线程读取一行记录。  Sharing Mode： 代表每个线程组一个文件还是每个线程读取一个文件，通过文件别名来实现。如果不是多个线程组共享同一文件，默认值即可。    设置变量和默认值：
 HTTP Header Manager HTTP Request Defaults User Defined Variables  读写文件：
f = new FileOutputStream(&amp;#34;Results.csv&amp;#34;, true);p = new PrintStream(f);变量 # 读取变量vars.get()# 设置变量vars.put()# 使用变量${var1}多个线程组间共享变量：
BeanShell Assertion${__setProperty(first_url, ${first_url})};${__property(first_url)}# BeanShell PreProcessor 操作字符串props.get(&amp;#34;name_of_variable&amp;#34;)内置变量
${__threadNum}
函数 [工具]-[函数助手对话框]
 随机数: ${__Random(1,100,rand_id)} 时间： ${__time(,)}和${__time(,)} / 1000分别返回当前时间的毫秒数和秒数  扩展阅读  官方:共享变量 计数器 各种计时器 /Constant Throughput Timer While Controller 函数讲解 jsr223/groovy variables </content>
    </entry>
    
     <entry>
        <title>JMeter高级使用笔记</title>
        <url>https://xulizhao.com/blog/jmeter-advanced/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>jmeter</tag>
        </tags>
        <content type="html"> JMeter的使用不能说最频繁，但是性能测试之前多次使用过，每次都有些时间间隔。
汇总下之前零散的笔记供参考。
接上文JMeter基础篇。
一些插件用法 用Plugins Manager方便插件管理，需要把下载的插件管理jar放在lib/ext 目录并重启JMeter. GUI: [Options] - [Plugins Manager]下载安装。
常用插件：
 PerfMon监控服务端 ConcurrencyThreadGroup InterThreadCommunication  非GUI模式 参数说明:
 -n: 非GUI模式执行 -t: 测试计划文件的位置 -l: 指定生成测试结果的保存文件(jtl文件格式) -e: 测试结束后生成测试报告 -o: 指定测试报告生成位置  # 命令行执行并生成报告jmeter -n -t testplan.jmx -l result.jtl如何查看JTL报告 添加&amp;quot;察看结果树&amp;rdquo;,点击&amp;quot;浏览&amp;quot;打开生成的jtl文件。
也可以生成HTML报告：
jmeter.bat -g result.jtl -o /tmp/report以XML查看jtl
在jtl文件的testResults标签前添加 Windows批处理：
del /s /Q result.jtlrd /s /Q E:\reportmd E:\reportjmeter -n -t E:\opt\apache-jmeter-5.1.1\bin\testplan.jmx -l result.jtl -e -o E:\report# 汇总报告# jmeter.propertiessummariser.log=true分布式执行 分布式测试时各slave要读取不同的csv数据。
1 . 从节点 - 禁用RMI SSL: jmeter.properties
 server.rmi.ssl.disable=true
 2 . 从节点 - 启动Slave
 JMETER_HOME/bin/jmeter-server 或 JMETER_HOME/bin/jmeter -s　 3 . 主节点 - 添加slave IP到master配置文件: jmeter.properties
 remote_hosts=192.168.1.101,192.168.1.102
 4 . 主节点 - 远程界面启动: ［Run］- [Remote Start All] 或 命令行
 jmeter -n -t script.jmx -r # 或者 jmeter -n -t script.jmx -R server1,server2,…
 注: 有时候必须指定report发送到的master地址,否则收不到报告，并一直停留在Waiting for possible Shutdown/StopTestNow/Heapdump message on port 4445 这时需要配置 -Djava.rmi.server.hostname=[slave节点IP]
调试和日志 调试常用组件：
 View Result Tree(仅用于调试) Debug Sampler JSR223 Sampler RegExp Tester  详细调试  命令行带参数 -LDEBUG 启动文件：%JM_START% &amp;ldquo;%JM_LAUNCH%&amp;rdquo; %ARGS% %JVM_ARGS% -jar &amp;ldquo;%JMETER_BIN%ApacheJMeter.jar&amp;rdquo; %JMETER_CMD_LINE_ARGS% -LDEBUG
 set JVM_ARGS=-Dlogback.debug=true -Dlogback.configurationFile=logback.xml性能优化  使用非GUI模式 监听器仅用于调试，大并发关闭 增加Heap大小  JMeter Engine(Node): 对于HTTP/S协议，推荐每个Engine最多运行1000个threads/virtual users；　通常考虑以下２个因素:
 每个Engine 每秒最多600个hits 每个Engine最多300Mbps带宽  模拟更高并发 JMeter 是同步线程请求/BIO，如果需要更高的压力应该用异步线程。
当设置所有的请求均为1s超时时，可以类比实现tps=线程数的效果，jmeter默认使用httpclient4，可以在HTTPHC4Impl的setupRequest()方法中增加超时时间限制
HttpParams requestParams = httpRequest.getParams();...requestParams.setIntParameter(CoreConnectionPNames.SO_TIMEOUT, 1000);requestParams.setIntParameter(CoreConnectionPNames.CONNECTION_TIMEOUT, 1000);//设置请求均为1000ms超时扩展阅读 教程  分布式测试 BlazeMeter博客 awesome-jmeter 实现Java Sampler 性能及测试开发文章整理 配置日志 如何测试TCP  增强  插件管理 Taurus </content>
    </entry>
    
     <entry>
        <title>mqtt轻量级发布订阅协议</title>
        <url>https://xulizhao.com/blog/mqtt/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>message</tag>
        </tags>
        <content type="html"> 轻量级发布订阅协议MQTT介绍。
MQTT协议 MQTT（消息队列遥测传输）是一个应用层协议，基于TCP/IP协议。使用发布-订阅模式用户客户端和其他端的通讯。
广泛应用于物联网领域。
通常使用1883端口作为默认端口，如果开启SSL，TCP端口是8883。
服务等级 常用服务等级分为3级，级别越高，性能损耗越大，但同时可靠性越高。
 QoS = 0 - means one delivery at most，The receiver gets the message either once or not at all. QoS = 1 - means one delivery at least. 可能存在重复消息 QoS = 2 - means one delivery exactly.  保活 MQTT客户端可以一直保持连接状态，即使不发布或接受任何消息。
但是Broker需要追踪哪些客户端还在连接，所以需要知道何时发送Last Will and Testament (LWT)消息给客户端。
这时候用到了keepalive时间，即每次客户端接受或发送一个消息时，broker重置一个计时器，如果计时器超过1.5倍的保活(keepalive)时间,则标记客户端为已断开并处理LWT。
为阻止低频率消息客户端被断开连接，broker会在计时器到达keepalive时间时发送PINGREQ包到客户端，如果收到客户端的PINGRESP回包，会重置计时器到0，代表客户端仍处于连接状态。
客户端 最常用的客户端应该是paho,对应各种常见语言的版本及安卓版,可以去官方仓库查找。
最常用的有Python和Java版:
 paho.mqtt.python paho.mqtt.java  Python客户端 pip install paho-mqtt对于python客户端，连接时会遇到错误码，对应关系如下：
 0: Connection successful 1: Connection refused - incorrect protocol version 2: Connection refused - invalid client identifier 3: Connection refused - server unavailable 4: Connection refused - bad username or password 5: Connection refused - not authorised  用法 既然是订阅，最常用到的就是topic，其中通配符主题用 # 表示。
Server实现 扩展阅读  MQTT </content>
    </entry>
    
     <entry>
        <title>开源压测工具Locust</title>
        <url>https://xulizhao.com/blog/locust/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> locust是流行的开源性能测试工具,其压测脚本就是python代码,所以特点是简单,灵活.
之前使用的场合比较多,汇总些笔记供参考.
安装及依赖 pip3 install locustio注: 可以在Windows做开发调试,不建议做实际运行,性能较差
Locust主要基于以下库实现:
 gevent/greenlet: 轻量级异步线程 msgpack-python: master和slave通讯的一种高效消息格式 flask/jinja2/werkzeug: web界面的实现  Windows安装  安装gevent错误修复：   修复Python库 Windows安装错误:error Microsoft Visual C&#43;&#43; 14.0 is required 安装Microsoft Build Tools for Visual Studio
 下载vs_buildtools.exe并选择Workloads → C&#43;&#43; build tools -&amp;gt; Windows 10 SDK安装。
启动时web页面打不开问题解决：需指定&amp;ndash;web-host参数   locust &amp;ndash;web-host=127.0.0.1
 使用 默认的压测脚本为本地目录的locustfile.py
具体的用法见locust -h
常用选项
locust -H &amp;lt;my_url&amp;gt; -f &amp;lt;my_locust_file&amp;gt; -c 120 -n 10000 --no-web --only-summaryWeb管理页面方式 执行完命令后,访问本地或Master的IP地址, http://127.0.0.1:8089 就可以看到web控制台了.
命令行执行 也支持不使用web页面, 需要指定几个参数值
locust --no-web -c 10 -r 5# -c == --clients# -r == --hatch-rate扩展阅读 官方必读  Quick Start Writing a locustfile </content>
    </entry>
    
     <entry>
        <title>开源反向代理及负载均衡Envoy初探</title>
        <url>https://xulizhao.com/blog/envoy-proxy/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>microservice</tag>
        </tags>
        <content type="html"> Envoy是Lyft于2017年开源的网络反向代理工具,现属于CNCF基金会的毕业项目.
和Nginx和HAProxy相比,功能更强大,开源更彻底(提供的许多功能是其他产品的付费功能).
作为新兴代理,与微服务紧密结合,可以提高强大的可观察性功能,通常做为入口代理/边缘代理/中间代理等. 流行的Service Mesh框架istio就是基于Envoy构建而成.
Envoy本身用C&#43;&#43;开发,并发模型与Nginx类似,具有很高的处理性能.属于L4层代理，但支持7层HTTP协议栈。
本文聚焦于Envoy代理本身所提供的丰富功能,个别地方也会引入微服务和Service Mesh的概念,读者可以再做深入了解.
sending (egress) and receiving (ingress) service。
使用和部署 官方提供两种部署方式.
本地编译 在Ubuntu 18.04下编译,具体参考官方说明.
安装bazel参考这里
# 安装依赖apt-get install ninja-build# 本地编译bazel build //source/exe:envoy-static编译后的文件位于 /bazel-bin/source/exe/envoy-static
使用docker容器的方式 快速验证
docker pull envoyproxy/envoy-dev:8d1ad35aa724962f64f7535531e408c9a93d364cdocker run --rm -d -p 10000:10000 envoyproxy/envoy-dev:8d1ad35aa724962f64f7535531e408c9a93d364c# 默认使用10000端口curl -v localhost:10000定制和扩展 基于配置规则创建自己的envoy.yaml
docker run --name=envoy -d \ -p 10000:10000 \ -v $(pwd)/envoy.yaml:/etc/envoy/envoy.yaml \ envoyproxy/envoy:latest或者创建自己镜像:
# DockfileFROM envoyproxy/envoy-dev:8d1ad35aa724962f64f7535531e408c9a93d364cCOPY envoy.yaml /etc/envoy/envoy.yaml构建新的定制镜像
docker build -t envoy:v1 .# 9901为管理端口docker run -d --name envoy -p 9901:9901 -p 10000:10000 envoy:v1curl -v localhost:10000调试  访问管理接口 /logging 传递日志参数  -l &amp;lt;string&amp;gt;, --log-level &amp;lt;string&amp;gt; --log-path &amp;lt;path string&amp;gt;部署方式 Front Proxy 作为公网客户请求的主负载均衡,也叫做edge proxy/load balancer (南北流量).
同时适合做中心认证,重试,健康检查.
Service Mesh 处理内部服务间流量(东西流量).
k8s作为sidecar 配置服务发送所有出口(outbound)流量到该sidecar.
配置 静态配置文件默认位于 /etc/envoy/envoy.yaml
概念 路由配置:
 Route: 映射虚拟主机到集群的一组规则集. Cluster: 一组相似的上游主机/端口,用于负载均衡流量 Endpoint: IP和端口,负责具体的服务处理 Listener: 命名的网络地址,用来接受下游客户端的网络连接.  动态配置 动态配置支持文件和API(配置服务器)两种方式.
 Control Plane/控制平面 Data Plane/数据平面  最佳实践:基于数据中心/区域或服务类型做配置分隔.
基于文件的动态配置 参考文档: 动态配置路由
配置服务器实现 官方提供了Go和Java两个默认实现
常见应用场景 官方文档的沙箱部分是个很好的开始.
熔断 配置项定义在cluster下
circuit_breakers:thresholds:- priority: DEFAULTmax_connections: 1000max_requests: 1000- priority: HIGHmax_connections: 2000max_requests: 2000max_retries: xxx注: HTTP/1.1使用max_connections, HTTP/2 使用max_requests
自动重试 重试策略:
# 在route下定义retryretry_on: &amp;#34;5xx&amp;#34;num_retries: 1 # 默认值per_try_timeout_ms: 2000 不要重试会改变重试结果的请求(建议先尝试GET操作) 不要重试昂贵的请求  要仔细考虑设置策略,比如上游timeout_ms不应该设置过长避免不能在指定时间完成重试,全局timeout_ms也不应该设置过长避免并发请求超时造成系统负担.
健康检查 可以分主动检查和被动检查,配置项在cluster下定义.
 健康检查/Health Checking 异常检测/Outlier Detection  # 健康检查例子health_checks:- timeout: 1sinterval: 60sinterval_jitter: 1sunhealthy_threshold: 3healthy_threshold: 3tcp_health_check: {}# http_health_checkhost: &amp;#34;servicehost&amp;#34;path: &amp;#34;/health&amp;#34;service_name: &amp;#34;authentication&amp;#34;异常检测: 效果更好一些,可以排除健康检查的短暂异常情况.
# 一般不常用consecutive_5xx: &amp;#34;3&amp;#34;base_ejection_time: &amp;#34;30s&amp;#34;# 基于统计的检查更可靠,需要流量支持interval: &amp;#34;10s&amp;#34;base_ejection_time: &amp;#34;30s&amp;#34;success_rate_minimum_hosts: &amp;#34;10&amp;#34;success_rate_request_volume: &amp;#34;500&amp;#34;success_rate_stdev_factor: &amp;#34;1000&amp;#34; # divided by 1000 to get a double监控/统计/追踪 envoy内置常用的统计,可以访问管理台/stats查看具体metrics. 用于响应统计通常结合Prometheus和Grafana实现,参考这里/Demo代码.
分布式追踪通常结合Jaeger/Zipkin使用, 结合Jaeger的实现参考官方文档沙箱部分或这里.
分流/蓝绿发布/流量复制 Traffic mirroring/shadowing: 用于生产环境服务的验证测试, 镜像功能发送一部分生产流量副本到镜像服务,镜像请求采用fire&amp;amp;forgot模式,响应被丢弃.
可参考:
 官方:流量迁移和分离 流量复制示例  扩展阅读 与其他代理的比较  与其他主流代理的比较 traefik反向代理/负载均衡: Go实现,支持kubernetes编排服务和etcd/consul服务注册  学习资源  Envoy中文文档 kata在线实验环境 基础 learnenvoy: 不再维护  应用  eBay是如何将 Envoy 作为边缘代理的   将硬件负载均衡器替换为软件解决方案,在每个集群的边缘上有一个“north-south”网关，用来管理所有针对外部的传入和传出流量.
</content>
    </entry>
    
     <entry>
        <title>bazel构建工具</title>
        <url>https://xulizhao.com/blog/bazel-build/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>build</tag>
        </tags>
        <content type="html"> Bazel是Google开源的一个构建系统,主要支持分布式缓存和增量编译,使得大项目的构建更快速, 主要用于C&#43;&#43;,Java,Go等服务端项目构建.
有一个与之类似的快速构建系统Buck(Facebook开源)则更关注于Android和iOS客户端的构建. 两者都倾向于mono repo(而非基于项目的仓库)的构建.
之前看了眼官方教程,觉得过于复杂没有引起兴趣. 最近看到在B站代码和envoy都作为标配,所以再做些深入了解.
使用基础 在项目的根目录下创建WORKSPACE和BUILD文件.
工作区/WORKSPACE配置 bazel有工作区的概念, 该文件配置加载bazel环境需要的规则和依赖,可以为空.
### BUILD配置 构建项目信息配置文件,语法类似于python.
java_binary(name = &amp;#34;ProjectRunner&amp;#34;,srcs = [&amp;#34;src/main/java/com/example/ProjectRunner.java&amp;#34;],main_class = &amp;#34;com.example.ProjectRunner&amp;#34;,deps = [&amp;#34;:greeter&amp;#34;],)java_library(name = &amp;#34;greeter&amp;#34;,srcs = [&amp;#34;src/main/java/com/example/Greeting.java&amp;#34;],visibility = [&amp;#34;//src/main/java/com/example/cmdline:__pkg__&amp;#34;],)visibility = level属性改变目标的可见范围, 在上面的例子中需要改变默认当前BUILD的限制,因为用到了其他BUILD配置.
构建命令 bazel build //:ProjectRunner构建后将生成一些输出目录的符号链接,如bazel-bin和bazel-out.
可部署 # 默认不会包含依赖,而采用加入CLASSPATH的方式确保本地可以运行bazel build //src/main/java/com/example/cmdline:runner# jar tf bazel-bin/src/main/java/com/example/cmdline/runner.jar# 如果要求可部署,需要加_deploy后缀bazel build //src/main/java/com/example/cmdline:runner_deploy.jarGo项目构建 WORKSPACE文件 加载Go规则,使用gazelle自动生成/更新BUILD文件.
load(&amp;#34;@bazel_tools//tools/build_defs/repo:http.bzl&amp;#34;, &amp;#34;http_archive&amp;#34;)http_archive(name = &amp;#34;io_bazel_rules_go&amp;#34;,urls = [&amp;#34;https://github.com/bazelbuild/rules_go/releases/download/0.18.5/rules_go-0.18.5.tar.gz&amp;#34;],sha256 = &amp;#34;a82a352bffae6bee4e95f68a8d80a70e87f42c4741e6a448bec11998fcc82329&amp;#34;,)http_archive(name = &amp;#34;bazel_gazelle&amp;#34;,urls = [&amp;#34;https://github.com/bazelbuild/bazel-gazelle/releases/download/0.17.0/bazel-gazelle-0.17.0.tar.gz&amp;#34;],sha256 = &amp;#34;3c681998538231a2d24d0c07ed5a7658cb72bfb5fd4bf9911157c0e9ac6a2687&amp;#34;,)load(&amp;#34;@io_bazel_rules_go//go:deps.bzl&amp;#34;, &amp;#34;go_rules_dependencies&amp;#34;, &amp;#34;go_register_toolchains&amp;#34;)go_rules_dependencies()go_register_toolchains()load(&amp;#34;@bazel_gazelle//:deps.bzl&amp;#34;, &amp;#34;gazelle_dependencies&amp;#34;)gazelle_dependencies()BUILD配置文件 添加
load(&amp;#34;@bazel_gazelle//:def.bzl&amp;#34;, &amp;#34;gazelle&amp;#34;)# 更新为对应项目名gazelle(name = &amp;#34;gazelle&amp;#34;,prefix = &amp;#34;bazeltest&amp;#34;,)生成配置文件
 bazel run //:gazelle
 注: 在我本地测试时,没有自动生成go_binary相关配置, 则需要更新配置如下:
load(&amp;#34;@io_bazel_rules_go//go:def.bzl&amp;#34;, &amp;#34;go_binary&amp;#34;,&amp;#34;go_library&amp;#34;, &amp;#34;go_test&amp;#34;)go_binary(name = &amp;#34;bazeltest&amp;#34;,srcs = [&amp;#34;main.go&amp;#34;],deps = [&amp;#34;:go_default_library&amp;#34;],# embed = [&amp;#34;:go_default_library&amp;#34;],# visibility = [&amp;#34;//visibility:public&amp;#34;],# out = &amp;#34;cmd&amp;#34;, )构建 # // 来表示当前项目的根目录， ... 表示当前路径下所有的包bazel build //...# 指定目标bazel build //cmd/bazeltest扩展阅读  官方教程Java/C&#43;&#43; 使用 Bazel 构建 Golang 项目 用 Bazel / Buck 构建大型项目 </content>
    </entry>
    
     <entry>
        <title>Go依赖库管理初探</title>
        <url>https://xulizhao.com/blog/go-mod/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go作为一个新语言,其依赖管理系统一直不够完善,官方直到去年才在1.11加入modules(也叫vgo). 在此之前社区不满官方的官僚,还有过一阵激烈的讨论,讨论流行第三方库dep的不被采纳而官方自造轮子.
最近在项目首次使用了modules系统,但还是采用的兼容的vendor模式. 总体用下来还不错,一些github库也已经使用该方式.
下面简要列下常见用法.
开启该选项 环境变量设置为开启状态: GO111MODULE=on
set GO111MODULE=on //windowsexport GO111MODULE=on //linux如果使用Goland IDE, 到项目 [settings]-[Go modules(vgo)]- 勾选 &amp;ldquo;Enable Go modules(vgo) integration&amp;rdquo;
使用 主要通过命令 go mod 实现, 具体用法参考 go help mod
常用命令 # 列出当前模块和它的所有依赖库go list -m all lists# 列出详细依赖信息go list -m -json all# 查看某库的可用版本go list -m -versions github.com/BurntSushi/toml# 删除不用的依赖go mod tidy使用vendor管理本项目依赖 注: 需要说明的,这些依赖只包含本项目用到的直接依赖, 第三方库的自身依赖由它本身维护.
# 生成本地依赖go mod vendor# 构建时指定vendorgo build -mod=vendor #或者 GOFLAGS=-mod=环境变量信息语义化版本维护库 semantic import versioning的支持.
# 把模块路径定义为类似 rsc.io/quote/v3 的格式版本管理 vendor目录和go.mod , go.sum文件都应该提交至版本库.
扩展阅读  官方博客介绍 官方wiki介绍 </content>
    </entry>
    
     <entry>
        <title>Go in Action 学习笔记</title>
        <url>https://xulizhao.com/blog/go-in-action/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>go</tag><tag>read</tag>
        </tags>
        <content type="html"> 初学Go时主要读的&amp;lt;Go语言圣经&amp;gt;,正式中文版叫&amp;lt;Go程序设计语言&amp;gt;, 由于当时写的代码还很少,实际上很多是不太懂的或后来也忘了. 之后想读些其他书时,本来想读的&amp;lt;Go编程实战&amp;gt;在豆瓣的评分偏低,便一直没读. 在写过一些代码后,偶然再读这本书,发现其实战意义很高,是很好的一本进阶书. 由此看来豆瓣的评分只能当个参考,需要读读看是不是适合自己.
做了些简单的笔记. 顺便说, 第一作者的Ultimate Go虽然是英文视频,讲的也很好很深入,有需要的可联系我.
读书笔记 Go特点和约定 在Go语言中，所有的变量都以值的方式传递。
命名惯例: 如果接口类型只包含一个方法，那么这个类型的名字以er结尾。
将工厂函数命名为New是Go语言的一个习惯。
因为大部分方法在被调用后都需要维护接收者的值的状态，所以，一个最佳实践是，将方法的接收者声明为指针。
并发 推荐使用WaitGroup(计数信号量)来跟踪goroutine的工作是否完成。
写并发程序的时候，最佳做法是，在main函数返回前，清理并终止所有之前启动的goroutine。
包 所有处于同一个文件夹里的代码文件，必须使用同一个包名。(按惯例,包和文件夹同名)
init函数在main之前执行, init函数用在设置包、初始化变量或者其他要在程序运行前优先完成的引导工作。
可以在指定包的时候使用通配符。3个点表示匹配所有的字符串。
第四章: 数组,切片和映射 主要介绍了集合数据结构:
数组: 长度固定,类型的相同的连续块.
切片: 动态数组
切片之所以被称为切片，是因为创建一个新的切片就是把底层数组切出一部分
slice := make([]int,3,5)slice := []string{&amp;#34;red&amp;#34;,&amp;#34;blue&amp;#34;}//创建有3个元素的整型数组array:=[3]int{10,20,30}//创建长度和容量都是3的整型切片slice:=[]int{10,20,30}nil切片和空切片是两个东西.
 在需要描述一个不存在的切片时，nil切片会很好用。 想表示空集合时空切片很有用  //创建有5个元素的整型数组array:=[5]int{10,20,30,40,50}//创建一个新切片,其长度为2个元素，容量为4个元素newSlice:=slice[1:3]// 生成新切片是限制第三个参数容量和长度一样,避免新切片的append操作改变原底层数组值source:=[]string{&amp;#34;Apple&amp;#34;,&amp;#34;Orange&amp;#34;,&amp;#34;Plum&amp;#34;,&amp;#34;Banana&amp;#34;,&amp;#34;Grape&amp;#34;}slice := source[2:3:3]slice = append(slice,&amp;#34;Kiwi&amp;#34;)// 追加s2的所有值到s1append(s1,s2...) 常用函数:append, cap, len
range 关键字range可以用于迭代数组、字符串、切片、映射和通道。
range迭代切片,返回的第二个值是对应元素值的副本
映射 是存储键值对的无序集合(散列表实现).
常用函数: delete.
将切片或者映射传递给函数成本很小，并且不会复制底层的数据结构。
第五章: 类型系统 使用组合设计模式,复用其他类型的功能. 一个类型通常由其他更小的类型组合而(避免使用复杂的继承模型).
关键字func和函数名之间的参数被称作接收者，将函数与接收者的类型绑在一起。如果一个函数有接收者，这个函数就被称为方法。
值接收者使用值的副本来调用方法，而指针接受者使用实际值来调用方法。
 内置(原始)类型: 数值类型(整型,浮点型),字符串类型,布尔类型 引用类型: 切片,映射,通道,接口,函数类型  类型的本质 大多数情况下,结构类型的本质是非原始的,需要使用指针来共享这个值.
类型的值具备非原始的本质，所以总是应该被共享，而不是被复制。
是使用值接收者还是指针接收者，不应该由该方法是否修改了接收到的值来决定。这个决策应该基于该类型的本质。 这条规则的一个例外是，需要让类型值符合某个接口的时候，即便类型的本质是非原始本质的，也可以选择使用值接收者声明方法。这样做完全符合接口值调用方法的机制。
因为不是总能获取一个值的地址，所以值(Value)的方法集(Method Receivers)只包括了使用值接收者实现的方法。
接口 是声明了一组行为并支持多态的类型。
接口允许对行为(而不是类型)建模. Go的接口更小,只倾向于定义一个单一的动作.
如果要让一个用户定义的类型实现一个接口，这个用户定义的类型要实现接口类型里声明的所有方法。
嵌入类型 嵌入类型提供了扩展类型的能力，而无需使用继承。
嵌入类型是将已有的类型直接声明在新的结构类型里。被嵌入的类型被称为新的外部类型的内部类型。
由于内部类型的提升，内部类型实现的接口会自动提升到外部类型。如果外部类型实现了notify方法，内部类型的实现就不会被提升。
扩展阅读  书籍配套代码 作者博客 Ultimate Go 培训 文档 /大纲 </content>
    </entry>
    
     <entry>
        <title>Python高性能技巧</title>
        <url>https://xulizhao.com/blog/python-performance/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 数据结构使用技巧 列表 在列表中检查是否存在某个值远比字典和集合速度慢，因为Python是线性搜索列表中的值，但在字典和集合中，在同样的时间内还可以检查其它项（基于哈希表）。
append vs insert 与append相比，insert耗费的计算量大，因为对后续元素的引用必须在内部迁移，以便为新元素提供空间。
如果要在序列的头部和尾部插入元素，你可能需要使用collections.deque，一个双尾部队列。
串联和组合 通过加法将列表串联的计算量较大，因为要新建一个列表，并且要复制对象。用extend追加元素，尤其是到一个大列表中，更为可取。
bisect 如果列表项很多,且需要保持排序,更高效.
bisect模块支持二分查找，和向已排序的列表插入值。
前提: 列表已排序.即对未排序的列表使用bisect不会产生错误,但结果不一定正确.
工具  VMProf  Profiler SnakeViz: An in-browser Python profile viewer line_profile Memory Profiler vprof: 可视化profiler gperftools : Google Performance Tools pdb&#43;&#43;  </content>
    </entry>
    
     <entry>
        <title>工作工具箱</title>
        <url>https://xulizhao.com/blog/toolbox/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 在工作中经常会用到各种工具，但重装系统或换机器后经常忘了软件名字。
工欲善其事，必先利其器。因为工具/软件，计算机才如此强大。
开发工具 说明: paid(付费)、win(仅Windows平台)、mac(仅Mac平台)
通用  Git版本管理  Github Desktop SourceTree KDiff3 : 差异比较   文档浏览  Dash - 最好用(Mac) Zeal - 接口文档    Python  PyCharm : IDE  Go  Goland : IDE  Java  IntelJ IDEA : IDE  Profiler
 YourKit (paid)  大前端  Android Studio  数据处理 数据库  DataGrip : 全数据库客户端 MySQL Workbench PGAdmin 4 DB Browser for SQLite Redis Desktop Manager  数据科学  Octave  综合类  d-tools ： 基于Electron开发的跨平台工具集 Dadroit Json Viewer  测试/调试工具 接口测试  Postman ：最常用的此类工具，要善用变量{{server}} Restlet Client - REST API Testing : 功能同上  网络分析  Fiddler （win） Wireshark Burp Suite  正则  Kodos - Python调试工具  Chrome  Chrome Developer Tools : 快捷键 F12/Ctrl&#43;Shift&#43;I Extensions  有道词典Chrome划词插件 Evernote Web Clipper Save to Pocket Base64 Encode and Decode JSONView Web Developer CSS Selector Helper for Chrome Proxy SwitchyOmega ： 设置代理 Screencastify - Screen Video Recorder ： 录屏 Fireshot - Take Webpage Screenshots Entirely : 截屏 Seo Enable Copy ： 允许复制   Apps  FastString - 字符处理工具箱：base64/hash/encoder/generator JSON Editor Cookies： Cookie编辑器 JADE - JAvascript based Database Editor： sqlite 客户端    运维  Bitvise SSH Client Filezilla Client : FTP SecureCRT (paid)  部署  XAMPP - 一体化PHP环境  效率类  印象笔记/Evernote : 配合Chrome插件使用 Pomotodo：番茄工作法 XMind ： 脑图  产品工具 项目工具  画图  yED Graph Editor Astah Community Modelio    系统工具  7-zip: 压缩/解压必备 Everything: 文件检索（Windows必备） Free Download Manager : 多线程下载 Dukto R6 : 多机器共享 Bulk Rename Utility Synergy : 多机共享键盘 TreeSize Free :磁盘文件大小统计  编辑器  Sublime Text VS Code Notepad&#43;&#43; Typora : markdown editor TeX Live - TeX IDE  手机  Hand Shaker: 安卓文件管理  多媒体处理  截屏录屏  Snipaste: 图像截屏 OBS Studio : 屏幕视频录制   PotPlayer: 视频播放 Audacity : 音频处理 IrfanView : 图形浏览 paint.net : 图像编辑 Any Video Converter： 视频格式转换 RMVB Converter  电子书  Calibre : 电子书管理 Kindle Previewer 3 Kindle Mate Sigil EpubSTAR </content>
    </entry>
    
     <entry>
        <title>Django再记录</title>
        <url>https://xulizhao.com/blog/django/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag><tag>web</tag>
        </tags>
        <content type="html"> Django作为python web开发第一框架,很早就有所了解, 上次使用是在3年多之前. 作为全栈框架来说,是个很优秀的框架.
据我所知Instagram,Mozilla等高流量/大公司都在使用.
之前几个项目特意使用了以轻量著称的Flask,两者算是各有千秋吧.
去年Django2.0推出后一直想尝试,正好最近拿来试试.
用下来感觉简化部署和可定制化相比之前改观很多,做下简要笔记.
manage.py命令行工具 Django的工具真的好用很多.
# 创建项目mysitedjango-admin startproject mysite# 运行开发服务器,也可指定IP/端口# python manage.py runserver 0:8000python3 manage.py runserver# 指定配置 --settings SETTINGS# 创建应用python3 manage.py startapp polls# 创建超级管理员python3 manage.py createsuperusershell交互式命令行 python3 manage.py shell升级/migration # 为 INSTALLED_APPS 创建必要的数据表python3 manage.py migrate# makemigrations命令会检测对模型的修改并生成迁移文件,位于migrations文件夹python3 manage.py makemigrations polls开发基础 提倡开发可重用的app, 主要基于Model/View/URL 模式.
App 添加应用
# mysite/settings.pyINSTALLED_APPS = [&amp;#39;polls.apps.PollsConfig&amp;#39;,# polls/app.py# verbose_name 对应页面显示名称class PollsConfig(AppConfig):name = &amp;#39;Polls&amp;#39;verbose_name = &amp;#39;My Polls&amp;#39;Model # polls/models.pyclass Poll(models.Model):name = models.CharField(max_length=256, verbose_name=&amp;#39;Poll Name&amp;#39;)created = models.DateTimeField(auto_now_add=True)updated = models.DateTimeField(auto_now=True)class Meta:verbose_name = &amp;#39;Poll Display Name&amp;#39;View # polls/views.pyfrom django.shortcuts import render,redirectfrom django.http import HttpResponsefrom django.contrib.auth.decorators import login_required# @login_requireddef index(request):return HttpResponse(&amp;#34;Welcome.&amp;#34;)添加路由/urls 注: Django2.x里的re_path() 等价于之前的url()
# mysite/urls.pyurlpatterns = [path(&amp;#39;polls/&amp;#39;, include(&amp;#39;polls.urls&amp;#39;)),path(&amp;#39;admin/&amp;#39;, admin.site.urls),Admin定制 添加model到Admin # polls/admin.pyclass PollsAdmin(admin.ModelAdmin):list_display = (&amp;#39;name&amp;#39;,&amp;#39;updated&amp;#39;)search_fields = [&amp;#39;name&amp;#39;]fieldsets = [(None, {&amp;#39;fields&amp;#39;: [&amp;#39;name&amp;#39;]}),]admin.site.register(Polls, PollsAdmin)丰富显示 # 自定义list_filterfrom django.contrib.admin import SimpleListFilter内置关联: InlineModelAdmin 的两个子类TabularInline和StackedInline
修改Admin显示 # mysite/urls.py# 以最简方式修改标题等admin.site.site_header = &amp;#39;Test header&amp;#39;admin.site.site_title = &amp;#39;Test title&amp;#39;admin.site.index_title = &amp;#39;Test index&amp;#39;Admin功能扩展 高级功能定制经常用到的类:
django.contrib.admin.sites.AdminSitedjango.contrib.admin.options.ModelAdmindjango.forms.models.ModelFormdjango.contrib.admin.options.InlineModelAdmindjango.forms.formsets 模板 在项目文件夹创建templates存放模板文件
# settings.pyTEMPLATE_DIR = os.path.join(BASE_DIR, &amp;#39;templates&amp;#39;)TEMPLATES = [{&amp;#39;BACKEND&amp;#39;: &amp;#39;django.template.backends.django.DjangoTemplates&amp;#39;,&amp;#39;DIRS&amp;#39;: [TEMPLATE_DIR],...常用模板:
admin/base.htmladmin/index.htmladmin/change_form.htmladmin/change_list.html 可重载模板:
基于项目的: admin/change_form.html基于app的: admin/&amp;lt;my_app&amp;gt;/change_form.html基于模型的: admin/&amp;lt;my_app&amp;gt;/&amp;lt;my_model&amp;gt;/change_form.html 要点:
 使用extend而不是 重载/override 使用 {{ block.super }} 扩展 blocks 如果涉及模板的递归,使用软链接的方式 在base.html扩展全局通用块  配置 配置文件 指定配置文件: 用 DJANGO_SETTINGS_MODULE环境变量
# 在Python代码中使用settings # settings是对象而非模块，不要运行时修改 from django.conf import settings 邮件配置 # 设置邮件后端为Console用于测试目的 # EMAIL_BACKEND = &amp;#39;django.core.mail.backends.console.EmailBackend&amp;#39; EMAIL_HOST = &amp;#39;smtp.exmail.qq.com&amp;#39;EMAIL_PORT = &amp;#39;465&amp;#39;EMAIL_HOST_USER = &amp;#39;demo@xulizhao.com&amp;#39;EMAIL_HOST_PASSWORD = &amp;#39;xxxxxxxx&amp;#39;EMAIL_USE_SSL = TrueDEFAULT_FROM_EMAIL = &amp;#39;demo@xulizhao.com&amp;#39;部署 总体使用Nginx&#43;gunicorn&#43;wsgi的方式部署生产环境.
生产环境一定要修改settings.py为DEBUG = False
静态文件 # settings.pySTATIC_ROOT = &amp;#39;/home/xulz/www/mysite/static/&amp;#39;之后运行
# 首次部署运行# 或静态文件更新后运行./manage.py collectstaticgunicorn 之前用Apache&#43;wsgi的方式部署,相对麻烦. 这次直接使用gunicorn, 简单到再也不想提Apache.
# -D 常驻进程# -b 可指定IP/端口# -w 8 可指定worker进程数gunicorn -D mysite.wsgi --log-file=log.txt --access-logfile=access.log --log-level=infoNginx server {listen 8000;server_name localhost;location / {proxy_pass http://127.0.0.1:8000;proxy_set_header X-Forwarded-For $remote_addr;proxy_set_header Host $http_host;}location /static {autoindex on;alias /home/xulz/www/mysite/static;}}链接 官方文档:
 多语言 设计理念  第三方应用:
 django-registration / 使用教学 django-mptt 树状遍历库 Celery Periodic Tasks backed by the Django ORM Viewflow  工作流库 DjangoPackages: 第三方app扩展汇总网站  主题定制：
 Material Design for Django [Customizing the Django Admin] (http://lincolnloop.com/static/slides/2010-djangocon/customizing-the-admin.html) Slide Django Grappelli 后台定制皮肤  扩展阅读:
 Django Debug Toolbar The Ultimate Guide to Django Redirects  其他:
 gunicorn po文件编辑 </content>
    </entry>
    
     <entry>
        <title>Mindset读书笔记</title>
        <url>https://xulizhao.com/blog/mindset/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> Mindset是一本讲思维模式的书,作者是斯坦福大学心理学教授, 与其说这是一本心理学或成功学著作, 更重要的这是一本很好的教育理念的书, 当然对于个人的成长也是很有帮助的.
好多年前看到有人推荐这边书,当时只知道英文名字,英文版读起来也很慢. 后来才知道原来已有中译版, 人邮的&amp;lt;心理定向与成功 &amp;gt;,中信的&amp;lt;看见成长的自己 &amp;gt;和最新后浪的&amp;lt;终身成长&amp;gt;其实都是这本书. 之前只看了开头几章, 也许好书你很难错过,因为总会看到有人推荐,于是最近开始继续阅读.
概要 本书以作者10多年的研究表明我们获得的成功并不是能力和天赋决定的，更受到我们在追求目标的过程中展现的思维模式的影响。
我们通常具有两种思维模式中的一种：固定型或成长型，它们体现了应对成功与失败、成绩与挑战时的两种基本心态。
你认为才智和努力哪个重要，能力能否通过努力改变，决定了你是会满足于既有成果还是会积极探索新知。只有用正确的思维模式看待问题，才能更好地达成人生和职业目标。
通过了解自己的思维模式并做出改变，人们能以最简单的方式培养对学习的热情，和在任何领域内取得成功都需要的抗压力。
两种思维模式 要培养自己/儿童具有成长型思维模式,改变原来的固定型思维模式.
理念(前提) 固定型: 相信自己的才能是一成不变的
成长型: 能力是可以通过你的努力来培养的
生活态度(对待烦心事) 固定型: 把发生的事当作一个衡量自己的能力和价值的直接标尺
成长型: 不会给自己贴上标签,或对自己失去信心.即使感到沮丧,也准备好去承担风险,直面挑战,继续为此奋斗
对结果的态度 固定型: 所有的一切都是为了结果.
成长型: 享受过程带来的乐趣.
对于挫折和失败
固定型: 认为没有能力做好,需要另辟蹊径. 不会从失败中学习并纠正自己的失败,相反,可能只是去尝试修复自尊(找借口).
成长型: 更努力的学习和付出
成功的意义
固定型: 希望能够确保自己的成功,认为聪明的人应该永远是成功的 (不想暴露不足)
成长型: 成功意味着拓展自己的能力范畴,变得越来越聪明 (捉住机会学习)
对努力的认识 固定型: 如果需要为某事付出努力,是自己不擅长做某事. 害怕努力后依然失败.
成长型: 天才也要通过努力达到成功,努力才能激发能力.
成长型思维模式 想达成重要成就需要明确的关注点,全身心的努力,无穷无尽的策略,还有学习中的同伴.
掌握学习过程和动力,在学习方面愿意尝试各种不同的方法. (兴趣或者好奇心是主要驱动力)
爱上自己做的事,即使面对困难也会继续热爱.有时投入一件事情,恰恰是因为不擅长做这件事.
寻求挑战,挑战越大,成长空间就越大.在拓展自己的过程中感到兴奋不已.
固定型思维模式 TBC.
</content>
    </entry>
    
     <entry>
        <title>用kubeadm手动搭建Kubernetes集群</title>
        <url>https://xulizhao.com/blog/kubeadm/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag>
        </tags>
        <content type="html"> 用kubespray基于Ansible自动化工具搭建集群是很方便,但是一旦遇到问题查起来经常找不到头绪,因为不知所以然.
所以回归本源,用官方提供的kubeadm一步步建立一个单主的集群,可以让我们更容易弄清它的部署架构.
这也是此文/这次实践的目的所在.
前提条件 禁用swap sudo swapoff -a# 永久性禁用# 编辑/etc/fstab并注释掉swap那一行保留端口 Master节点
   组件 端口 注释     API server 6443 可重新定义   etcd 2379-2380    Kubelet API 10250    kube-scheduler 10251    kube-controller-manage 10252     注: 2 CPU&#43;
Worker节点
   组件 端口 注释     Kubelet API 6443    NodePort Services 30000-32767 可重新定义    Docker 容器运行时默认使用docker
安装说明 kubeadm, kubelet, kubectl  kubeadm: 集群引导命令行 kubelet: 集群每个节点都有(Node Agent),用于启动Pod/容器等 kubectl: 交互式集群管理命令行  注: kubelet的版本号不应该超过API server
# Ubuntuapt-get update &amp;amp;&amp;amp; apt-get install -y apt-transport-https curlcurl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.listdeb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial mainEOFapt-get updateapt-get install -y kubelet kubeadm kubectlapt-mark hold kubelet kubeadm kubectlkubeadm init # 可以先运行下面命令检查到gcr.io的连接性# kubeadm config images pull# 解决etcd pull失败的问题docker pull xulz/coreos-etcd:v3.2.24docker tag xulz/coreos-etcd:v3.2.24 gcr.mirrors.ustc.edu.cn/google-containers/etcd:3.2.24kubeadm init --kubernetes-version=v1.13.1 --image-repository=gcr.mirrors.ustc.edu.cn/google-containers --pod-network-cidr=192.168.0.0/16# --image-repository 指定镜像mirror,默认k8s.gcr.io# 也可以通过配置文件的形式 imageRepository: &amp;lt;private-registry&amp;gt;# root用户运行 export KUBECONFIG=/etc/kubernetes/admin.conf# 记录下关于 kubeadm join的输出用于添加节点注: token用户master和加入节点间的双向认证,需保密. 也可用 kubeadm token命令管理token.
# kubelet环境变量# /var/lib/kubelet/kubeadm-flags.env# kubelet配置文件# /var/lib/kubelet/config.yaml安装Pod网络插件 pod networking provider
这里使用的CNI network plugin是Calico,它需要提供CIDR(默认使用192.168.0.0/16), 已经在上步的init提供.
# 先获取本地镜像并tagdocker pull xulz/calico-node:v3.3.2docker tag xulz/calico-node:v3.3.2 quay.io/calico/node:v3.3.2docker pull xulz/calico-cni:v3.3.2docker tag xulz/calico-cni:v3.3.2 quay.io/calico/cni:v3.3.2docker pull quay.mirrors.ustc.edu.cn/calico/typha:v3.3.2docker tag quay.mirrors.ustc.edu.cn/calico/typha:v3.3.2 quay.io/calico/typha:v3.3.2以Calico为例:
kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yamlkubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml# 检查状态, CoreDNS pod应该已经运行kubectl get pods --all-namespaces添加节点 kubeadm join --token &amp;lt;token&amp;gt; &amp;lt;master-ip&amp;gt;:&amp;lt;master-port&amp;gt; --discovery-token-ca-cert-hash sha256:&amp;lt;hash&amp;gt;# 获取tokenkubeadm token list# 获取 --discovery-token-ca-cert-hash的值openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&amp;gt;/dev/null | \ openssl dgst -sha256 -hex | sed &amp;#39;s/^.* //&amp;#39;# 检查状态kubectl get nodes 删除节点/清除 在Master节点执行
kubectl drain &amp;lt;node name&amp;gt; --delete-local-data --force --ignore-daemonsetskubectl delete node &amp;lt;node name&amp;gt;在要删除的节点执行:
# 重置状态kubeadm reset# 清理iptablesiptables -F &amp;amp;&amp;amp; iptables -t nat -F &amp;amp;&amp;amp; iptables -t mangle -F &amp;amp;&amp;amp; iptables -X参考 kubeadm 命令参考 # 输出默认配置kubeadm config print# 输出指定api对象kubeadm config print-default --api-objects KubeletConfiguration# 列出/获取kubeadm需要的容器镜像kubeadm config images listkubeadm config images pull# 指定版本, 跳过该地址的检查 https://dl.k8s.io/release/stable-1.txt--kubernetes-version=v1.13.1# --config指定配置文件kubeadm init --config kubeadm-config.yamlkubelet配置 init阶段
 /var/lib/kubelet/config.yaml : 同时上传至kubelet-config-1.X的ConfigMap /etc/kubernetes/kubelet.conf : 存储客户端证书用于和API Server通讯 /var/lib/kubelet/kubeadm-flags.env : 实例特定的信息及cgroup driver,CRI runtime socket  join阶段
 读取ConfigMap并写入/var/lib/kubelet/config.yaml /etc/kubernetes/bootstrap-kubelet.conf 包含CA 证书和Bootstrap Token. 读取上步的文件生成/etc/kubernetes/kubelet.conf  systemd使用的配置
/etc/systemd/system/kubelet.service.d/10-kubeadm.conf
kubeadm init 输出日志 [init] Using Kubernetes version: v1.13.1[preflight] Running pre-flight checks[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using &amp;#39;kubeadm config images pull&amp;#39;[kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;[kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder &amp;#34;/etc/kubernetes/pki&amp;#34;[certs] Generating &amp;#34;front-proxy-ca&amp;#34; certificate and key[certs] Generating &amp;#34;front-proxy-client&amp;#34; certificate and key[certs] Generating &amp;#34;etcd/ca&amp;#34; certificate and key[certs] Generating &amp;#34;etcd/server&amp;#34; certificate and key[certs] etcd/server serving cert is signed for DNS names [xulz-master1 localhost] and IPs [192.168.10.1 127.0.0.1 ::1][certs] Generating &amp;#34;etcd/peer&amp;#34; certificate and key[certs] etcd/peer serving cert is signed for DNS names [xulz-master1 localhost] and IPs [192.168.10.1 127.0.0.1 ::1][certs] Generating &amp;#34;apiserver-etcd-client&amp;#34; certificate and key[certs] Generating &amp;#34;etcd/healthcheck-client&amp;#34; certificate and key[certs] Generating &amp;#34;ca&amp;#34; certificate and key[certs] Generating &amp;#34;apiserver&amp;#34; certificate and key[certs] apiserver serving cert is signed for DNS names [xulz-master1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.10.1][certs] Generating &amp;#34;apiserver-kubelet-client&amp;#34; certificate and key[certs] Generating &amp;#34;sa&amp;#34; key and public key[kubeconfig] Using kubeconfig folder &amp;#34;/etc/kubernetes&amp;#34;[kubeconfig] Writing &amp;#34;admin.conf&amp;#34; kubeconfig file[kubeconfig] Writing &amp;#34;kubelet.conf&amp;#34; kubeconfig file[kubeconfig] Writing &amp;#34;controller-manager.conf&amp;#34; kubeconfig file[kubeconfig] Writing &amp;#34;scheduler.conf&amp;#34; kubeconfig file[control-plane] Using manifest folder &amp;#34;/etc/kubernetes/manifests&amp;#34;[control-plane] Creating static Pod manifest for &amp;#34;kube-apiserver&amp;#34;[control-plane] Creating static Pod manifest for &amp;#34;kube-controller-manager&amp;#34;[control-plane] Creating static Pod manifest for &amp;#34;kube-scheduler&amp;#34;[etcd] Creating static Pod manifest for local etcd in &amp;#34;/etc/kubernetes/manifests&amp;#34;[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &amp;#34;/etc/kubernetes/manifests&amp;#34;. This can take up to 4m0s[apiclient] All control plane components are healthy after 21.502262 seconds[uploadconfig] storing the configuration used in ConfigMap &amp;#34;kubeadm-config&amp;#34; in the &amp;#34;kube-system&amp;#34; Namespace[kubelet] Creating a ConfigMap &amp;#34;kubelet-config-1.13&amp;#34; in namespace kube-system with the configuration for the kubelets in the cluster[patchnode] Uploading the CRI Socket information &amp;#34;/var/run/dockershim.sock&amp;#34; to the Node API object &amp;#34;xulz-master1&amp;#34; as an annotation[mark-control-plane] Marking the node xulz-master1 as control-plane by adding the label &amp;#34;node-role.kubernetes.io/master=&amp;#39;&amp;#39;&amp;#34;[mark-control-plane] Marking the node xulz-master1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: r4p7.6fuglhjtitmb[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the &amp;#34;cluster-info&amp;#34; ConfigMap in the &amp;#34;kube-public&amp;#34; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user:mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &amp;#34;kubectl apply -f [podnetwork].yaml&amp;#34; with one of the options listed at:https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root:kubeadm join 192.168.10.1:6443 --token r4p7.6fuglhjtitmb --discovery-token-ca-cert-hash sha256:12345660bf8a5ff727b3563a4be19abee27785fcc806bbf2e20f82a15a82be06添加节点输出日志 [preflight] Running pre-flight checks[discovery] Trying to connect to API Server &amp;#34;192.168.10.1:6443&amp;#34;[discovery] Created cluster-info discovery client, requesting info from &amp;#34;https://192.168.10.1:6443&amp;#34;[discovery] Requesting info from &amp;#34;https://192.168.10.1:6443&amp;#34; again to validate TLS against the pinned public key[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &amp;#34;192.168.10.1:6443&amp;#34;[discovery] Successfully established connection with API Server &amp;#34;192.168.10.1:6443&amp;#34;[join] Reading configuration from the cluster...[join] FYI: You can look at this config file with &amp;#39;kubectl -n kube-system get cm kubeadm-config -oyaml&amp;#39;[kubelet] Downloading configuration for the kubelet from the &amp;#34;kubelet-config-1.13&amp;#34; ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;[kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;[kubelet-start] Activating the kubelet service[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...[patchnode] Uploading the CRI Socket information &amp;#34;/var/run/dockershim.sock&amp;#34; to the Node API object &amp;#34;xulz-node1&amp;#34; as an annotationThis node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run &amp;#39;kubectl get nodes&amp;#39; on the master to see this node join the cluster.文章列表  Installing kubeadm Creating a single master cluster with kubeadm *Creating a Custom Cluster from Scratch </content>
    </entry>
    
     <entry>
        <title>再提镜像站的使用</title>
        <url>https://xulizhao.com/blog/mirror/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>python</tag>
        </tags>
        <content type="html"> 把时间花在下载软件或必须翻过去访问外部网络是让人苦恼的一件事, 镜像站能很好地解决一些问题.
最早时使用Ubuntu国内镜像加速软件更新,后来使用豆瓣的pypi镜像安装Python包,因为之前的pypi站实在太慢,经常超时.
最近用Docker和Kubernetes就不得不使用镜像站,之前用阿里的较多.
其实还有两个很好的国内镜像站就是清华TUNA和中国科大镜像开源站.
这两个站点基本包括了常用的软件开发工具和环境等,举例如下:
 Linux发行版: Ubuntu,CentOS 安装镜像及软件仓库 Python: Anaconda,pypi,saltstack Docker CE Grafaba,InfluxData MySQL,PostgreSQL,Percona,MongoDB Apache各项目 Cygwin, VirtualBox, Adobe开源字体 Homebrew, MacPort Elastic Stack, Gitlab Android: AOSP Tex: CTAN  官方还提供了一个python脚本,方便本地环境一键使用.
wget https://tuna.moe/oh-my-tuna/oh-my-tuna.pypython oh-my-tuna.py科大的补充:
 Nginx Golang Kubernetes的gcr.io和quay.io (此处给科大的同学一个大大的👍)  Kubernetes的使用说明
# gcr.io/namespace/image_name:image_tag # 替换为# gcr.mirrors.ustc.edu.cn/namespace/image_name:image_tag gcr.mirrors.ustc.edu.cn/kubernetes-helm/tiller# Kubernetes官方教程经常用到k8s.gcr.io, # 相应的 k8s.gcr.io 等同于 gcr.io/google-containers/# 因此 k8s.gcr.io/busybox 等价于gcr.mirrors.ustc.edu.cn/google-containers/busybox# quay.io/calico/cni 替换为quay.mirrors.ustc.edu.cn/calico/cniP.S: 之前我使用的镜像已停止维护,参考这里.
[update]
再补一个: 阿里开源镜像站
</content>
    </entry>
    
     <entry>
        <title>书法与文字</title>
        <url>https://xulizhao.com/read/shufa/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> 最近随着对国学和唐文化的喜爱,开始重新拾起毛笔找一点空隙时间练字.
之前拿毛笔应该是上小学期间了,印象比较深的时写的字没有一个被标红圈的(写的好),也打击了当时学习的热情. 毕业后也尝试改进自己写字的优美程度(写好字一直是我的一个痛点),多年前从图书大厦买了田英章的硬笔行书技法,当时不得要领只是摹写,加上硬笔练得少后来便荒废了.
幸运的时现在互联网知识传播已很发达,于是通过知乎/公众号/电子书/视频做了简单的系统认知, 因此学起来也算走了些捷径. 同事推荐的&amp;lt;田蕴章每日一题每日一字&amp;gt;也让我受益良多.
毛笔比硬笔的好处是仪式感更强, 对写字的认识和要求体会也更深. 重要的是功利心态比较轻,更多作为放松身心的方式.
最近在读的&amp;lt;极简中国书法史&amp;gt;(刘涛著)也让我对书法的历史有了更深的了解, 更能理解中国文字本身和书写之美.
从看到鸟兽在雪地的脚印得到灵感创造文字,到最初时的象形会意无不传神, 再到后面各书体的发展.
大篆到小篆到汉隶的化繁为简,隶书发展至行草的由静到动的变化之美,到现在第一书体楷书的端庄之美.
(最开始不理解篆体现代的意思,了解后才知道不学习篆体你就不知道汉字的渊源,比如有/右的第一笔撇画为什么开始经常见到短横)
顺便说, 五四运动之后提倡白话文,解放后废除繁体字,这些对于文字书写虽然不利,但不能成为我们不学习文言文和繁体字的理由.
书法作为国学的一部分, 无疑国学这个宝库应该被更多国人发现和开发.
自己是从欧楷学起的,也许需要很长一段时间才能看到成果, 计划之后再学颜柳赵诸大家,作为一个长久的爱好吧.
</content>
    </entry>
    
     <entry>
        <title>利器之iTerm2</title>
        <url>https://xulizhao.com/blog/iterm2/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>mac</tag>
        </tags>
        <content type="html"> 平时用的最多的系统是Windows10和Ubuntu,如果说苹果系统MacOS有什么让我离不开的特性的话,iTerm2绝对排第一.
可这个经常使用的免费终端居然有一些我不知道的好用功能,特记录与此.
友好特性 Split Panels 我经常用到tmux,居然忽视了该功能.
右键就可以看到.
快捷键: Cmd&#43;d 垂直分割/ Cmd&#43;Shift&#43;d 水平分割
Autocomplete Cmd &#43; ;调出自动提示.
Paste History Cmd &#43; Shift &#43; h
[Preferences]-[General]-&amp;ldquo;Magic&amp;rdquo;-&amp;ldquo;&amp;ldquo;Save copy/paste and command history to disk&amp;rdquo;
选中即复制 支持鼠标和查找模式(Cmd&#43;f)的Tab复制
系统热键调出 Hotkey实现类似Linux中Yakuake功能.
[Preferences]-[Keys]中设置.
常用快捷键 Cmd&#43;w : 关闭窗口/面板
</content>
    </entry>
    
     <entry>
        <title>LaTeX生成PDF实践</title>
        <url>https://xulizhao.com/blog/latex/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>document</tag>
        </tags>
        <content type="html"> LaTeX最广泛的用途应该是在学术领域写论文, 其实在排版(尤其公式,格式)上也胜过Word很多,绝对专业.
最近为了在本地生成一个PDF,做了一些了解.
简介 TeX -&amp;gt; LaTeX -&amp;gt; XeLaTex
XeLaTeX 是基于TeX的一个专业排字系统, 对于Unicode 和 OpenType字体的支持很好. 可以用来创建好看的PDF文档.
编辑器和编译 TeXLive应该是第一选择,文件安装包有点大(3个G),推荐在清华开源镜像下载.
 TexLive Windows TexLive Mac - MacTex  不推荐使用BasicTeX/安装依赖包 最初我使用了简易版的BasicTeX, 使用起来很繁琐,需要安装大量的包/样式.
如果直接安装TextLive Full可忽略该阶段.
# 在使用前需要先更新PATHexport PATH=/usr/local/texlive/2018basic/bin/x86_64-darwin:$PATH# 使用包管理工具 tlmgrsudo tlmgr update --self --repository http://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnetsudo tlmgr install latexmk --repository http://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnetsudo tlmgr install ctex# 其他常用依赖cjk cjkpunct zhnumber environ trimspaces subfigure multirow tocbibind placeins datatool解决错误
# 如果遇到类似下列错误# LaTeX Error: File `ctexbook.cls&amp;#39; not found# LaTeX Error: File &amp;#39;&amp;#39;picins.sty&amp;#39;&amp;#39; not Found# 安装相应包sudo tlmgr install picins对Mac来说文件安装在/usr/local/texlive/2018basic/texmf-dist/tex/latex/, 因此也可以通过创建文件夹, 把样式复制到相应文件夹, 或者直接复制到文档目录下.
资源链接
 algorithms包 BasicTeX安装说明  生成PDF文档 安装完TexLive后, 打开TeXworks, Typeset选择XeLateX
中文排版 涉及中文一般会用到CTeX宏包
CTeX-kit 是一系列 TeX/LaTeX/ConTeXt 宏包的集合, 相关脚本和资源文件, 主要针对中文TeX用户.
中文字体 .tex文件配置
\setCJKmainfont[AutoFakeBold=true]{AdobeSongStd-Light}\setCJKsansfont{AdobeHeitiStd-Regular}\setCJKmonofont{AdobeFangsongStd-Regular}中易宋体(SimSun)和华文宋体(STSong)分别是 Windows 和 Mac OS X 默认的简体中文宋体.
通常也会用到Adobe中文字体,可到以下网址下载:
 字体库下载 fontsmarket  # 查看当前系统中文字体# Mac直接使用系统的Font Book/字体册# 找到对应字体按Command&#43;i键,就会显示字体的详细信息,postScript即字体名fc-list;lang=zh-cn扩展阅读  ctan官方包仓库 Travis-CI与Latex构建开源中文PDF 中科大论文模板 </content>
    </entry>
    
     <entry>
        <title>Kubernetes命名空间的应用</title>
        <url>https://xulizhao.com/blog/k8s-namespace/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag>
        </tags>
        <content type="html"> 在实际应用中存在一个Kubernetes集群中多个部署环境的问题,比如存在dev,qa,stage等.
如果部署在一个集群会省去不少运维成本且节省资源占用.
通常这会用到命名空间的特性.
Namespaces 命名空间 命名空间可以被看做virtual cluster/虚拟集群.
默认存在default和kube-system两个命名空间.
用户的普通应用默认是在default下，与集群管理相关的为整个集群提供服务的应用一般部署在kube-system的namespace下.
创建新的命名空间
namespace-dev.yml
kind:NamespaceapiVersion:v1metadata:name:dev-spacelabels:name:dev-space kubectl create -f namespace-dev.yml
 kubectl get ns# 指定命名空间kubectl -n &amp;lt;namespace&amp;gt;kubectl get services —namespace=&amp;lt;my-space&amp;gt;给命名空间指派context/上下文 一旦切换上下文, kubectl命令的执行(增改删)会在该命名空间运行.
# 绑定命名空间和上下文的关系kubectl config set-context dev --namespace=dev --cluster=minikube --user=minukube# 切换到Dev contextkubectl config use-context dev# 核实当前contextkubectl config current-context# Delete dev namespacekubectl delete namespaces dev扩展阅读  Dynamic Environments with Kubernetes Gitlab和Kubernetes做集成部署 </content>
    </entry>
    
     <entry>
        <title>Python发布</title>
        <url>https://xulizhao.com/blog/python-release/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> Python库的打包,发布,分发.
打包  Source Distribution/sdist: setuptools用来制作源码分发 bdist_wheel扩展用来创建wheels(可包含二进制扩展库) twine发布到pypi  # 前提pip install wheel twine# 打成发布包python setup.py sdist bdist_wheel# twine 发布twine upload --repository-url http://10.100.220.103:6543/ dist/*setup.py setup.py里的entry_points会最终生成entry_points.txt并存放在EGG-INFO文件夹．
entry point一般是一个可调用函数，方便命令行调用．
python setup.py --help-commands# 打包wheelpython setup.py bdist_wheel -d TARGET# 上传本地python3 setup.py bdist_wheel upload -r dev一个setup.py的例子：
from setuptools import setup, find_packagesimport osfrom os.path import dirnamehere = os.path.abspath(dirname(__file__))required = []setup(name=&amp;#39;loads&amp;#39;,version=&amp;#39;1.0.0&amp;#39;,description=&amp;#39;Test Project.&amp;#39;,packages=find_packages(exclude=[&amp;#39;tests&amp;#39;]),packages=[&amp;#39;locust&amp;#39;, &amp;#39;locust.rpc&amp;#39;, &amp;#39;locust.rpc&amp;#39;, &amp;#39;locust.templates&amp;#39;],include_package_data=True,zip_safe=False,tests_require=[&amp;#39;unittest2&amp;#39;, &amp;#39;mock&amp;#39;],install_requires=required,entry_points={&amp;#39;console_scripts&amp;#39;: [&amp;#39;locust = locust.main:main&amp;#39;,]},)MANIFEST.in 包含文件配置，包含非py代码
recursive-include loads/packages/locust/static *setup.cfg [easy_install]index_url = http://pypi.douban.com/simple.pypirc(可选) 注：使用twine上传时可指定repository，则该文件不必要存在。
存放于Home目录
[distutils]index-servers =dev[dev]repository: http://xulizhao.com:6543/pypi/username: adminpassword: admin本地pypi 搭建本地pypi服务或镜像
PyPI Cloud
# 运行pserve server.ini# 配置：允许上传覆盖pypi.allow_overwrite = True功能更强的其他选择
 devpi pypiserver  分发  pyinstaller ： 制作成安装包 dh-virtualenv:打包成deb系统格式 Pynsist:Build Windows installers for Python applications  扩展阅读  部署优雅的Python代码 Python Packaging User Guide/官方推荐工具 setup.py (for humans) </content>
    </entry>
    
     <entry>
        <title>迁移至Python3</title>
        <url>https://xulizhao.com/blog/python3/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 用过Python的都知道,他有两个互不兼容的大版本Python2和Python3,由于历史遗留问题许多生产环境或库还只支持老版本Python2.
实际上2.7已经发布了近8年,且是最后一个2.x的大版本,并且将于2010(两年后)彻底停止维护,退出历史舞台.
Python3在两年前及更早时的库支持和应用范围确实不太好,有选择困难症的同学都转去Go语言了:) .
幸运的是近两年主流库/框架都已支持Python3,毕竟发布已经10年多了,在新项目中毫无疑问必须用Python3.
之前我在两个新项目已经使用Python3,最近把一个老项目也彻底迁移过来, 这里记录下一些知识点.
string和unicode Python 2 的 str 是 bytes, Python 3 的 str 是 unicode.
# 字符串和二进制转换 unicode_string.encode() # 默认utf-8 byte_string.decode()# split现在是bytes的方法 # requests.get(xxx).content返回bytes类型 your_content.split(b&amp;#39;,&amp;#39;)# base64编码后返回字节类型,转换为str base64.b64encode(some_bytes).decode()语法变化  使用print() except语句  有用的技巧 使用命令行参数提示兼容性问题:
 python2 -3参数 提示warning python3 -bb参数 提示字符串处理差异  # 判断当前运行版本 PY3 = sys.version_info[0] == 3# 安装pip3python3 -m ensurepip兼容2和3 除非迫不得已,应该只支持Python3
如果要兼容参考:
 官方迁移指南 Cheat Sheet: Writing Python 2-3 compatible code:如何写兼容的代码  扩展阅读  Pragmatic Unicode :关于unicode的通俗讲解  代码片段 # 对称加密移除padding的帮助函数(py2版本不适用于py3) def unpad(bytestring, k=16):&amp;#34;&amp;#34;&amp;#34;Remove the PKCS#7 padding from a text bytestring.&amp;#34;&amp;#34;&amp;#34;val = bytestring[-1]if val &amp;gt; k:raise ValueError(&amp;#39;Input is not padded or padding is corrupt&amp;#39;)l = len(bytestring) - valreturn bytestring[:l]def pad(bytestring, k=16):&amp;#34;&amp;#34;&amp;#34;Pad an input bytestring according to PKCS#7&amp;#34;&amp;#34;&amp;#34;l = len(bytestring)val = k - (l % k)return bytestring &#43; bytearray([val] * val)</content>
    </entry>
    
     <entry>
        <title>设计数据密集型应用笔记</title>
        <url>https://xulizhao.com/blog/ddia/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>distributed</tag><tag>database</tag>
        </tags>
        <content type="html"> 去年就看到总有人推荐这本书(简称DDIA),最初手里只有英文版,缓慢的读了个开头后来就忙别的去了.
今年偶然看到网上有中译版,惭愧的是到了年底,最近几个月才读来.
书的信息量很大,对数据库和分布式系统感兴趣的尤其值得一读.
暂时还剩第三部分没读完,先记些凌乱的笔记.
数据密集型:
 数据是主要挑战,涉及数据量,数据复杂度和数据变化速度. 于此对应的是计算密集型.  第一部分:数据系统基础 数据系统设计的基本思想
第一章: 可靠性,可扩展性,可维护性 可靠性:
 要设计具有容错/韧性的系统以应对各种故障. 常见的故障种类: 硬件故障 软件错误 人为错误  可扩展性: 用负载参数描述负载
描述性能:
 Throughout Response Time(客户端感受时间,区别于Latency). 响应时间重视时间分布,即使用百分位而不是平均数  软件系统的三个设计原则
 可操作性(运维友好) 简单性(好的抽象) 可演化性/可扩展性/可修改性/可塑性  第二章:数据模型和查询语言 数据模型: 数据的存储和查询等
 关系模型: 事务处理和批处理 文档模型: 对多对多和连接(记录之间存在关系)支持较差 图模型  关系模型 存储ID还是文本字符串是个副本(duplication)问题,去除冗余副本是数据库规范化的关键思想.
声明式查询语言(SQL)相对命令式的优势:
 比命令式API更简洁和容易 隐藏了数据引擎的实现细节  文档数据库 适用于大多数关系都是一对多关系(树状结构化数据)
文档数据库的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。
准确的说文档数据库 并不是无模式(schemaless),应该是schema-on-read(隐含的数据结构).
JSON表示比多表模式具有更好的局部性(locality).
第三章 主流的两大类存储引擎：
 日志结构（log-structured）的存储引擎 面向页面（page-oriented）的存储引擎（例如B树）  日志结构学派 日志/log:仅追加的数据文件. (只允许附加到文件和删除过时的文件，但不会更新已经写入的文件)
哈希索引: Bitcask(Riak默认存储引擎)
SSTables(排序字符串表（Sorted String Table）)制作LSM树/日志结构合并树
Bloom过滤器/布隆过滤器是用于近似集合内容的内存高效数据结构，它可以告诉您数据库中是否出现键，从而为不存在的键节省许多不必要的磁盘读取操作.
LSM树性能优势:
由于数据按排序顺序存储，因此可以高效地执行范围查询（扫描所有高于某些最小值和最高值的所有键），并且因为磁盘写入是连续的，所以LSM树可以支持非常高的写入吞吐量。
就地更新学派 将磁盘视为一组可以覆盖的固定大小的页面。例子:B树.
日志结构索引将数据库分解为可变大小的段，通常是几兆字节或更大的大小，并且总是按顺序编写段。相比之下，B树将数据库分解成固定大小的块或页面.
为了使数据库对崩溃具有韧性，B树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log）/ 重做日志(redo log)
并发控制使用锁存器（latches）（轻量级锁）保护树的数据结构来完成.
根据经验，通常LSM树的写入速度更快，而B树的读取速度更快。 LSM树上的读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。
内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。
数据仓库 数据仓库是一个独立的数据库，分析人员可以查询需要的内容，而不影响OLTP操作。 数据仓库包含公司所有各种OLTP系统中的只读数据副本。 从OLTP数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。将数据存入仓库的过程称为&amp;quot;抽取-转换-加载（ETL）&amp;rdquo;
 在线事务处理（OLTP, OnLine Transaction Processing） 在线分析处理（OLAP, OnLine Analytice Processing）  星型模式/维度建模
由事实表和维度表组成.
列存储
第四章:编码与演化 将数据结构转换为网络中的字节或磁盘上的字节的几种方法。我们看到了这些编码的细节不仅影响其效率，更重要的是应用程序的体系结构和部署它们的选项。
服务支持滚动升级需要提供向后兼容性（新代码可以读取旧数据）和向前兼容性（旧代码可以读取新数据）的方式进行编码.
 编程语言特定的编码 JSON，XML和CSV等文本格式 二进制模式驱动格式  二进制模式驱动格式允许使用清晰定义的前向和后向兼容性语义进行紧凑，高效的编码。
对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，因为它可以在编译时进行类型检查。
 Thrift Protocol Buffers Avro  数据流的几种模式
 数据库 RPC和REST API 异步消息传递(消息代理或Actor模型)  REST似乎是公共API的主要风格。 RPC框架的主要重点在于同一组织拥有的服务之间的请求，通常在同一数据中心内。
第二部分:分布式数据系统  共享架构:  共享内存架构（shared-memory architecture）: 垂直扩展（vertical scaling）或向上扩展（scale up） 共享磁盘架构（shared-disk architecture）: 网络附属存储（Network Attached Storage, NAS）或存储区网络（Storage Area Network, SAN）   无共享架构（shared-nothing architecture）: 水平扩展（horizontal scale） 或向外扩展（scale out）  NUMA: 非均匀内存访问（nonuniform memory access）
数据分布在多个节点上有两种常见的方式：
 复制（Replication） 分区 (Partitioning) : 不同的分区可以指派给不同的节点（node）, 亦称分片（shard）  第五章: 复制 单主复制 半同步（semi-synchronous）配置: 在数据库上启用同步复制，通常意味着其中一个跟随者是同步的，而其他的则是异步的。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库。
处理节点宕机
 从库失效：追赶恢复 主库失效：故障转移（failover）,需要认真考虑可能的情况  复制日志的实现
 基于语句的复制(副作用太大,通常不使用) 传输预写式日志（WAL） 逻辑日志复制（基于行）: 复制和存储引擎使用不同的日志格式 基于触发器的复制: 较灵活,但开销较大  多主复制 多领导者配置（也称多主、多活复制）,通常用于多数据中心.
实现: CouchDB
无主复制 leaderless
复制延迟问题(最终一致性)  读己之写 单调读（Monotonic reads）: 比强一致性（strong consistency）更弱，但比最终一致性（eventually consistency）更强的保证 一致前缀读: 如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现  第六章: 分区/Partitions 键值数据的分区
 根据键的范围分区:存在偏斜和热点的问题 根据键的散列分区  分片与次级索引
 按文档的二级索引/文档分区索引/本地索引: 分散/聚集（scatter/gather）方法 根据关键词(Term)的二级索引/全局索引  分区再平衡策略
 固定数量的分区:创建比节点更多的分区，并为每个节点分配多个分区 动态分区: 按节点比例分区  第七章: 事务 事务通常被理解为，将多个对象上的多个操作合并为一个执行单元的机制
ACID代表原子性（Atomicity），一致性（Consistency），隔离性（Isolation）和持久性（Durability）
 原子性/可中止性（abortability）: 能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。 一致性: 对数据的一组特定陈述必须始终成立。即不变量（invariants） 原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。 隔离性: 同时执行的事务是相互隔离的  并发控制常用的隔离级别  读已提交是一个非常流行的隔离级别,通过使用行锁（row-level lock） 来防止脏写 快照隔离/可重复读: 通常使用多版本对象/多版本并发控制（MVCC, multi-version concurrentcy control）实现 可序列化(Serializability）:通常被认为是最强的隔离级别。它保证即使事务可以并行执行，最终的结果也是一样的  一些可能遇到的问题:
脏读/脏写/读取偏差(不可重复读)/更新丢失/写偏差/幻读/字面意义上的串行执行(单核CPU)/两阶段锁定/可串行化快照隔离（SSI）
MySQL/InnoDB的可重复读并不会自动检测丢失的更新
比较并设置（CAS, Compare And Set）
幻读（phantoms）:即一个事务改变另一个事务的搜索查询的结果
记录系统和衍生数据系统之间的区别不在于工具，而在于应用程序中的使用方式。
第八章: 分布式系统的麻烦 分布式系统与运行在单台计算机上的程序的不同之处：
 没有共享内存，只有通过可变延迟的不可靠网络传递的消息 系统可能遭受部分失效 不可靠的时钟和处理暂停  物理时钟:时钟和单调钟
时钟: 根据某个日历（也称为挂钟时间（wall-clock time））返回当前日期和时间,通常程序返回自epoch（1970年1月1日 午夜 UTC，格里高利历）以来的秒数（或毫秒）.需要根据NTP服务器设置同步. 单调钟: 适用于测量持续时间（时间间隔），例如超时或服务的响应时间. 保证总是前进的事实（而时钟可以及时跳回）.单调钟不需要同步.
拜占庭将军问题: 在不信任的环境中达成共识的问题.
第九章: 一致性与共识 共识（consensus）：就是让所有的节点对某件事达成一致
事务隔离主要是为了，避免由于同时执行事务而导致的竞争状态，而分布式一致性主要关于，面对延迟和故障时，如何协调副本间的状态。
最强一致性模型之一: 线性一致性（linearizability）
线性一致性（linearizability）/ 原子一致性（atomic consistency）/ 强一致性（strong consistency）/ 立即一致性（immediate consistency）/ 外部一致性（external consistency ）
基本思想：使系统看起来好像只有一个数据副本,是读取和写入寄存器（单个对象）的新鲜度保证
依赖线性一致性的场景:
 锁定和领导选举 约束和唯一性保证 跨信道的时序依赖  CAP定理的正式定义仅限于很狭隘的范围，尽管CAP在历史上有一些影响力，但对于设计系统而言并没有实际价值.
因果一致性为我们提供了一个较弱的一致性模型
版本向量可以区分两个操作是并发的，还是一个因果依赖另一个；而兰伯特时间戳(更加紧凑)总是施行一个全序。
线性一致的CAS（或自增并返回）寄存器与全序广播都都等价于共识问题
共识可以解决的问题:
 线性一致性的CAS寄存器 原子事务提交 全序广播 锁和租约 成员/协调服务 唯一性约束  ZooKeeper这样的工具为应用提供了“外包”的共识、故障检测和成员服务。
第三部分: 派生数据 第十章: 批处理算法和框架 与Unix设计相通 Unix设计原则包括：输入是不可变的，输出是为了作为另一个（仍未知的）程序的输入，而复杂的问题是通过编写“做好一件事”的小工具来解决的.
在Unix世界中，允许程序与程序组合的统一接口是文件与管道；在MapReduce中，该接口是一个分布式文件系统。
分布式批处理/MapReduce 批处理的常见用途: 搜索,构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，图像识别）与推荐系统（例如，你可能认识的人，你可能感兴趣的产品或相关的搜索)
分布式批处理框架需要解决的两个主要问题是：
 分区: 在MapReduce中，Mapper根据输入文件块进行分区。 容错: MapReduce经常写入磁盘;数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态;确定性算子减少了需要重算的数据量.  分布式批处理引擎有一个刻意限制的编程模型：回调函数（比如Mapper和Reducer）被假定是无状态的. 使得批处理作业中的代码无需操心实现容错机制.
MapReduce的连接算法
 排序合并连接 广播散列连接 分区散列连接  数据流引擎的优化 Tez是一个相当薄的库，它依赖于YARN shuffle服务来实现节点间数据的实际复制，而Spark和Flink则是包含了独立网络通信层，调度器，及用户向API的大型框架。
Hive，Spark和Flink都有基于代价的查询优化器可以做到这一点，甚至可以改变连接顺序，最小化中间状态的数量.
图批量处理 在整个图上执行某种离线处理或分析,这种需求经常出现在机器学习应用（如推荐引擎）或排序系统中,最着名的图形分析算法之一是PageRank.
使用批量同步并行（BSP）计算模型,即Pregel模型.
一些概念 事件日志: 描述登录用户在网站上做的事情（称为活动事件（activity events）或点击流数据（clickstream data）.事件日志是事实表，用户数据库是其中的一个维度。
物化（materialization）: 将中间状态写入文件的过程
算子(operators)是Map和Reduce的泛化
高级API和语言:
Mahout在MapReduce，Spark和Flink之上实现了用于机器学习的各种算法
空间算法: 如最近邻搜索（k-nearest neghbors, kNN）
第十一章: 流处理(stream processing) 消息系统的分类:
 直接从生产者传递给消费者 消息代理(message broker) / 消息队列(message queue)  AMQP/JMS风格的消息代理: 适用于在消息处理代价高昂，希望逐条并行处理，顺序不重要的情况下 基于日志的消息代理: 适用于消息吞吐量很高，处理迅速，顺序很重要的情况下    一个记录/事件(event)由生产者（producer）/发布者（publisher）/发送者（sender）生成一次，然后可能由多个消费者（consumer）/订阅者（subscribers）/接收者（recipients）进行处理.
许多开源分布式流处理框架的设计都是针对分析设计的：例如Apache Storm，Spark Streaming，Flink，Concord，Samza和Kafka Streams。
流处理的几种目的:
 搜索事件模式（复杂事件处理） 计算分窗聚合（流分析) 保证衍生数据系统处于最新状态（物化视图）。  流式连接
流处理中可能出现的三种连接类型：
 流流连接 流表连接 表表连接  容错
流处理中实现容错和恰好一次语义的技术: 可以使用更细粒度的恢复机制，基于微批次，存档点，事务，或幂等写入。
Spark在批处理引擎上执行流处理，将流分解为微批次（microbatches）, 而Apache Flink则在流处理引擎上执行批处理.
幂等性（idempotence）: 幂等操作是多次重复执行与单次执行效果相同的操作。
第十二章:数据系统的未来 (串联起前边章节的汇总篇)
批处理与流处理 在维护衍生数据时，批处理和流处理都是有用的。流处理允许将输入中的变化以低延迟反映在衍生视图中，而批处理允许重新处理大量累积的历史数据以便将新视图导出到现有数据集上。
Lambda架构
核心思想是通过将不可变事件附加到不断增长的数据集来记录传入数据，这类似于事件溯源。
为了从这些事件中衍生出读取优化的视图, Lambda架构建议并行运行两个不同的系统：批处理系统（如Hadoop MapReduce）和独立的流处理系统（如Storm）。
在Lambda方法中，流处理器消耗事件并快速生成对视图的近似更新；批处理器稍后将使用同一组事件并生成衍生视图的更正版本。
</content>
    </entry>
    
     <entry>
        <title>读国学</title>
        <url>https://xulizhao.com/read/guoxue/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> 国学的火热似乎起自十多年前百家讲坛的于丹系列,最近几年也总能听到教儿童读弟子规或者各地开女德班等的无关真正国学的负面新闻.
最近读章太炎的国学讲义才知道,国学最早是在一个世纪前提出的,当时社会变革收到西方先进思想文化的冲击,人们试图重现审视中国传统文化挖掘其精华和价值.
先说定义,国学泛指中国传统文化和学术(这个涵盖各行各业). 一般使用传统分类: 经史子集, 区别于现代使用的西方学科分类法.
 经: 本意是线装经典书,在汉初定义,汉之前的经典书都算此类. 主要包括&amp;lt;诗经&amp;gt;,&amp;lt;论语&amp;gt;,&amp;lt;孟子&amp;gt;,&amp;lt;尚书&amp;gt;,&amp;lt;左传&amp;gt;等 史: &amp;lt;史记&amp;gt;,&amp;lt;汉书&amp;gt;等朝代史,前两部也有很高的文学价值. 尚书开纪传体之先,左传为编年体之先. 子: 先秦诸子及各种行业著作(九流) 集: 诗词赋文学  之前读过些华杉读懂孙子兵法,偶尔也读论语的解读,基本是汇集各家之长,同时结合现实实践. 两千来年的儒学也总有他的可取之处.
作为理科出身,确实该提高下古文学鉴赏和古文阅读能力,毕竟这是中文之本,学好母语的基础.
</content>
    </entry>
    
     <entry>
        <title>读诗词</title>
        <url>https://xulizhao.com/read/poem/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> 为了听蒙曼品最美唐诗冲了会员,也因此收听到了更多的音频,毕竟喜欢的还有郦波品读唯美诗词名篇, 虽然我之前从没看过诗词大会之类的节目.
听过一些之后的感觉是,唐诗真的是文学里最美的花, 不同于学生时代的死记硬背,在人生经历丰富后,更能体会到诗的文字精炼之美,音韵之美.
因为想理清唐诗的发展历程,又找来了闻一多的唐诗杂论,朱自清的经典常谈等经典著作来读, 也再次引发我的下篇, 对于国学的了解.
似乎职业习惯的毛病,联网化了.
这几篇文章之后慢慢更新吧,先写个点题的开头.
音韵
以前不太理解多音字,听唐诗讲课多了才理解其中原因. 比如几个缘故:
 历史发展/流变: 比如 &amp;ldquo;车&amp;quot;最初表示战车读ju,后来统称车类就读che 名词,动词等词性不同: 比如 &amp;ldquo;冠&amp;quot;四声表示动词一声表示名词 正式或口语表示: 比如 &amp;ldquo;血&amp;quot;的xue/xie 不同含义: 比如 &amp;ldquo;思&amp;quot;的一声和四声(表示心情,思绪) 押韵: 比如 &amp;ldquo;斜&amp;quot;在诗歌里一般读xia  总结起来,这就是汉语的博大精深之初,即大道至简. 因为在你了解了这些知识/常识后, 放在上下文里就能准确的表达含义. 比拉丁语系的不同词性都造个生词要高明的多.
</content>
    </entry>
    
     <entry>
        <title>读历史</title>
        <url>https://xulizhao.com/read/history/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> 缘起 在年初的时候,因偶然机会追了一部国产剧,即网剧大军师司马懿. 当时是很着迷的, 因为看的下载版,可以说看的不舍昼夜. 评价嘛,上部明显好于下部,制作精良,演技总体给力. 缺点就是改动太随意,好多不符合历史的情景.
剧本你可以改编,但大的历史人物事件还是要尊重的,否则你搞个戏说也行,或者干脆架空历史.
也因为这点,了解了很多魏晋的历史. 更重要的时开始读易中天老师的中华史系列,一发而不可收拾,断断续续读了隋唐及之前大部分历史.
古代史 作为中华的一份子, 最想了解的就是那段光辉岁月: 秦汉和隋唐.
由于中华史做纯粹的历史书看的话,会稍显细节不够. 上个月开始在路上补隋史,而且是通过更方便碎片的喜马拉雅听书,主要听的蒙曼老师的百家讲坛音频:大隋风云.
也因此喜欢上了蒙老师,又重新引起自己对于唐诗美的欣赏(具体见下篇).
听完后,又收听了易中天说禅,作为中华智慧的一部分,收获就是做人有时要放弃执念(破执),当然做事还是要认真的.
回头把先秦(春秋战国)补上,毕竟出了那么大思想家哲学家.
秦 短暂而创造辉煌的时代, 秦始皇的功绩地位毋庸置疑, 统一中华, 开创帝国时代.
皇帝这个名词就是他发明的, 统一的不仅是领土,更是文字,度量衡等,促进沟通和繁荣.
成败都在法家和吏治,在时代大变革之际使用高压企图大一统,最终促成了起义和反抗. 过在焚书.
汉 刘邦的成和项羽的败是必然的,一个优秀团队对一个有英雄主义的人, 汉高祖有其个人魅力.
张良运筹帷幄,韩信国士无双.
众诸侯下场很惨,有其时代必然性,从封建到集权不得已而为之. 也导致了之后汉的外戚和宦官政治.
汉武帝确是一代英主,那也是一个传奇的时代,卫青霍去病生逢其时.
三国魏晋 之前一直误解曹操了,真是一代枭雄,也成就了魏. 只可惜之后两代生命短暂,最后又托孤不妥从此断送.
也是了解历史后才知道王者游戏里的甄姬原是甄宓.
蜀因为名著三国演义成就了刘备和诸葛亮等诸名将,更因为理想主义被人们传为佳话.
吴的功是发展了江南,也因为之后司马氏的善待,才有了东晋的建立和南方的开发.
蜀吴的问题是二代太差,更重要的是实力真的不能和北方抗衡,败也属必然了.
晋最大的问题是因为是篡来的王朝,制度建设和子女教育真是问题,注定了短命王朝,留下了晋惠帝立长这个反面典型和比富的故事.
好在留下士人风骨和诗歌书法的宝贵遗产,记起的有杜预(杜甫和杜牧的先祖),陆机,王谢等大家.
读到五胡乱华时真是痛心,可也因此有了南北之说. 十六国里能记得的只有苻坚了,气候确实不够.
南北朝 因为长江而有了南北,期间也促进了民族融合和文化发展.
北魏发展也算传奇,一个小部落有如此大发展,不无理由.
拓跋宏的改革和融合载入教科书,可惜的是生命太短. 另一方面改革也埋下了陇西六镇(之后的关陇贵族)反叛的隐患.
西魏的宇文泰一代枭雄,南朝梁元帝江陵焚书臭名昭著.
隋 隋唐真的和秦汉好像啊,而且隋唐的关系更近, 杨广这个炀帝的称号有些过了.
杨坚的历史地位还是很高的,以较小的代价统一南北,开创科举,建立隋律,开三省六部行政体系,确定东亚霸主地位.
当然这些名臣也功不可没的载入历史,高炯,长孙昇等.
杨广的急功近利,刚愎自用,好大喜功真是印象深刻, 也应了不作就不会死这句话.
从人的成长看,过早的一帆风顺真的有其弊病啊,一次打击(东征高句丽)就再也起不来了.
大运河通南北,东都洛阳连东西,再通西域还是很有功劳的,不过执行急了些. 也应了性格决定命运这句话,这个锅有独孤氏一份.
唐 唐是我心目中最辉煌的时代,开放和包容,文化大发展,历史影响最大.
唐诗,书法,禅宗永流传.
唐太宗李世民绝对可以上帝王排行榜前几位,虽然有玄武门政变和改史美化自己的问题,但从十八学士和重用魏征等很多史实看,却也是综合实力最强的太子.
可惜的是晚年选太子不够妥当,也因此成就了大政治家武则天的传奇.
正如无字碑一样,武则天功过很难说,却是国内史上唯一女皇帝.
唐玄宗也是晚年出了大问题,直接造成安史之乱而由极盛转衰,之后长期的宦官干政和藩镇割据这个锅他必须背.
由此看,做一辈子好人真难,能做到孟子所谓大丈夫真是需要极高的修养了.
</content>
    </entry>
    
     <entry>
        <title>Android自动化测试</title>
        <url>https://xulizhao.com/blog/android-test/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 安卓客户端测试的一些主流技术。
官方支持 Espresso UI测试支持，Android Support库的一部分。
  优点：控件支持最丰富，定制型强。
  对应的： 需要安卓控件的良好设计MVP，对客户端代码的熟悉。安卓开发的最爱。
  官方主页
  API接口文档
  Android user interface testing with Espresso - Tutorial
  mobly  mobly:Python实现的负载E2E测试工具  App Crawler  App Crawler主页  自动测试应用（遍历模拟点击、滑动等行为），不需要额外的开发。支持配置登录等。
可以用来测试崩溃、显示问题、性能问题。
截屏测试 WindowManagerGlobal &#43; imageMagick
性能测试  内存  App启动初始内存 最高峰值 使用均值   启动时间 (均值和众数)  TTFB(Time to First Byte) First Paint DOM Content Loaded onLoad    框架  Matrix:微信APM管理检测 AndroidViewClient:Python实现的自动化增强工具 Test Butler: Lindedin的稳定测试 STF设备工厂: Node.JS实现的web，远程管理众多设备 Airtest :网易出品，基于图形识别，跨平台[python] Uiautomator2 :Uiautomator2 的Python实现 Robolectric: 安卓单元测试 leakcanary: 内存泄露检测  </content>
    </entry>
    
     <entry>
        <title>GUI图形界面测试</title>
        <url>https://xulizhao.com/blog/gui-test/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> PC和Mac的自动化工具/框架.
框架工具  AutoIt:最早接触的Windows自动化工具 AutoHotkey : a scripting language for desktop automation SikuliX: 基于图形识别，电脑端自动化。 PyAutoGUI:控制键盘和鼠标[python] pywinauto:[python] Windows的各种模块支持  </content>
    </entry>
    
     <entry>
        <title>iOS测试</title>
        <url>https://xulizhao.com/blog/ios-test/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 框架  EarlGrey:Google开发的UI自动化框架，基于XCTest，支持Swift 和Objective-C FBSnapshot: 截图对比  工具  Carthage : Cocoa依赖管理  </content>
    </entry>
    
     <entry>
        <title>TestNG测试框架</title>
        <url>https://xulizhao.com/blog/testng/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>testing</tag>
        </tags>
        <content type="html"> Java测试必备之TestNG。
学习笔记 结构组成：Suite，Test，Class
配置：testng.xml (可选)
Exception：如果调用者能处理异常，则抛出，否则用RuntimeException.
学习资源  testNG changing test results dynamically </content>
    </entry>
    
     <entry>
        <title>人体工学电脑办公</title>
        <url>https://xulizhao.com/blog/work-health/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>office</tag>
        </tags>
        <content type="html"> 如何避免腰椎、颈椎问题 坐姿 坐着工作时保持脊柱的正直，注意不要往前弯腰和伸颈.
 调整好屏幕高度，直立上半身时，显示器屏幕顶端应略低于水平视线（笔记本使用电脑支架） 离显示器起码要有一臂的距离 鼠标应放在键盘边，用的时候要用桌子支撑手臂 调整好座椅高度，使您的膝盖水平或略低于臀部，同时脚可以平放在地上 腰部后面有支撑，保持脊椎和颈椎竖直 （不要弯腰驼背）  避免长时间疲劳 工作中注意体位的改变。不要保持一个姿势太长时间，哪怕是正确的坐姿也会造成肌肉的疲劳。要多站起走走，腰部和颈部可以做简单的前屈、后伸、侧屈、旋转（注意不要做环转运动），可以用头部为笔画“米”字。
中英文对照  人体工学/ergonomics 肘/elbows  参考  熬夜久坐，腰痛怎么办？ 微软指导-设置你的桌面 </content>
    </entry>
    
     <entry>
        <title>办公软件之Word</title>
        <url>https://xulizhao.com/blog/word/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>office</tag>
        </tags>
        <content type="html"> 用习惯了Markdown，回不去Word的格式排版。
不得不用的情况下，有必要了解这些技巧提高效率。
必备技巧 核心是能自动生成的不要手动输入。
标题样式 修改常用主要标题样式。
多级列表样式 “定义新的多级列表”并将“级别链接到样式”，自动关联标题样式。
封面 使用表格排版。
正文 用Tab”键手动缩进
目录 页眉和页脚 页脚要从目录之后开始计数。
图和表 图和表的编号一定要用题注。 【引用】-【插入题注】
进阶必须 使用自己的模板文件，【文件】-【新建】-【我的模板】。 模板格式为dotx扩展名。
链接  打造自己的word常规模板 </content>
    </entry>
    
     <entry>
        <title>开发者成长</title>
        <url>https://xulizhao.com/blog/developer/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 写程序就要有追求，只要还在写，就永无止境。
重构   价值观：沟通、简单、灵活
  原则：简洁、清晰、易扩展、易维护
  指导思想：局部影像、最小化重复、将逻辑和数据捆绑
  转移方法：当两个或以上的消息发给一个不同的对象时
  开放/封闭原则：对象应当对扩展开放，对进一步的修改封闭
  TDD 目标：
 Clean Code(再解决) that Works(先解决) 消除代码和测试程序之间的重复 重构，消除重复设计和优化程序结构  关于测试：
 将设计缺陷转换为测试程序 将一种感觉(比如对副作用的厌恶)转换成测试程序 TestSuite是TestCase的组合(Composite)  TDD应该测什么？
 条件部分 循环部分 操作部分 多态性  学习资源  酷壳精选 开放式教育 design_patterns/refactoring </content>
    </entry>
    
     <entry>
        <title>性能测试</title>
        <url>https://xulizhao.com/blog/performance-test/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 有些内容会涵盖在我写的系列记录。
 使用JMeter: 熟悉Java的用户 使用Locust: 熟悉Python的用户 全链路压测学习1/ 全链路压测学习2: 大公司里用  扩展  taurus：JMeter等常见性能测试工具集成 Jenkins性能测试插件/文档  </content>
    </entry>
    
     <entry>
        <title>日志处理</title>
        <url>https://xulizhao.com/blog/logging/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html"> 日志系统 Kafka partition可以理解为一个日志目录。
工具：
 kafka-python：客户端 kafka-tools  默认端口：
 zookeeper :9092 kafka :2181  # 启动ZKbin/zookeeper-server-start.sh config/zookeeper.propertiesbin/kafka-server-start.sh config/server.properties# 主题相关bin/kafka-topics.sh --list --zookeeper localhost:2181bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic billingbin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.propertiesbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic healthing --from-beginningElastic ELK: ElasticSearch存储索引 &#43; Logstash收集整理 &#43; Kibana展现
 Beats :Go实现的轻量级日志收集Agent Logstash: Ruby实现的数据处理管道 ElastAlert:Python实现的报警系统  注： StreamAlert是另一个基于AWS lambda的Python类似实现。
默认端口：
 kibana :5601 logstash :5043 elasticsearch :9200  目录结构：
 主目录 /usr/share/elasticsearch/ 配置 /etc/elasticsearch 日志 /var/log/elasticsearch 启动脚本 /etc/init.d/elasticsearch 默认启动 sudo systemctl enable elasticsearch.service  http://localhost:9200/_nodes?prettycurl &amp;#39;localhost:9200/_cat/indices?v&amp;#39;curl -XGET &amp;#39;http://localhost:9200/billing/billing/1&amp;#39;curl -XGET &amp;#39;http://localhost:9200/billing/billing/_search?q=*&amp;#39;cp config.yaml.example config.yamlelastalert-create-indexelastalert-test-rule rules/test_frequency.yamlelastalert --verbose --rule rules/test_frequency.yaml# --debug会记录邮件内容，并且查询不会被保存curl -XGET &amp;#39;http://localhost:9200/elastalert_status/_mapping/&amp;#39;其他  Python 日志处理 mtail: Google开源的Go实现，把日志导出到时序数据库 Graylog: 日志管理平台，Java实现  扩展阅读 Elasticsearch/Solr基于Lucene。
相关性算法 TF-IDF: term frequency –inverse document frequency
 TF: term出现的频率 IDF: 各单词在其他文档越不常见,权重越高  常用场景：
 拼写错误 变种 建议: 自动补全 和 did you mean </content>
    </entry>
    
     <entry>
        <title>机器学习</title>
        <url>https://xulizhao.com/blog/machine-learning/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>data</tag>
        </tags>
        <content type="html"> 学了也用不到系列。
注: 部分笔记来源于左耳听风专栏。
机器学习分类  Classification 特征识别  Virus recognition 病毒识别 Credit evaluation 信用预估 Junk email detection 垃圾邮件检测    监督式学习/Supervised Learning 需要提供一组学习样本(训练数据/training data)，包括相关的特征数据以及相应的标签。
程序可以通过这组样本来学习相关的规律或是模式，然后通过得到的规律或模式来判断没有被打过标签的数据是什么样的数据。
一种比较常见的监督式学习，就是从历史数据中获得数据的走向趋势，来预测未来的走向。
回归是(连续的值)，分类是(离散的值)。
非监督式学习/Unsupervised Learning 也称特征点学习，能自动地为数据进行分类,寻找相似事物。
常见算法 监督式学习   决策树（Decision Tree）。可用于自动化放贷、风控。
  朴素贝叶斯分类（Naive Bayesian classification）。可以用于判断垃圾邮件，对新闻的类别进行分类，判断文本表达的感情是积极的还是消极的，以及人脸识别等。
  最小二乘法（Ordinary Least Squares Regression），算是一种线性回归。
  逻辑回归（Logisitic Regression）。常用于预测。一种强大的统计学方法，可以用一个或多个变量来表示一个二项式结果。它可以用于信用评分、计算营销活动的成功率、预测某个产品的收入等。
  支持向量机（Support Vector Machine，SVM）。可以用于基于图像的性别检测，图像分类等。
  集成方法（Ensemble methods）。通过构建一组分类器，然后根据它们的预测结果进行加权投票来对新的数据点进行分类。原始的集成方法是贝叶斯平均，但是最近的算法包括纠错输出编码、Bagging 和 Boosting。
  KNN
  非监督式学习  聚类算法（Clustering Algorithms）。目标是给数据分类  种类分组/Species group 相似的人或书/similar peple and books   主成分分析（Principal Component Analysis，PCA）。PCA 的一些应用包括压缩、简化数据，便于学习和可视化等。 奇异值分解（Singular Value Decomposition，SVD）。 独立成分分析（Independent Component Analysis，ICA）。ICA 是一种统计技术，主要用于揭示随机变量、测量值或信号集中的隐藏因素。   实际上，PCA 是 SVD 的一个简单应用。在计算机视觉中，第一个人脸识别算法使用 PCA 和 SVD 来将面部表示为“特征面”的线性组合，进行降维，然后通过简单的方法将面部匹配到身份。虽然现代方法更复杂，但很多方面仍然依赖于类似的技术。
 深度学习 一些应用领域：计算机视觉、语音识别、翻译、 物联网、 医疗、 聊天机器人等。
学习资源  Awesome Machine Learning 动手学深度学习: 李沐 AiLearning中文翻译  开源框架/库   Neural-Net-with-Financial-Time-Series-Data : 股票预测模型, LSTM  其他  Apache Mahout: Java机器学习库 kubeflow:  NLP  TextBlob:Python库,Sentiment analysis, part-of-speech tagging, noun phrase extraction, translation  工具  可以用Octave做原型   sudo apt-get install gfortran fort77; sudo apt-get build-dep octave
 扩展阅读  机器学习原来这么有趣！ TF-IDF模型的概率解释 / 在文档中找到重要的单词 / scikit相关 / NLTK和scikit 解决文本相似度 </content>
    </entry>
    
     <entry>
        <title>构建高性能系统</title>
        <url>https://xulizhao.com/blog/oss-system/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>architecture</tag><tag>java</tag>
        </tags>
        <content type="html"> 文章 组件 分布式服务  Apollo:携程的分布式配置中心，适用于微服务配置管理场景 Sentinel:阿里的服务保障，轻量级的流量控制、熔断降级 Redisson:增强Redis Java客户端 Seata:分布式事务中间件 XXL-JOB:轻量级分布式任务调度平台 Soul: 基于webflux的网关  APM APM(Application Performance Management)的Java实现
 SkyWalking:支持多种traces和metrics系统格式，Apache项目 pinpoint  缓存  Apache Traffic Server:不止是缓存代理，用于CDN或内容分发 Varnish Cache: HTTP缓存加速 Squid Web Proxy Cache  </content>
    </entry>
    
     <entry>
        <title>测试计划</title>
        <url>https://xulizhao.com/blog/testplan/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 测试计划。
测试计划 / Test Plan 测试计划，用于具体项目的测试，通常包含测试策略。是整个测试活动的指南性（road map）文档。
关注于3W: who will test what and when.
示例：
 概述 测试目的 测试范围 测试方法/策略 进入和退出条件 时间计划 人员安排 测试环境 假设和风险  测试计划构成 最基本的组成：
 测试范围 测试策略 测试资源 测试进度 测试风险预估  测试范围 确定测试范围的过程在一定程度上也是对测试需求分析的进一步检验，测试范围中需要明确“测什么”和“不测什么”，做有针对性的测试。
测试策略 / Test Stratergy  明确先测什么后测什么  明确测试的重点 明确各项测试的先后顺序   如何来测  采用什么样的测试类型和测试方法 要详细说明具体的实施方法    测试策略，适用于所有项目的定制策略，应该包含用于测试的方法和测试范围，通常在早期制定。
侧重于测试执行层面或测试基础设施的计划，比如范围、环境、方法、工具、假设、接受条件等。
功能测试
 手工：测试用例设计和数据准备 自动： 先实现主干业务流程 评估可测试性  兼容性测试： 通常测试后期执行。
测试资源  测试人员：谁来测  测试工程师的数量 测试工程师的个人经验和能力 具体任务责任到人   测试环境：在哪里测  测试进度 主要描述各类测试的开始时间，所需工作量，预计完成时间，并以此为依据来建议最终产品的上线发布时间。
测试风险预估 通常需求变更、开发延期、发现重大缺陷和人员变动是引入项目测试风险的主要原因。
</content>
    </entry>
    
     <entry>
        <title>算法</title>
        <url>https://xulizhao.com/blog/algorithm/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 程序=数据结构&#43;算法，所以这里记录下算法的点点滴滴。
基础 状态机 有限状态(自动)机, Finite-State Machine/FSM,是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。
搜索 折半搜索/二分搜索/Binary Search 是一种在有序数组中查找某一特定元素的搜索算法.（预排序数组的查找）
复杂度：
 时间复杂度: O(log n) 空间复杂度: O(1)  两种实现
 递归版本 While循环  参考BinarySearch.java
其他 指数补偿 即exponential backoff, 通常用于网络和传输协议,例如重试等
 Java实现 Go实现 参考1  学习资源  酷壳精选 </content>
    </entry>
    
     <entry>
        <title>编码和解码</title>
        <url>https://xulizhao.com/blog/encoding/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 只要和计算机打交道就涉及到编码和解码。
常用编码 进制  二进制 十进制  十六进制 Hex： 由0~9 A B C D E F构成,表示的长度更短
与二进制转换: 每4位一组,位数不够高位补0
ASCII ASCII码： 美国信息交换标准代码 (可读性更强) : 由(128个)英文及常用符合组成
UTF-8 又称万国码。
Base64 64个可读字符进行编码, 介于 Hex和ASCII(去除了不可读字符).
 方便把含有不可见字符的信息用可见字符表示出来, 以便复制粘贴. 方便通信转换, 使用场景: X.509公钥证书, 电子邮件数据/附件 (MIME)  数字 &#43; 小写字母 &#43; 大写字母 和 &#43; /
按顺序为: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789&#43;/
改进Base64(URL Safe Base64 ) 标准Base64问题:
 &#43;/经常用于文件系统和URL,容易冲突 ; padding字符=常用于URL, 比如URL编码器会把 &#43;和/变成 %XX的形式 (存入数据库还需要再次转换,因为%是通配符).  为解决以上问题, 改进Base64(URL Safe Base64 ) 把 &#43;和/分别替换成 -和_,同时去掉末尾的padding.
 每3个8位转换成4个6位,每组添加2个高位0后成为4个8位, 即理论增加1/3长度\ 特点: 能被4整除, =后缀数为0,1,2个.  扩展阅读  Base64编码原理与应用 </content>
    </entry>
    
     <entry>
        <title>缺陷报告</title>
        <url>https://xulizhao.com/blog/defect/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 好的缺陷报告什么样?
缺陷报告要素  缺陷标题 缺陷概述 缺陷影响 环境配置(按需描述) 前置条件 缺陷重现步骤 期望结果和实际结果 优先级和严重程度 变通方案(影响优先级)/Workaround 根原因分析(测试尽可能提供RCA) 附件  缺陷标题 对缺陷的概括性描述，通常采用“在什么情况下发生了什么问题”的模式。
 问题的描述既要清晰简洁，最关键是要足够具体。要清楚地表述发生问题时的上下文，也就是问题出现的场景。 标题应该尽可能描述问题本质，而避免只停留在问题的表面。 要易于检索以避免重复提交  缺陷标题不易过长，更多描述应该放在缺陷概述。
缺陷概述通常会提供更多概括性的缺陷本质与现象的描述，是缺陷标题的细化。
缺陷影响 缺陷引起的问题对用户或者对业务的影响范围以及严重程度。
严重程度是缺陷本身的属性，通常确定后就不再变化，而优先级是缺陷的工程属性，会随着项目进度、解决缺陷的成本等因素而变动。
 缺陷的优先级（Priority） 严重程度（Severity）  开发经理会以此为依据来决定修复该缺陷的优先级 产品经理会以此为依据来衡量缺陷的严重程度，并决定是否要等该缺陷被修复后才能发布产品    缺陷描述  前置条件:简化描述 缺陷重现步骤：缺陷报告中最核心的内容，其目的在于用简洁的语言向开发工程师展示缺陷重现的具体操作步骤。  操作步骤通常是从用户角度出发来描述 每个步骤都应该是可操作并且是连贯的，通常采用步骤列表的形式。   期望结果 实际结果  缺陷分析 通常使用缺陷管理系统自动报表功能做进一步分析，提升后续产品质量或改进流程。
 测试缺陷统计 bug趋势分析 bug收敛情况 bug模块分布 bug发现阶段统计  常用工具  JIRA tapd  </content>
    </entry>
    
     <entry>
        <title>自动化测试</title>
        <url>https://xulizhao.com/blog/automation-test/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 自动化测试适用场景：
 手工无法测试 功能稳定不容易变动 频繁回归  有些内容会涵盖在我写的系列记录。
 Android 测试 iOS 测试 GUI图形界面测试 测试数据的准备  设计 分层测试/金字塔模型 三层测试：
 单元测试：关注代码覆盖率，结合mock用 接口测试：业务逻辑和持久数据验证。占比20%. UI测试：显示相关，复杂业务场景。占比10%.  分层设计  工具层  UI控件识别操作的功能完整性 接口合理性 编写自动化脚本的语言   核心层：xUnit  测试用例的组织 测试执行 反馈结果   适配层：对常用方法封装以保证测试代码中尽可能少地重复代码，PageObject，BDD  工具层 负责测试执行的动作触发，同时分离测试部分和业务功能。
例如移动测试的Appium, 安卓官方支持的Espresso, Web测试的Selenium/WebDriver。
核心层 负责测试执行的驱动和结果监控并反馈。
通常使用xUnit框架和进一步的封装定制，并结合断言库的使用。
适配层 负责把重复使用的测试方法封装适配，方便快速地编写和维护用例。
比如数据驱动、关键字驱动的Robot Framework、行为驱动/BDD的 Cucumber。通常与实现语言、业务和具体测试无关。
流程优化  环境 数据 测试用例生成 数据比对 CI/持续集成  工具/框架 xUnit框架  TestNG: Java  断言库  REST Assured: Java DSL for easy testing of REST services  报告  Allure Report:丰富的报告框架，Java开发，支持多语言集成 Allure官方文档 Jenkins Allure Plugin  BDD 用类似自然语言书写用例，通常与DSL(Domain Specific Language)结合。
一些常用概念：
 feature : 功能点具体描述 background 前置条件 scenario 测试场景  Given When Then   step  常用框架
 Cucumber:基于Ruby和RSpec实现，支持常用语言集成 Behave: Python实现 Jasmine : JavaScript/Node.JS实现  跨平台E2E  Macaca: 阿里的基于Node.JS的全过程测试框架  Gauge/基于Contract 实例化需求的实现，活文档/可执行的文档。
 Gauge：Go实现，ThoughtWorks出品 Gauge Python插件  </content>
    </entry>
    
     <entry>
        <title>关于测试</title>
        <url>https://xulizhao.com/blog/testing/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 测试的方方面面。
关于测试 软件测试总的目标之一是在足以检查出错误的前提下,使测试用例的数量最小.
三个重要的测试原则：
 软件测试是为发现错误而执行程序的过程 一个好的测试用例具有较高的发现某个尚未发现的错误的可能性 一个成功的测试用例能够发现某个尚未发现的错误  测试阶段  Smoke Tests/冒烟测试： 基本功能的快速验证，或对构建后的完整性检查(sanity check) BFT/ Basic Functionality Tests: 基本功能测试 FFTs/Full Functionality Tests： 全功能测试 User acceptance testing/UAT: 最后一阶段测试，基于需求标准的真实最终用户和场景验证  Smoke Tests 主要功能或特性要包含至少一条测试用例，通常会发现以下问题：
 初始环境搭建或配置问题 整体应用稳定性问题 产品特性不工作或不可用  有时也会用范围更小的Sanity Tests。
Regression Tests 回归测试，最适合把稳定的部分用自动化的实现。
Exploratory Tests 探索性测试。
相比Ad-hoc测试更有规划性。
Unit Test 单元测试通常由开发完成，通常只有底层模块或者核心模块的测试中才会采用单元测试。。
要做到代码功能逻辑正确，必须做到分类正确并且完备无遗漏，同时每个分类的处理逻辑必须正确。
驱动代码，桩代码和 Mock 代码，是单元测试中最常出现的三个名词。驱动代码是用来调用被测函数的，而桩代码和 Mock 代码是用来代替被测函数调用的真实代码的
测试设计 Test Plan 测试计划，用于具体项目的测试，通常包含测试策略。是整个测试活动的指南性（road map）文档。
关注于3W: who will test what and when.
示例：
 概述 测试目的 测试范围 测试方法/策略 进入和退出条件 时间计划 人员安排 测试环境 假设和风险  Test Stratergy 测试策略，适用于所有项目的定制策略，应该包含用于测试的方法和测试范围，通常在早期制定。
侧重于测试执行层面或测试基础设施的计划，比如范围、环境、方法、工具、假设、接受条件等。
手机应用测试 一些测试点：
 App升级管理  覆盖/增量安装 用户信息 数据库变化 删除App   通知推送的测试  推送是否工作，消息显示，跳转是否正确 手机开关机、待机 应用打开关闭、后台运行 单条、多条推送 未读消息数的更新   同步：不同设备信息同步 （一处改变多处同步）  性能测试  首次启动 &#43; 非首次启动：启动时间 登录 每隔3秒获取一次 获取Crash/ANR数据 电量测试: 手机前台亮屏10mins &amp;mdash; 按Home键放后台灭屏10mins &amp;mdash; 退出应用后灭屏10mins 流量测试: 手机待机10mins &amp;mdash; 按Home键放后台运行10mins &amp;mdash; 退出应用后待机10mins  稳定性测试  短时多次求出错次数(5mins x 50次) 长时单次求无故障时长(10~100 hours) 弱网络测试  安全测试  WebService iPhone Configuration Utility Android Developer Tools: DDMS SQLite数据库 App请求中⽤用户信息  自动化测试 方式：
 应用最新/最成熟的自动化技术和工具 应用业界最佳实践  目地：
 降低成本并提高产出(ROI) 缩短发布时间 提升测试效率、可重用性、稳定性和一致性  性能测试 实现整体系统性能需求，满足以下方面：
 速度 可靠性 可扩展性 效率  </content>
    </entry>
    
     <entry>
        <title>测试数据</title>
        <url>https://xulizhao.com/blog/test-data/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 测试替代技术  Test Double / 测试替身 Mocks Aren&#39;t Stubs  Mock和Stub的本质区别：测试期待结果的验证（Assert and Expectiation）
 对于 Mock 代码来说，我们的关注点是 Mock 方法有没有被调用，以什么样的参数被调用，被调用的次数，以及多个 Mock 函数的先后调用顺序。所以，在使用 Mock 代码的测试中，对于结果的验证（也就是 assert），通常出现在 Mock 函数中。 对于桩代码来说，我们的关注点是利用 Stub 来控制被测函数的执行路径，不会去关注 Stub 是否被调用以及怎么样被调用。所以，你在使用 Stub 的测试中，对于结果的验证（也就是 assert），通常出现在驱动代码中。  桩代码（stub）  用来代替真实代码的临时代码 对顶层或上层模块进行测试时所编写的替代下层模块的程序 仅用于替代当前代码依赖  目的：
 起到了隔离和补齐的作用，使被测代码能够独立编译、链接，并独立运行 还具有控制被测函数执行路径的作用  Mock  经过编程，可以做检查并发送符合规则的响应 更强大的能力：验证这个 Mock 对象在方法调用过程中的使用情况，比如调用了几次  具体框架 Mock框架  Martian : HTTP/S proxies,Go实现 by Google mountebank : nodejs实现，基于配置的实现 Google Test: C&#43;&#43; 测试  单元测试  Mockito : Java Moco : Java,stub Mock框架  录制回放类 录制 HTTP/HTTPS 请求然后回放之前录制的HTTP事务(称为情景)
 GoReplay : Go实现 mockingjay server: Go实现，不需要编码 VCR.py: python实现 Flashback: Java实现  </content>
    </entry>
    
     <entry>
        <title>自动生成SSL证书的利器acme.sh</title>
        <url>https://xulizhao.com/blog/acme/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>web</tag><tag>security</tag>
        </tags>
        <content type="html"> 已经使用letsencrypt的免费证书一段时间了，是之前折腾Ghost博客时自动安装的，而后台其实也是用的acme.sh这个工具。
遇到的问题是不知哪里的配置错误，我的证书自动更新有问题，每次都是遇到证书已经过期，网站彻底不能访问了，必须要手动更新。
之前用的HTTP的验证方式，由于一知半解，这块每次手动配置也会花费一些时间。
今天重读了官方文档，才发现有一些细节的使用，其实可以做到一劳永逸。
安装 curl https://get.acme.sh |sudo sh# 默认安装在~/.acme.sh/# 每天0点自动检测是否过期，并会通过cronjob自动更新证书生成证书 支持两种验证方式。 注：记得带上www.mydomain.com这种形式的域名。
HTTP 我之前一直用这种，相比DNS方式还是麻烦些。
acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/xulz/wwwroot/mydomain.com/# 之前都不知道还可以指定nginx智能识别acme.sh --issue -d mydomain.com --nginxDNS 这个是真的自动化了。
# 以阿里云为例# 下面的信息存在~/.acme.sh/account.conf，也可以手动修改export Ali_Key=&amp;#34;sdfsdfsdfljlbj&amp;#34;export Ali_Secret=&amp;#34;jlsdflanljkljlfdsaklkjflsa&amp;#34;acme.sh --issue --dns dns_ali -d mydomain.com -d www.mydomain.com安装证书 这步常被忽略。 注： 默认生成的证书都放在安装目录下: ~/.acme.sh/, 请不要直接使用此目录下的文件
# 注：Nginx 的配置 ssl_certificate 需要使用 /etc/nginx/ssl/fullchain.cer acme.sh --installcert -d &amp;lt;domain&amp;gt;.com \ --key-file /etc/nginx/ssl/&amp;lt;domain&amp;gt;.key \ --fullchain-file /etc/nginx/ssl/fullchain.cer \ --reloadcmd &amp;#34;service nginx force-reload&amp;#34;其他 # 更新acme.sh# V2版本已支持wildcard证书acme.sh --upgrade# 调试，打印更详细信息acme.sh --issue ... --debug </content>
    </entry>
    
     <entry>
        <title>JVM和GC调优</title>
        <url>https://xulizhao.com/blog/jvm/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>performance</tag>
        </tags>
        <content type="html"> 曾多次接触Java的GC参数调优和日志分析，零散的记录在各处，时间一长也忘的差不多了，汇总于此。
Hotspot JVM 这里的JVM特指Oracle的 Hotspot JVM. 由 class loader, the runtime data areas（含heap）, 和execution engine（含GC和JIT）三部分组成。 Heap主要用于对象数据的存放。
性能优化主要涉及heap大小和适合的GC算法的调优。 优化着重于两个目标：
 响应能力：长时间的停顿不可接受 吞吐率：较长一段时间的处理量，快速响应不是必须的。  查看当前JVM设置 Spring Boot应用默认使用系统JVM内存设置。
# 当前环境的常用默认值java -XX:&#43;PrintFlagsFinal -version | grep -iE &amp;#39;HeapSize|PermSize|ThreadStackSize&amp;#39;查看运行JVM进程 # 使用jps查看进程idjps -v# 使用jmapjmap -heap &amp;lt;pid&amp;gt;常用设置 # 查看常用命令参数java -X# 设置最大heap sizejava -Xmx4GSpring Boot2 设置  java -Xmx4g -jar my-springboot-app.jar
 &amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;jvmArguments&amp;gt;-Xmx4G&amp;lt;/jvmArguments&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/plugin&amp;gt;GC主要算法 Serial -XX:&#43;UseSerialGC
Parallel JDK8默认值。 -XX:&#43;UseParallelGC -XX:&#43;UseParallelOldGC
CMS 新生代使用Parallel New &#43; 老年代使用CMS（Concurrent Mark-Sweep Collector）。
-XX:&#43;UseParNewGC -XX:&#43;UseConcMarkSweepGC
前三种算法的Heap堆结构：  Young Generation = eden &#43; Survivor Space(S0&#43;S1) Old Generation == Tenured Permanent Generation == Permanent  G1 代表Garbage First，适用于多核和超大内存的情况，需要JDK7u4&#43;。 是CMS的替代方案，被划分为相同大小的区域，由eden,survivor和old三部分组成。 使用场景：Heap 6G&#43; 或要求停顿时间小于0.5s
-XX:&#43;UseG1GC
其他参数：
 -XX:MaxGCPauseMillis=200 （默认200ms） -XX:InitiatingHeapOccupancyPercent=45 （默认45%，开始并发GC Cycle） -XX:G1ReservePercent=10（默认10%，提高以避免 to-space overflow错误）  通常2000个区域，每个区域1~32Mb。
注：不要设置新生代大小（-Xmn）
调优 建议：老年代占用率至少大于新生代活跃数据的1.5倍，新生代空间大小至少为堆大小的10%.
主要触发事件：
新生代用完会触发Minor GC，时间通常很快； 老年代（tenure&#43;perm）用完会触发Full GC,时间通常较长。 原始是更频繁的Minor GC和更少的Full GC。
Heap Size = Young Gen &#43; Old Gen &#43; Meta space
主要参数  -Xms Heap初始大小 -Xmx Heap最大值 -Xmn 新生代Heap大小（推荐不设置，使用则该值不能太大）  XMX和XMS设置一样大,减轻伸缩堆带来的压力　JVM占用内存会超过Xmx大致1/3, 因此Xmx的值不应超过总内存的60%~70%.　-X 是设置JVM参数的新命令，不带-X 的是为了兼容之前版本.
打印默认参数 java -XX:&#43;PrintFlagsFinal -version
Thread Stack Size Java 8 64bit 默认1024k. 每个线程启动时JVM为该线程创建一个新的Java Stack,在discrete frames存放线程状态,执行两类操作push和pop frames. 使用递归算法或使用第三方框架会增加该大小．
如果应用创建很多线程，在申请更多线程栈内存会报StackOverFlowError错误. 可以用设置最大线程栈内存: -Xss256k 或　-XX:ThreadStackSize=256 也可以压缩操作符和类指针: -XX:&#43;UseCompressedClassPointers -XX:&#43;UseCompressedOops
原则:
 一般没必要设置该值，除非64bit　JVM的物理内存较小产生OutOfMemory错误 设置为较小的值可以有更大的Heap size 一般来说，64bit　JVM使用256k足够用  OOM问题 针对Tomcat
# 检索gc日志grep &amp;#39;java.lang.OutOfMemoryError: GC overhead limit exceeded&amp;#39; catalina.2016-10-25.log# 记录heap dump，setenv.sh-XX:&#43;HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/tomcat/logs/GC日志 参数设置 一些gc日志参数，经常使用的: -verbosegc -Xloggc:/var/log/gc.log
设置更详细日志 -XX:&#43;PrintGC -XX:&#43;PrintGCDetails
显示时间 -XX:&#43;PrintGCTimeStamps -XX:&#43;PrintGCDateStamps
日志分析 Allocation Failure：运行GC（一般是新生代回收即minor GC）的原因，意味着新生代已没有空间.
一共存在8种OutOfMemoryErrors , GC日志可以记录5种:
 Java heap space GC overhead limit exceeded Requested array size exceeded VM limit Permgen space Metaspace  名称缩写  JRE: Java Runtime Environment JDK: Java Development Kit JVM： Java Virtual Machine GC: Garbage Collection JMX: Java Management Extentions JPA: Java Persistence API  工具 GC日志分析  jstat: 命令行工具 Visual GC GCViewer 在线gc日志分析  Heap Dump分析  JHAT   jhat heap-dump.hprof
  Eclipse Memory Analyzer (MAT) IBM HeapAnalyzer:貌似已停更  获取heap dump  jmap -dump : 运行时获得(会停止java进程) JConsole使用 HotSpotDiagnosticMXBean 使用JVM参数 -XX:&#43;HeapDumpOnOutOfMemoryError 使用hprof命令: java -agentlib:hprof=help  参考资源 官方文档：
 Getting Started with the G1 Garbage Collector HotSpot Virtual Machine Garbage Collection Tuning Guide Java Virtual Machine Troubleshooting  其他：
 GC Handbook ： GC手册 JVM Anatomy Park ：深入讲解JVM How to Tune Java Garbage Collection </content>
    </entry>
    
     <entry>
        <title>Java I/O学习</title>
        <url>https://xulizhao.com/blog/java-io/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Java系列记录文章.
文件操作  包 java.nio.file  常用类及方法：
 Files  readAllBytes readAllLines write(Path,,StandardOpenOption.CREATE) newInputStream/newOutputStream   Paths 和Path  Paths.get getName getParent deleteIfExists   File  toPath    // 当前路径String currentDir = System.getProperty(&amp;#34;user.dir&amp;#34;);// lsFiles.list(Paths.get(&amp;#34;.&amp;#34;)).forEach(System.out::println);Stream&amp;lt;String&amp;gt; lines = Files.lines(Paths.get(&amp;#34;META-INF&amp;#34;,&amp;#34;MANIFEST.MF&amp;#34;));// 遍历所有文件Files.walk(Paths.get(&amp;#34;.&amp;#34;)).filter(Files::isRegularFile).forEach(System.out::println);// 删除所有文件Files.walk(path).sorted(Comparator.reverseOrder()).map(Path::toFile).forEach(File::delete);// 过滤Files.lines(new File(fileName).toPath()).map(s -&amp;gt; s.trim()).filter(s -&amp;gt; !s.isEmpty()).filter(s -&amp;gt; !s.matches(&amp;#34;#.*&amp;#34;)).forEach(System.out::println);Stream/数据流 数据流是Java与磁盘,数据库,网络等源或目的媒介数据通信的描述,可分为(面向人的)字符流/Character和(面向机器的)字节流/Byte.
缓冲流避免一个一个字符的读写,更加高效,常用来包装文件读写流.
常用类如下:
 Streams/字节流:InputStream /OutputStream  面向8位字节,二进制或和机器打交道的数据 FileInputStream/FileOutputStream：从文件读取字节，将字节写入文件 ByteArrayInputStream/ByteArrayOutputStream：从内存型的数组读取字节，将字节写入内存中的数组   字符流: Reader/Writer  面向字符(16位unicode),文本或人可读数据 Reader 喜欢从字节流读取字节并转换为字符. Writer 喜欢将字符转换为字节，以便将它们放在字节流上. StringReader/StringWriter：在内存的 String 中读取和写入字符. InputStreamReader/InputStreamWriter和子类 FileReader/FileWriter：充当字节流和字符流之间的桥梁.   缓存流: 读大文件或频繁读有更高的性能  BufferedReader / BufferedWriter：在读取或写入另一个流时缓冲数据，使读写操作更高效.    行操作  reader.readLine(): 只支持字符 Scanner: 功能更强 PrinterWriter: 支持多种类型或格式定义printf System.out是一个PrintStream对象  注： 流操作要记得关闭资源，通常是外层的Buffer对象，避免占用文件句柄不释放。推荐使用try-with-resources(){}
double hoursWorked;Scanner inFile = new Scanner(new FileReader(&amp;#34;employee.dat&amp;#34;));hoursWorked = inFile.nextDouble();// 两个true参数代表开启追加模式和开启自动flushPrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(&amp;#34;books.txt&amp;#34;,true)), true);异常  IOException  EOFException FileNotFoundException    扩展阅读  Reading and writing files in Java (Input/Output) - Tutorial Java I/O 学习 Java教学大纲 </content>
    </entry>
    
     <entry>
        <title>Java设计模式</title>
        <url>https://xulizhao.com/blog/java-patterns/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Java的世界，你需要知道设计模式^_^
设计模式概述  解决代码可扩展性问题 创建型，结构型，行为型  工厂模式 单例 单线程 final class Singleton {private static Singleton instance = null;private Singleton() {}public static Singleton getInstance() {if (instance == null) {instance = new Singleton();}return instance;}}多线程/线程安全 final class Singleton {private static volatile Singleton instance = null;private Singleton() {}public static Singleton getInstance() {if (instance == null) {synchronized (Singleton.class) {if (instance == null) {instance = new Singleton();}}}return instance;}}内部类实现：
public class SingletonUsingInnerClass {private SingletonUsingInnerClass() {}private static class LazySingleton{private static final SingletonUsingInnerClass SINGLETONINSTANCE = new SingletonUsingInnerClass();}public static SingletonUsingInnerClass getInstance(){return LazySingleton.SINGLETONINSTANCE;}}// Effective Java作者提倡用单元素的枚举类型，避免多线程和反序列化重现创建新对象public enum Singleton {INSTANCE;public void whateverMethod() {}}每个线程一个单例 当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。
public class Singleton {private Singleton() {}private static ThreadLocal&amp;lt;Singleton&amp;gt; _threadLocal =new ThreadLocal&amp;lt;Singleton&amp;gt;() {@Overrideprotected Singleton initialValue() {return new Singleton();}};// 返回ThreadLocal 单例 public static Singleton getInstance() {return _threadLocal.get();}}Adaptor/Listener observer/观察者 主要实现分布式事件处理系统，是MVC（Model–View–Controller）结构的主要模式。
用UML来表示:
Observablem_observerCollectionf_registerObserver(observer)f_unregisterObserver(observer)f_notifyObservers():for observer in observerCollection:call observer.notify()Observerf_notify()扩展阅读  Design patterns implemented in Java/github:各种模式的Java实现 https://www.javacodegeeks.com/2014/05/java-singleton-design-pattern.html </content>
    </entry>
    
     <entry>
        <title>Java集合类</title>
        <url>https://xulizhao.com/blog/java-collections/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Java系列记录文章。
集合  在 Java 编程中，可以将某种类型的变量赋给另一种类型，只要被赋值的变量是赋值变量所实现的超类或接口。
 内置方法
 clone() ： Deep Copy 不改变原数据 Collections.nCopies(1000, new Object()) : 填充N个默认对象副本 Collections.copy(list, list) Collections.sort(list)  List/列表 接口 是一种有序集合，也称为序列，实现了Iterable 接口。
常用方法：
 add(): 添加到末尾 size(): 获取大小 get(index): 检索某项  常用实现：
 ArrayList: get()/set() LinkedList: add()/remove()的性能更好  List&amp;lt;String&amp;gt; list = Arrays.asList(&amp;#34;Lars&amp;#34;, &amp;#34;Simon&amp;#34;);list.forEach(System.out::println);// 排序list.sort(null);list.sort((s1,s2)-&amp;gt; s1.compareToIgnoreCase(s2));list.sort(String::compareToIgnoreCase);//removeIf 条件删除list.removeIf(s-&amp;gt; s.toLowerCase().contains(&amp;#34;x&amp;#34;));// Deep CopyArrayList&amp;lt;String&amp;gt; copy = (ArrayList&amp;lt;String&amp;gt;) al.clone();数组和集合的转换 数组转集合
 Arrays.asList(): 返回不可变集合(只可通过set修改原值)，不能做修改个数操作。 如果需要，则创建新集合new java.util.ArrayList(Arrays.asList(数组))  集合转数组
toArray()无参会导致泛型丢失
Set/集 包含唯一元素（没有重复元素），确保唯一性，但不保证（添加）顺序。
接口的常用实现是HashSet。
Map/映射 接口 键值对集合。
 HashMap  getOrDefault() 取值,如果不存在用默认值 computeIfAbsent() 存值,如果不存在用默认值    map.put(&amp;#34;key&amp;#34;,&amp;#34;value&amp;#34;);map.remove(&amp;#34;Android&amp;#34;);// keys to Arrayreturn map.keySet().toArray(new String[map.keySet().size()]);// keys to ListList&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;(map.keySet());Iterable/迭代变量 快速迭代语法：
 for (objectType varName : collectionReference) {}
 规范  集合初始化时要指定集合初始化大小。默认ArrayList为10，HashMap为16.  泛型/Generics 声明时用&amp;lt;&amp;gt;指明特定类型，确保类型安全，属于编译时特性。
约定T/Type,K/Key,V/Value,E/Element
Bounded Generics: 方法接受一种类型和它的所有子类(upper bound) 或类型和它的所有超类 (lower bound).
 List&amp;lt;?&amp;gt;一般作为参数来接受外部的集合，或返回一个不知道具体元素类型(类型未知)的集合。      // 泛型方法// 返回类型前有类型参数定义,可以有多个以&amp;#34;,&amp;#34;分开的类型参数public &amp;lt;T&amp;gt; List&amp;lt;T&amp;gt; fromArrayToList(T[] a) {return Arrays.stream(a).collect(Collectors.toList());}扩展阅读  http://tutorials.jenkov.com/java-collections/index.html http://www.vogella.com/tutorials/JavaCollections/article.html Java Generics </content>
    </entry>
    
     <entry>
        <title>全链路压测笔记续</title>
        <url>https://xulizhao.com/blog/more-load-test-note/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>performance</tag>
        </tags>
        <content type="html"> 看完美团的分享觉得不过瘾，继续学习其他大厂的分享。
不用猜，第一个搞出这套系统的一定是阿里，因为他的双11需求最迫切。
阿里分享 2013年为了双11提前预演而诞生,该服务已提供在阿里云PTS铂金版。
 系统稳定性保障核武器——全链路压测 双11核武器——全链路压测详解  可用性及单机压测问题 系统可用性问题 经常由下面一些不确定性因素引起：
 系统容量 业务性能 基础设施瓶颈 中间件瓶颈 系统直接的依赖影响  传统线上单机与单系统压测的四种方式  模拟调用者压测生产环境：读请求&#43;写请求（需要特定处理） 流量录制和回放：快速率回放对单机压测  从流量分配的角度，将流量集中到某台机器（这两种方式要求访问流量不能太小）：
 请求流量转发 改变负载均衡的权重  单系统压测的问题  在做单个系统的容量规划时，所有的依赖环节能力是无限的，进而使得我们获取的单机能力值是偏乐观的； 采用单系统规划时，无法保证所有系统均一步到位，大多数精力都集中核心少数核心系统； 部分问题只有在真正大流量下才会暴露，比如网络带宽等等。  全链路压测组成 单链路指一个业务线。
全链路压测是一个模拟线上环境的完整闭环，由5大核心要素组成：
 压测环境：对应用户真实的线上环境，具备数据与流量隔离能力的生产环境； 原则：能够用中间件解决的问题，绝不对业务系统进行改造，系统所需做的是升级中间件，这一原则极大提高了工作效率。 压测基础数据：构造满足高峰场景的核心基础相关数据，影子库里构造相同量级的数据； 真实线上数据筛选脱敏。 压测流量（模型、数据）：成百上千的接口组合，到复杂的接口之间的参数传递，复杂的条件判断来构造精准的全局流量模型，和真实业务情况保持一致；   压测引擎的三层结构： * 协议支持 * 请求发送：CGroup资源隔离，异步Reactor模型发送请求，链路间线程池隔离 * 集群协作： Master，Slave长连接； Cristian算法同步网络延迟，Slave动作一致；
 流量发起：模拟全国各地真实的用户请求访问，探测站点能力； 问题定位：多维度的监控和报表，服务端可通过其他生态产品协助定位。  翻译构造能力的体现：便捷的构造全局业务场景和流量数据的能力。
原子因素：链路（被压测的最小单位） 指令： 思考时间、集合点、条件跳转、cookie存取、全局准备、并发用户限制等
原子因素-&amp;gt;串行链路-&amp;gt;场景
超限后的流量控制  丢弃请求 对下游降级 黑白名单 请求排队  流量平台数据量  T级别的压测请求数据 每秒1600W&#43;次请求压测能力 维持1亿&#43;的无线长连接和登陆用户 秒级的智能数据调度和引擎调度能力  京东分享 ForgeBot， 2016年开发
京东全链路压测军演系统(ForceBot)架构解密
最早基于开源的NGrinder，能胜任单业务压测。Controller功能耦合重，支持的Agent数量有限。 之后开发了ForgeBot。
主要功能模块  Controller：任务分配 Task Service：负载任务下发，支持横向扩展。提供任务交互和注册服务。（gRPC:HTTP2&#43;protobuf3） Agent：注册心跳，拉取任务、更新任务状态、 执行和停止worker process（采用Docker容器部署） Monitor Service:接受并转发压测数据给JMQ DataFlow:对压测数据做流式计算(输出TPS,TP999,TP99,TP90,TP50,MAX,MIN)，将计算结果存到DB(ES)  在管理端创建测试场景，Controller扫描发现场景，寻找空闲Agent资源。
任务分配时，Controller计算每个间隔的执行时间点和递增的虚拟用户数，由Agent动态加压减压。
在多个组件使用了gRPC框架通讯
分读压测和写压测
一些解决问题的思路 问题：如何模拟在某一个瞬间压力达到峰值？ 解决方案：通过集合点功能实现，提前开启峰值所需足够数量的线程，通过计算确定各个时间点上不需要执行任务的线程数量，通过条件锁让这些线程阻塞。当压力需要急剧变化时，我们从这些阻塞的线程中唤醒足够数量的线程，使更多的线程在短时间进入对目标服务压测的任务。
问题：为了计算整体的 TPS，需要每个Agent把每次调用的性能数据上报，会产生大量的数据，如果进行有效的传输？ 解决方案：对每秒的性能数据进行了必要的合并，组提交到监控服务
饿了么分享 饿了么全链路压测平台的实现与原理
业务模型的梳理  是否关键路径 业务的调用关系 业务的提供的接口列表 接口类型(http、thrift、soa等) 读接口还是写接口？ 各接口之间的比例关系  数据模型的构建 写请求 压测方法：
 用户、商户、菜品等在数量上与线上等比例缩放； 对压测流量进行特殊标记； 根据压测标记对支付，短信等环节进行mock； 根据压测标记进行数据清理；  读请求 压测方法：拉取线上日志，根据真实接口比例关系进行回放
无日志服务 压测方法：
 构建压测数据使缓存命中率为0%时，服务接口性能，数据库性能； 缓存命中率为100%时，服务接口性能； 缓存命中率达到业务预估值时，服务接口性能；  压测工具 定制JMeter
压测指标监控和收集  应用层面 服务器资源 基础服务：中间件和数据库  要点：
 响应时间不要用平均响应时间，关注95线； 吞吐量和响应时间挂钩 吞吐量和成功率挂钩  具体实现 SpringBoot&#43;AngularJS.
测试期间产生的冷数据(用例数据、结果数据)持久化至MongoDB，热数据(实时数据)持久化至InfluxDB并定期清理。
分布式测试：重新实现JMeter的分布式调度 测试状态流转：各种流程形成闭环，要考虑各种异常。 主要流程：配置 -&amp;gt; 触发 -&amp;gt; 运行 -&amp;gt; 结果收集 -&amp;gt; 清理。
整个状态流转的实现，采用异步Job机制实现了类似状态机的概念，状态属性持久化到数据库中，便于恢复。
安全保障 由于是在线上真实环境，需要避免测试引起的服务不可用和事故。
 权限管理：用户权限分级管理，不能随意触发他人的测试用例，同时高峰期和禁止发布期，不允许执行任何测试。 停止功能：这是面向用户的手动停止功能，用户可以随时点击运行状态下的测试用例上的停止按钮，后台会直接kill掉所有运行该测试用例的测试机上的JMeter进程。 熔断功能：系统会根据实时信息中的错误率进行判断，当一定时间内的实时错误率达到或超过某个阈值时，该次测试将被自动熔断，无需用户干预。 兜底脚本：最极端的情况，当整个系统不可用，而此时需要停止测试时，我们提供了一份外部脚本直接进行停止。 </content>
    </entry>
    
     <entry>
        <title>美团全链路压测Quake学习笔记</title>
        <url>https://xulizhao.com/blog/meituan-load-test-note/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>performance</tag>
        </tags>
        <content type="html"> 今天读了美团技术团队新发布的全链路压测平台Quake在美团中的实践，做个笔记。
先说下总的读后感:
压力测试/性能测试有多种方式，从下面的几个发展阶段可以看出越来越追求真实高峰访问的模拟。
现在大公司普遍的分布式架构，云计算的应用，容器的使用也可以提供更有力的资源调度。但全链路压测最重要的工作在于需要架构，开发团队的支持和适配工作。
没有全链路的监控及相关工具支撑，没有架构的调整（压测标识）和数据库的配合（影子表），这个全链路压测就是个听起来更美的名字（你也知道技术圈喜欢造新词）。
印象中APM/Application Performance Management 前几年就挺火的，现在各大厂又都在提全链路了。
 文章笔记摘要
 背景 要解决的问题  验证峰值流量下服务的稳定性和伸缩性 验证新上线功能的稳定性 进行降级、报警等故障演练 对线上服务进行更准确的容量评估  压力测试方式的几个阶段  对线上的单机或集群发起服务调用 将线上流量进行录制，然后在单台机器上进行回放 通过修改权重的方式进行引流压测 全链路压测  全链路压测介绍 基于线上真实环境和实际业务场景，通过模拟海量的用户请求，对整个系统进行压力测试。
主要特征：
 真实流量 线上环境 实时监控和过载保护  核心功能 数据构造 回放业务高峰期产生的流量
 HTTP： Nginx Access Log分析 RPC：对部分机器录制  通过以上两种方式生成压测词表（词表分片处理，方便后续批量加载）
压测隔离 添加压测标识，各服务和中间件依据标识来进行压测服务的分组和影子表方案的实施。
在请求头添加特殊标识，但需要保证线程间和跨服务间透传。
链路诊断功能方便定位问题。
服务隔离 通常选择深夜低峰压测，同时隔离正常流量和测试流量。 隔离策略：基于IP，机器数，百分比
数据隔离 影子表（阿里）：使用线上同一个数据库，包括共享数据库中的内存资源，只在写入数据时写进另一个影子表。 KV的处理类似，MQ则选择生产端或消费端忽略消息。
调度中心 资源计算预估  压测期望到达的QPS 压测请求的平均响应时间和请求/响应体大小 压测的词表大小、分片数 压测类型  事件注入机制 根据系统的实际情况对压力进行相应调整。
 调整QPS 触发熔断 开启事故注入 开启代码级性能分析  代码设计：观察者模式（会触发的事件）和责任链模式（执行事件）
熔断保护机制 客户端熔断： 根据业务自定义的熔断阈值，实时分析监控数据，当达到熔断阈值时，任务调度器会向压测引擎发送降低QPS或者直接中断压测的指令，防止系统被压挂。
</content>
    </entry>
    
     <entry>
        <title>再学游泳</title>
        <url>https://xulizhao.com/play/swimming/</url>
        <categories>
          <category>play</category>
        </categories>
        <tags>
          <tag>health</tag>
        </tags>
        <content type="html"> 最近再次开始学游泳，距离初次学蛙泳已经过去了10多年。当时还在大学蹭宿舍，因为一直很喜欢向往大海，便让老同学教我蛙泳。 期间由于基础不行，某次在深水区溺水给我留下了阴影，之后参与便不积极，直到搬家远离了游泳馆，便不再接触该运动了。 这段时间有短短续续的一年多，现在想来最后可能也就40～50分，主要是基础动作不对，连续换气困难，对深水不自在。
这次的契机是8月初公司组织去南戴河，去之前复习了游泳，结果到海里一旦脚够不着底就很慌不敢游，也呛了好几口海水。回来后从知乎开始学习，跟着“网红”教练梦觉（易鑫海）又到B站，几乎看了所有视频，受益良多。
现在水性（和水的亲和感）好多了，学会了基本的潜泳，前滚翻，仰泳腿，也学会了踩水,可以再次游到深水区了。
蛙泳练的差不多了，现在已改学自由泳,自由泳腿刚有感觉。
能继续参与的另一个原因是之前找到运动方式要么时间空间受限，要么热情不够。而自从上个月开始游泳，每次都有小的进步，这种感觉还是很爽的。
也欢迎大家关注讲解细致幽默系统的易教练，视频里的错误动作，我这个新手80%都犯过。
 B站：https://space.bilibili.com/7283282/#/index 知乎：怎样快速有效地学习游泳？  也该感谢这个内容创业火热的年代，让优质的教学内容有好的生长空间，让自学更容易了。
</content>
    </entry>
    
     <entry>
        <title>Ubuntu日常</title>
        <url>https://xulizhao.com/blog/ubuntu/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> 很早就接触使用Ubuntu，也是自己最钟爱的Linux系统。 给Ubuntu留一篇记录日常使用。
Ubuntu 18.04安装中文输入法 sogou拼音由于不支持最新的18.04，所以安装系统自带的中文输入法。 PS. Sublime Text 3不支持中文输入也很不爽。
安装中文语言 [Settings] - [Region &amp;amp; Language],点击“Manage Insalled Languages”,点击“Install/Remove Language”,勾选“Chinese(simplified)”并点击“Apply”.
或者直接使用命令行：
sudo apt install language-pack-zh-hans language-pack-gnome-zh-hans thunderbird-locale-zh-hans firefox-locale-zh-hans kde-l10n-zhcn fonts-arphic-ukai libreoffice-l10n-zh-cn kde-config-fcitx hunspell-en-za hyphen-en-ca mythes-en-au gnome-user-docs-zh-hans fonts-arphic-uming thunderbird-locale-zh-cn libreoffice-l10n-en-za kde-l10n-engb hyphen-en-gb libreoffice-l10n-en-gb ibus-table-wubi ibus-libpinyin libreoffice-help-zh-cn thunderbird-locale-en-gb fonts-noto-cjk-extra hunspell-en-au hunspell-en-gb hunspell-en-ca libreoffice-help-en-gb 添加智能中文输入法 注： 可能需要先Logout下。
之后在[Settings] - [Region &amp;amp; Language]的“Input Sources”选择 [Chinese]-[Chinese(Intelligent Pinyin)]并添加。
Ubuntu/Linux下常用软件  图像编辑： GIMP （[编辑]-[首选项]-[界面]下设置中文） 编辑器： sublimetext3/vscode FTP： FileZilla  Ubuntu 开发环境 sudo update-alternatives --config javasudo update-alternatives --config javacLinux桌面/GNOME 桌面快捷方式通常位于以下目录:
 /usr/share/applications/ ~/.local/share/applications/ /var/lib/snapd/desktop/applications/  # 前提sudo apt-get install --no-install-recommends gnome-panel# 可以使用gnome-desktop-item-edit 方便图标编辑gnome-desktop-item-edit --create-new ~/Desktop/ gnome-desktop-item-edit --create-new /home/xulz/.local/share/applications升级 从16.04升级到18.04
sudo do-release-upgrade# 如果中途升级出错运行sudo dpkg --configure -a</content>
    </entry>
    
     <entry>
        <title>MySQL性能优化</title>
        <url>https://xulizhao.com/blog/mysql-tuning/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>database</tag><tag>mysql</tag>
        </tags>
        <content type="html"> 关于MySQL性能问题查找及优化的点滴.
常用参数 # /etc/my.cnf[mysqld]max_connections=1000 # 最大连接数innodb_buffer_pool_size=4G # 缓存池大小,建议&amp;lt; 80% 总内存# 时间超过2秒的SQL记录在慢查询日志long_query_time=2# 用以下面响应时间分布的收集query_response_time_stats = oninnodb_buffer_pool_size 推荐大小 计算RIBPS(Recommended InnoDB Buffer Pool Size)基于所有InnoDB数据大小和额外60%索引大小.
SELECT CEILING(Total_InnoDB_Bytes*1.6/POWER(1024,3)) RIBPS FROM (SELECT SUM(data_length&#43;index_length) Total_InnoDB_BytesFROM information_schema.tables WHERE engine=&amp;#39;InnoDB&amp;#39;) A;实际占用大小为:
SELECT (PagesData*PageSize)/POWER(1024,3) DataGB FROM (SELECT variable_value PagesData FROM information_schema.global_status WHERE variable_name=&amp;#39;Innodb_buffer_pool_pages_data&amp;#39;) A,(SELECT variable_value PageSize FROM information_schema.global_status WHERE variable_name=&amp;#39;Innodb_page_size&amp;#39;) B;利用多核CPU # 无限并发innodb_thread_concurrency = 0# 下面两个值最大设置为64innodb_read_io_threadsinnodb_write_io_threads检查当前慢查询并运行EXPLAIN mysql&amp;gt; SHOW FULL PROCESSLIST;# 找到上面经常出现的SQL语句EXPLAIN SQL-Statement 状态sending data意味着正在等待从磁盘或内存读取数据并发送出去,即 reading and filtering data.
 PMM的MySQL Query Response Time仪表盘 PMM(Percona Monitoring and Management)的开源监控工具还是很好用的.
安装PMM服务端 建议使用docker的方式
# 获取镜像docker pull percona/pmm-server:latest# 创建容器docker create \ -v /opt/prometheus/data \ -v /opt/consul-data \ -v /var/lib/mysql \ -v /var/lib/grafana \ --name pmm-data \ percona/pmm-server:latest /bin/true# 运行docker run -d \ -p 80:80 \ --volumes-from pmm-data \ --name pmm-server \ --restart always \ percona/pmm-server:latest配置客户端 (在运行MySQL的主机) yum install -y pmm-client# Ubuntu 先获取# wget https://www.percona.com/downloads/pmm/1.13.0/binary/debian/xenial/x86_64/pmm-client_1.13.0-1.xenial_amd64.debsudo pmm-admin config --server 192.168.100.1# 可选项 —server-user admin —server-password adminsudo pmm-admin add mysql —user root —password password# 查看当前状态sudo pmm-admin listpmm-admin使用  pmm-admin ping pmm-admin config pmm-admin info pmm-admin stop —all pmm-admin uninstall  设置以记录Response Time分布 安装必要的插件:
mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME &amp;#39;query_response_time.so&amp;#39;;mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME SONAME &amp;#39;query_response_time.so&amp;#39;;mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME_READ SONAME &amp;#39;query_response_time.so&amp;#39;;mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME_WRITE SONAME &amp;#39;query_response_time.so&amp;#39;;# 检查当前安装插件状态mysql&amp;gt; SHOW PLUGINS;开启数据收集:
SET GLOBAL query_response_time_stats = &amp;#39;ON&amp;#39;;# 检查是否生效show variables like &amp;#39;%query_response_time%&amp;#39;;资源  EXPLAIN执行计划讲解 PMM Server官方文档 </content>
    </entry>
    
     <entry>
        <title>Java应用的数据库迁移工具Flyway</title>
        <url>https://xulizhao.com/blog/flyway/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>database</tag>
        </tags>
        <content type="html"> 最近折腾部署一年前的一个应用,发现一些由于一些细节已经忘记,常常可能多花费几个小时去重新解决问题的过程. 而有的过程之前写过KB,关键字一搜索就出来能省不少时间.
所以对于健忘的自己,还是多些记录,也不介意技术含量这个概念了.
印象中flyway应该是Java生态中很成熟的一个解决方案了,简略的记下使用过程.
安装 # Linuxwget -qO- https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/5.2.4/flyway-commandline-5.2.4-linux-x64.tar.gz | tar xvz &amp;amp;&amp;amp; sudo ln -s `pwd`/flyway-5.2.4/flyway /usr/local/binwget https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/5.2.4/flyway-commandline-5.2.4-linux-x64.tar.gztar xzf flyway-commandline-5.2.4-linux-x64.tar.gz# 可选cp mysql-connector-java-5.1.41.jar /opt/flyway-5.2.4/drivers/配置 主要在conf/flyway.conf文件
# 必需项flyway.url=jdbc:mysql://&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;database&amp;gt;flyway.user=testflyway.password=test# 升级数据库脚本位置flyway.locations=filesystem:/opt/db/migration/# 可选# 用于非空数据库首次使用flyway.baselineOnMigrate=true使用 # 清空数据./flyway clean# 指定配置文件./flyway -configFiles=./conf/flyway.conf clean# 升级/迁移数据./flyway migrate资源  Flyway官网 </content>
    </entry>
    
     <entry>
        <title>Go并发编程笔记</title>
        <url>https://xulizhao.com/blog/go-concurrency/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 最近尝试用Go重写之前用Python开发的一个工具,感觉一直工作于Hard模式,可是又不想轻易的放弃Golang的实践,变成遇到一些问题而从入门到放弃.
还好一周周坚持了下来,虽然遇到一个问题可能会解决多半天甚至一天多时间,还是有所学的.
今天整理下关于并发编程,也就是Go核心亮点goroutine使用中可能遇到的问题.
敲重点 一定打开 -race 命令行参数 该标记会打印产生读写冲突/数据竞争的错误及stacktrace, 避免到生产环境才发现问题. 绝对是提早排查的利器, 也算Go的优势之一 :)
其他应用: 该参数也可以加在test,build,run等命令, 由于生成带检测的build会消耗更多内存和CPU,建议生产环境不要部署或只部署其中一台节点.
并发Map 默认的map是不支持并发读写的, 如果违法了后果很严重,主程序直接异常退出,通常会看到如下的错误:
 fatal error: concurrent map writes
 解决方式有三个:
 仍使用原生map,用sync.RWMutex加锁 使用 1.9 引入的 sync.Map, 适用于读远大于写的情景(方法少了些) 使用 第三方库concurrent-map （sharding方式,更适合以内存数据库方式使用）  // 加锁的示例, 修改自SO的一个例子// 锁可以被任意读或唯一的写协程所持有var m = map[string]int{&amp;#34;a&amp;#34;: 1}var lock = sync.RWMutex{}func read() {lock.RLock()_ = m[&amp;#34;a&amp;#34;]lock.RUnlock()}func write() {lock.Lock()m[&amp;#34;b&amp;#34;] = 2lock.Unlock()}Goroutines  发送和接收两个操作都使用&amp;lt;-运算符. 在接收语句中，&amp;lt;-运算符写在channel对象之前 如果channel的容量大于零，那么该channel就是带缓存的channel. 无缓存Channels有时候也被称为同步Channels。 happens before 要表达的意思是要保证在此之前的事件都已经完成了 避免“循环变量快照”  sync.WaitGroup 使用buffered channel作为一个计数信号量
sync.Mutex  不要使用共享数据来通信；使用通信来共享数据。 一个只能为1和0的信号量叫做二元信号量(binary semaphore)。 惯例来说，被mutex所保护的变量是在mutex变量声明之后立刻声明的 用defer来调用Unlock，临界区会隐式地延伸到函数作用域的最后 “多读单写”锁(multiple readers, single writer lock)是sync.RWMutex 一次性初始化 Sync.Once net/http包提供了一个请求多路器ServeMux来简化URL和handlers的联系  mu sync.MutexChannel/信道 默认情况下，发送和接收操作在另一端准备好之前都会阻塞。这使得 Go 程可以在没有显式的锁或竞态变量的情况下进行同步。
 channel会返回两个值，一个是内容，一个是还有没有内容 channel是通过注册相关goroutine id实现消息通知的 发送者只有在必须告诉接收者不再有值需要发送的时候才有必要关闭/close信道（只有发送者才能关闭信道，而接收者不能）  带缓冲的信道 仅当信道的缓冲区填满后，向其发送数据时才会阻塞（阻塞写）。当缓冲区为空时，接受方会阻塞（阻塞读）
select  select 语句使一个goroutine 可以等待多个通信操作。 select 会阻塞到某个分支可以继续执行为止，这时就会执行该分支 当 select 中的其它分支都没有准备好时，default 分支就会执行。不想阻塞发送和接受时使用。  规范  goroutine记得return或者中断，不然容易造成goroutine占用大量CPU </content>
    </entry>
    
     <entry>
        <title>开源消息队列实现</title>
        <url>https://xulizhao.com/blog/mq/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>message</tag>
        </tags>
        <content type="html"> 经常会遇到系统中使用Message Queue/消息队列的情况, 与此类似的模型还有 pubsub/发布订阅模式(publisher/subscriber).
这两种模型的实现也被看做 消息中间件/MOM(Message-Oriented Middleware),因为这种结构解耦了发送端和接收端,简化了架构.
另外常提的一个概念是Messaging Broker, 更多的用于消息验证,转换,路由.
现在有很多流行的开源实现, 对于消息有常用的三种标准:
 AMQP: Advanced Message Queuing Protocol STOMP: Streaming Text Oriented Messaging Protocol MQTT/ MQ Telemetry Transport: 轻量级协议,IoT标准  其他
 XMPP/Extensible Messaging and Presence Protocol: 基于XML的通讯协议  前两个基于HTTP, 后一个基于TCP/IP.
下面是一些实现的概要描述, 这些实现的比较不全在同一纬度, 只是看那个更适合你的应用场景,语言绑定等.
开源实现    名称 语言 星数 描述     ActiveMQ Java 1.1 k Apache基金旗下, 支持JMS   RabbitMQ Erlang 4.3k 貌似MQ系列的首选,成熟且性能高   ZeroMQ C&#43;&#43; 4.4k 高度封装并支持多种收发模式。点对点的消息传输上，能在发送端缓存消息   Celery Python 10k 异步任务队列,常用于耗时操作的异步执行   Redis C 30.3k 最流行的内存KV数据库/缓存   Kafka Java/Scala 9k 早期LinkedIn开源产品,后归于Apache基金. 常用于日志处理分析   NATS Go 4.4k CNCF孵化项目   NSQ Go 12k 项目近期发布不活跃    注: 只接触过Celery,Redis和Kafka, MQ系列没有使用经验不做过多介绍.
示例 TBC&amp;hellip;
</content>
    </entry>
    
     <entry>
        <title>网络基础</title>
        <url>https://xulizhao.com/blog/network/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>networking</tag>
        </tags>
        <content type="html"> 好记性不如烂笔头, 网络基础知识备忘.
OSI 7层模型 OSI/开放式系统互联通讯参考
 7: 应用层: HTTP,FTP,Telnet, SSH, SMTP, POP3 6: 表达层 5: 会话层 4: 传输层: TCP 3: 网络层: IP 2: 数据链路层: 以太网,WiFi,GPRS 1: 物理层 : 数据帧传输,包括网卡,集线器,主机适配器等  注: OSI参考模型不是一个标准,也没有提供实现方法,而且概念性框架.
TCP/IP协议集 互联网基础协议, 可以被认为是简化版OSI模型
 应用层: HTTP, DNS 传输层: TCP, UDP 网络互连层(internet): IP  基于IP的高层协议  ICMP: IP发送诊断信息 IGMP: 管理多播数据     网络接口层(link): 以太网等  每个应用层协议一般会使用到两个传输层协议之一:
 面向连接的TCP传输控制协议 无连接的包传输的UDP用户数据报文协议  常用协议归类
 运行于TCP协议上的协议: HTTP/HTTPS/FTP/POP3/SMTP/TELNET/SSH 运行于UDP协议上的协议: BOOTP/NTP/DHCP 运行于TCP和UDP的协议: DNS/ECHO 其他协议: SNMP(简单网络管理协议)/ARP(地址解析协议)  DNS/域名系统  域名和IP地址互相映射的分布式数据库. 使用TCP和UDP的53端口. 每级域名长度限制63,域名总长度不超过253字符.  记录类型  主机记录/A记录: 将特定的主机名映射到对应主机的IP地址上 别名记录/CNAME记录: 将某个别名指向到A记录 IPv6主机记录/AAAA记录: 与A记录对应, 映射到IPv6地址 服务位置记录/SRV记录: 定义提供特定服务的服务器位置,如hostname,端口等  实现 全球有13组,504个根域名服务器, 为层次结构.
常用软件实现:
 BIND/Berkeley Internet Name Domain CoreDNS: Kubernetes默认的DNS Server  WHOIS/域名数据库查询
新的规定,域名机构不能返回注册者隐私信息.
NAT/网络地址转换 IP数据包通过路由器/防火墙时重写来源/目的IP的技术.
重写源/目的IP和端口.
解决的问题:
 局域网环境只有一个公网IP 负载均衡: 重定向到随机服务器 失效终极: 转换到备用服务器,提高可靠性 透明代理: 重定向到指定HTTP代理以缓存数据和过滤请求  HTTP/HTTP2 协议
客户端(用户)和服务器端(网站)请求和应答标准.
请求方法 GET/HEAD/POST/PUT/DELETE/TRACE/OPTIONS/CONNECT/PATCH
HTTP服务器至少应该实现GET和HEAD方法.
版本  HTTP/1.1: 1999年制定. 默认保持连接(Keep-Alive) HTTP/2: 2015年发布, 基于SPDY(Google主导的替代HTTP的项目,已被HTTP2取代). 主要为性能改进, 主流浏览器只支持加密通讯(即h2).  状态码 HTTP响应的第一行都是状态行, 状态代码是3位数字:
 1xx消息——请求已被服务器接收，继续处理 2xx成功——请求已成功被服务器接收、理解、并接受 3xx重定向——需要后续操作才能完成这一请求 4xx请求错误——请求含有词法错误或者无法被执行 5xx服务器错误——服务器在处理某个正确请求时发生错误  例子 # 请求信息:# 1. 请求行:指定方法、资源路径、协议版本# 2. 请求头(Host是必须项)GET / HTTP/1.1Host: www.google.com# 服务器应答HTTP/1.1 200 OKContent-Length: 3059Server: GWS/2.0Date: Sat, 11 Jan 2003 02:44:04 GMTContent-Type: text/htmlCache-control: privateSet-Cookie: PREF=ID=73d4aef52e57bae9:TM=1042253044:LM=1042253044:S=SMCc_HRPCQiqyX9j; expires=Sun, 17-Jan-2038 19:14:07 GMT; path=/; domain=.google.comConnection: keep-aliveIP/因特网协议 子网指具有相同的前半部分地址的一组ip地址.
子网掩码/subnet mask 目的: 用来指明一个IP地址的哪些位标识的是主机所在的网络地址以及哪些位标识的是主机地址的位掩码.
可以表示为同地址一样的形式,也可以使用更简短的CIDR/无类别域间路由表示法.
比如 192.0.2.96/28表示的是一个前28位被用作网络号的IP地址（和255.255.255.240的意思一样）
IPv4子网 IPv4地址分3个部分: 网络部分,子网部分和主机部分.
共有3类IP地址,分别指定各部分占多少位.
   类别 起始位 开始 结束 点分十进制掩码 CIDR     A 0 0.0.0.0 127.0.0.0 255.0.0.0 /8   B 10 128.0.0.0 191.255.0.0 255.255.0.0 /16   C 110 192.0.0.0 223.255.255.0 255.255.255.0 /24    Docker网络 Docker 网络实质上是操纵Network Namespace, 网桥, 虚拟网卡及iptables实现的.
OVS (Open vSwitch): 开源虚拟交换机
ip netns 管理Network Namespaceip link 管理layer2网络ip addr 管理layer3网络sudo apt install bridge-utilsbrctl show# 内核IP路由表route -n软件定义网络 flannel: 虚拟网络,给每台主机划分一个子网用于容器运行时
</content>
    </entry>
    
     <entry>
        <title>Kubernetes和云原生计算</title>
        <url>https://xulizhao.com/blog/cloud-native/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>cloud</tag>
        </tags>
        <content type="html"> 最早注意到云原生这个概念是某次看文章说Kubernetes是作为CNCF(云原生计算基金会)的主要项目来开发的,该基金会属于Linux基金会旗下,还包括被熟知的prometheus,istio等开源项目, 似乎可以理解为Kubernetes生态系统.
至此Kubernetes把微服务,十二要素,服务网格/Service Mesh等串联了起来, 符合这些概念的应用架构就是云原生应用.
云原生计算 提到云计算,现在主流的分类及代表是:
 IaaS/基础设施:AWS,OpenStack PaaS/平台: Heroku, Cloud Foundry SaaS/软件,应用:  从云计算的角度看, 云原生计算可被看做是最新发展阶段.云原生/Cloud Native的代表技术:
 容器 服务网格 微服务 不可变基础设施 声明式API  相比传统应用架构, 云原生具备的优势是:
 敏捷 可靠 高弹性 易扩展 故障隔离保护 不中断业务持续更新  技术圈的造词运动没有停止过, 下面顺便学习下这两个新词:
 Serverless/无服务器技术: 也不算新概念,这里并不是真的不需要后端服务器,而是后端服务以服务的形式提供,或被称为Backend-as-a-Service/BaaS,通常简化移动端开发部署的成本,前几年最成功的代表Parse被Facebook收购后很快关闭服务,BaaS也随之不被提及. 这两年随着Amazon Lambda服务的火热, ServerLess又被提起,同时造了个新词:FaaS/Function-as-a-Service, 这可能是云服务平台乐于推广的,不过现在看来,应用场景似乎比较受限.  扩展阅读  CNCF官网 云原生概览 云原生详解 云原生语言:Pulumi </content>
    </entry>
    
     <entry>
        <title>私有Docker仓库Harbor</title>
        <url>https://xulizhao.com/blog/harbor/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>docker</tag><tag>ops</tag>
        </tags>
        <content type="html"> 提到私有容器仓库,VMWare出品的开源Harbor算是首选.
安装和配置照官方文档来很简单,今天在尝试push镜像时遇到了如下错误: &amp;ldquo;Get https://yourdomain.com/v2/: Service Unavailable&amp;rdquo;, 检查之下发现是没有配置https引起.
配置https 虽然可以给docker常驻进程添加&amp;ndash;insecure-registry 这个参数而改用默认的http协议(需要重启docker), 但该参数会使本机所有的注册服务都不再安全, 极力不推荐这么做.
配置https的步骤其实不复杂,记录如下:
先使用mkcert生成证书和密钥, 该工具见上篇证书一文 注: mkcert的方式对docker/k8s会产生问题, 改用官方证书生成方式
# 创建CA证书openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt# 生成CSRopenssl req -newkey rsa:4096 -nodes -sha256 -keyout yourdomain.com.key -out yourdomain.com.csr# 生成域名证书penssl x509 -req -days 365 -in yourdomain.com.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out yourdomain.com.crt# 复制证书到服务器ssh yourdomain.com &amp;#34;mkdir -p /data/cert&amp;#34;scp yourdomain.com*.pem yourdomain.com:/data/certvi ~/harbor/harbor.cfg编辑如下内容:
hostname = yourdomain.comui_url_protocol = httpsssl_cert = /data/cert/yourdomain.com.crtssl_cert_key = /data/cert/yourdomain.com.key 之后重启harbor服务:
./preparedocker-compose downdocker-compose up -d配置docker客户端进程https 解决错误:&amp;ldquo;Error response from daemon: Get v1/_ping: x509: certificate signed by unknown authority&amp;rdquo;
cd /etc/docker/certs.d/yourdomain.com# 复制上一节生成的ca.crt到此# 产生客户端证书openssl genrsa -out client.key 4096openssl req -new -x509 -text -key client.key -out client.cert最终目录结构如下: tree /etc/docker/certs.d/yourdomain.com
.├── ca.crt├── client.cert└── client.key Ubuntu可能需要更新系统证书:
cp youdomain.com.crt /usr/local/share/ca-certificates/update-ca-certificates为kubernetes节点设置验证 # 在其中一台节点登录私有仓库docker login reg.server# 会更新$HOME/.docker/config.json# 复制到其他节点nodes=$(kubectl get nodes -o jsonpath=&amp;#39;{range.items[*].metadata}{.name} {end}&amp;#39;)for n in $nodes; do scp ~/.docker/config.json root@$n:/root/.docker/config.json; done备注 Web UI 默认用户名/密码: admin/Harbor12345
推送本地镜像到该仓库 docker login yourdomain.comdocker tag myimg:mytag yourdomain.com/pt/myimg:mytagdocker push yourdomain.com/myproject/myimg:mytagDocker Notary Harbor可以和Notary结合, Notary是一个内容数字签名服务,保证分发的内容/镜像可信.
资源  官网 安装配置向导 https配置向导 k8s镜像文档  </content>
    </entry>
    
     <entry>
        <title>证书那些事</title>
        <url>https://xulizhao.com/blog/cert/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>security</tag><tag>networking</tag>
        </tags>
        <content type="html"> 断断续续接触过加密通讯的一些场景, 随着近两年安全的普及,建站使用https也成为标配.
这篇文章试图汇总下证书这块的知识提纲.
基本概念 认证和鉴权 经常容易混淆的两个概念.
 Authentication: 验证你是你所说的人,即通讯中某端的身份识别机制. 通常用于访问控制 Authorization: 验证你被许可你正在试图做的事. 用于用户识别访问权限  客户端证书 通常用户客户端/用户身份识别.
Client Certificate Authentication 用于相互的认证机制.
服务端证书 通常用于加解密内容.
区分客户端/服务端证书可以通过查看&amp;quot;Enhanced Key Usage&amp;quot;字段.
证书应用 通常用于认证/隐私/加密/数字签名.
常见数字证书类型  Certificate Signing Request (.csr) Base64编码的X.509证书 (.cer/.crt) (用于导出) DER编码的二进制X.509证书(.cer/.der/.crt) 加密消息语法标准 (PKCS#7) 证书 (.p7b/.p7r/.spc) 个人信息交换格式 (PKCS#12) 证书 (.pfx/.p12)/ Java Keystore (JKS) Privacy-enhanced Electronic Mail (.pem) (Base64编码改进版,OpenSSL所使用)  PKCS#12 证书用于客户端, 是唯一可以被导出证书和私钥的文件格式.
.pem格式可以在一个文件包含下面一种/全部的信息:
 Issued Public Certificate (Client/Server) Intermediate CA Certificate Root CA certificate Private Key(.key) (Linux or Java) Certificate Revocation List (.crl extension) (CRL Distribution Points) Certificate Trust List (.stl)  # 转换pem格式到crt格式openssl x509 -outform der -in ca.pem -out ca.crtSSL单向认证和SSL双向认证  SSL单向认证只要求站点部署了ssl证书就行，任何用户都可以去访问(IP被限制除外等)，只是服务端提供了身份认证。一般Web应用都是采用SSL单向认证的 双向认证则是需要服务端与客户端提供身份认证，只能是服务端允许的客户能去访问，安全性相对于要高一些。  通配符证书/Wild Card Certificates 在host包含来匹配多个子域名, 但只可以匹配一级子域名.
SAN/Subject Alternative Name也可以包含通配符主机名.
证书体系 CA含权威的第三方公开证书认证机构和内部认证机构(Enterprise CA).
Root CA/根证书机构 权威的根证书机构, 与中间证书机构的区别:
 Issued to 和Issued by是同一机构. Certification Path位于顶级  本身是自签证书.
Intermediate CA/中间证书机构 作为PKI体系的一部分,使证书结构可扩展. Root CA 把任务代理给Intermediate CA.
自签证书 顾名思义, Issued to 和Issued by 是同一机构/人. 通常用户非生产环境.
浏览器会显示警告为不可信任, 因为不被公共的根证书机构认可.
证书实战 mkcert 最简单的生成证书方式, 可用于开发测试环境
mkcert -installmkcert example.com &amp;#39;*.example.org&amp;#39; 127.0.0.1openssl使用 # Ubuntu生成自签名服务端证书和私钥openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /home/xulz/certs/server.key -out /home/xulz/certs/server.crt# 生成证书和密钥到一个文件openssl req -x509 -nodes -days 365 -new -keyout /home/xulz/certs/mail.pem -out /home/xulz/certs/mail.pem#key和cert分开创建openssl genrsa 2048 -out key.pemopenssl req -x509 -nodes -days 365 -new -key key.pem -out cert.pem# 其他命令示例# 产生私钥openssl genrsa -aes256 4096 -out key.pem# 产生不被密码保护的密钥openssl genrsa 4096 -out key.pem# 使用新版genpkey命令openssl genpkey -algorithm RSA -out key.pem -aes-256-cbc -pkeyopt rsa_keygen_bits:4096# 改用更强算法加密openssl pkcs12 -in weak.p12 -nodes -out decrypted.pemopenssl pkcs12 -export -in decrypted.pem -keypbe AES-128-CBC -certpbe AES-128-CBC -out strong.p12openssl req命令行参数
 -new new request. -out arg output file -nodes don&#39;t encrypt the output key -x509 output a x509 structure instead of a cert. req. -days number of days a certificate generated by -x509 is valid for. -keyout arg file to send the key to -key file use the private key contained in file   openssl genpkey [-out filename] [-outform PEM|DER] [-pass arg] [-cipher] [-engine id] [-paramfile file] [-algorithm alg] [-pkeyopt opt:value] [-genparam] [-text]
  openssl genrsa [-out filename] [-passout arg] [-des] [-des3] [-idea] [-f4] [-3] [-rand file(s)] [-engine id] [numbits]
 keytool Linux/Mac中OpenSSL的证书和密钥管理工具
# 产生密钥对keytool -genkeypair -alias test123 -keystore test123.pfx -storepass test123 -validity 365 - keyalg RSA -keysize 2048 -storetype pkcs12Misc 工具  testssl.sh: 强大友好的SSL证书测试命令行工具 certbot mkcert Windows证书管理: certmgr.msc  名词缩写    缩写 全名 注释     CA Certificate Authority    SSL Secure Socket Layer client和server加密通讯协议   TLS Transport Layer Security SSL继承者,应用层协议   PKCS Public Key Cryptography Standard    DER Distinguished Encoding Rules     扩展阅读  Unleashed Java加密 浅析TLS 1.2协议 </content>
    </entry>
    
     <entry>
        <title>python流行库/框架汇总</title>
        <url>https://xulizhao.com/blog/python-lib/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 作为一个Python粉,一直在各种场合使用这个语言,最近也在试图从Python2彻底切换到Python3.
如果说缺点的话,也只有对它的性能有所抱怨(GIL),不能使用多核CPU.
这篇主要记录使用过和部分mark过的库/框架,其他检索的话可以使用awesome-python.
注: 具体类别以个人喜好排序
开发类 必备  Requests :用的最久和最多的库  Web开发  Flask :轻量级微框架 Django :全栈框架 Pyramid :想用却没太多实战 spyne : RPC库  Flask相关  Flask-SQLAlchemy  REST服务  Eve: 基于Flask的灵活RESTful服务 Django REST framework Falcon: 高性能微服务框架  数据库  peewee : 轻量级ORM SQLAlchemy : 标配ORM pymysql - 纯python实现 mysqlclient - py3 - 和mysql-python一样对头文件有要求 influxdb 时序数据库 pyzmq  Driver/驱动  PyMySQL : 纯python实现的MySQL客户端 psycopg2: 最常用PostgreSQL客户端 asyncpg: 支持asyncio的PostgreSQL客户端 cx_Oracle: Oracle客户端  数据 I/O 多线程  Curio : 协程库,aysncio的其他版本  功能增强  CUP, common useful python-lib: baidu schedule: 类似cron的任务安排 ElastAlert : Elasticsearch提醒 Celery /web前端展示Flower: 异步消息/任务队列,可用于发送邮件任务等 rq: 精简版任务队列,基于Redis click - 命令行工具  日志Logging  structlog - 结构化日志 logbook sentry - 异常捕获  图像处理  Pillow matplotlib  图像figure subplot 子区 / axes 子图 label &#43; legend 图例 画横线 pyplot.axhline ticker 刻度, spines 轴线    加密  cryptography M2Crypto: crypto and SSL toolkit for Python Python-RSA: RSA纯Python实现 PyKerberos : Kerberos (GSSAPI) wrapper,用户认证/用户组支持系统  网络抓取  Scrapy/Portia web前端 pyspider- 爬虫库 Beautiful Soup 4 - 网页解析 pyquery - 基于lxml的XML查询  语言规范  YAPF : 格式化及规范 常用设计模式  客户端  Click: 命令行工具 PyInstaller : 安装打包 Kivy: 跨平台/手机产品原型设计  运维相关 生产部署  Gunicorn : WSGI HTTP Server  自动化/运维  Fabric : 轻量部署 Ansible Boto 3: AWS运维 buildout - 构建工具 ClusterShell - 在本地或远程Linux集群中并行运行命令  监控  psutil:进程和系统监控 psdash: 基于psutil和flask的web端  测试 测试库/框架  pytest : 基础测试框架 Faker : 假数据生成 Mimesis  Fake Data Generator 易出错输入字符集/Big List of Naughty Strings PyAutoGUI: GUI自动化,操作鼠标/键盘  性能测试  Locust  数据科学 数据处理  pandas openpyxl /XlsxWriter /xlrd : Excel操作 tablib - XLS, CSV, JSON, YAML等表格式数据集 q - CSV数据用SQL查询 List of Python API Wrappers 接口python库  可视化  Matplotlib : 最早接触的绘图库 Bokeh : 交互式可视化  System  sh - subprocess替代库 watchdog - Python library and shell utilities to monitor filesystem events path - &amp;ldquo;Path&amp;rdquo; object conveniently wrapping assorted file/path-related functionality netifaces - Portable network interface information  工具  HTTPie : 增强易用版curl httpbin/官方站 : 请求/响应服务,学习HTTP协议 pycurl - libcurl的python库 cookiecutter:项目开发模板 tqdm: cli命令行进度条 simpy 离散事件仿真  图像处理  pillow  # 安装pillow依赖: apt-get install libjpeg-dev zlib1g-dev扩展阅读  libhunt - 流行库的分类评测 awesome-python - 不得不提的awesome系列 中文版awesome-python  Windows库  Unofficial Windows Binaries for Python Extension Packages </content>
    </entry>
    
     <entry>
        <title>Fabric自动化部署</title>
        <url>https://xulizhao.com/blog/fabric/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>automation</tag><tag>python</tag>
        </tags>
        <content type="html"> Fabric比较轻量级,平时在部署多个服务器时经常用到.
今年作者发布了不向后兼容的Fabric2, 由于原有的脚本改动太多,暂时还没有迁移.
[2018.12更新]
Fabric2现在看来是个错误选择, Fabric v1不支持Python3,而Fabric2仍存在大量bug和未实现功能,从实用的角度看v2基本不可用.
在主流已经使用Python3的情况下,这意味着Fabric毫无迁移必要.
算了不折腾了,直接上Ansible吧.
Fabric2 # 如果要同时安装两个版本,建议使用下面方式安装新版本pip install fabric2TODO
Fabric v1 因为默认会安装新版v2,需要指定具体的版本号
pip install Fabric==1.14.1Q: 如果遇到错误: CTR mode needs counter parameter, not IV
A: 需要升级paramiko库
 sudo pip install -U paramiko
 fab命令行  -u User : 以该用户远程登录 -R ROLES : 以该角色执行任务 -l : 列出可执行任务 -P : 切换为并行执行 -H : 用,分割的远程主机列表 -f PATH : 加载python模块  # 执行参数化任务fab mytask:arg1,arg2fabfile.py的写法 常用接口 from fabric.api import *run(&amp;#39;pwd&amp;#39;)# 忽略错误 with settings(warn_only=True):sudo(&amp;#39;cat /etc/passwd&amp;#39;)文件操作 from fabric.operations import put,getfrom fabric.contrib import filesput(&amp;#39;/home/xulz/test1.txt&amp;#39;, &amp;#39;/home/ubuntu/tmp/&amp;#39;)get(&amp;#39;/home/ubuntu/remote.txt&amp;#39;,&amp;#39;/home/xulz/tmp/&amp;#39;)files.append(&amp;#34;/home/xulz/test.txt&amp;#34;, &amp;#34;new line&amp;#34;)灵活调用 from fabric.api import executefrom fabric.api import envenv.user = &amp;#39;xulz&amp;#39;env.roledefs = {&amp;#39;db&amp;#39;: {&amp;#39;hosts&amp;#39;: [&amp;#39;192.168.1.1&amp;#39;]}}@roles(&amp;#39;db&amp;#39;)def my_func(arg1,arg2)passdef my_task():execute(my_func,arg1,arg2)其他 from fabric.colors import red, green资源  官网 </content>
    </entry>
    
     <entry>
        <title>Vim必知必会</title>
        <url>https://xulizhao.com/blog/vim/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>tools</tag><tag>linux</tag>
        </tags>
        <content type="html"> VI/VIM作为Nix环境的常用编辑器,有一些常用命令/用法.
由于平时用VSCode/SublimeText比较多,以至于切换到vi经常需要查阅,特记录与此.
命令行用法 # 以只读方式打开vi -R filename# 从某行打开vi &#43;linenumber file.py#修改当前路径gvim -c &amp;#34;cd ~/workspace&amp;#34;导航  切换Tab: Ngt (N是页码) 跳转到某行 ：NG或Ngg或:N (N代表行数)  常用快捷键    快捷键 说明     zz 移动当前行到屏幕中间   zt 移动当前行到屏幕顶部   zb 移动当前行到屏幕底部   Ctrl-y 上移屏幕一行, 只   Ctrl-e 下移屏幕一行   Ctrl-u 向上移动光标屏幕1/2页面   Ctrl-d 向上移动光标屏幕1/2页面   Ctrl-b 向前翻页,光标移到最后一行   Ctrl-f 向后翻页,光标移到第一行   Ctrl&#43;C 或 Ctrl&#43;[ Esc     &amp;lsquo;zt&amp;rsquo;, &amp;lsquo;zz&amp;rsquo; 和 &amp;lsquo;zb&amp;rsquo; 会保持当前光标位置, 但移动视野使其在屏幕的&#39;t&#39;op, &amp;lsquo;z&amp;rsquo; center, 或 &amp;lsquo;b&#39;ottom 位置.
  &amp;lsquo;H&#39;ighest, &amp;lsquo;M&#39;iddle, &amp;lsquo;L&#39;ower 屏幕行
 设置命令 # 执行命令!! 等同于 :.! 或Ctrl-z &#43; fg#显示行号/自动缩进/忽略大小写/显示结束行和tab标识/显示换行符:set number/ai/ic/list/wm# 关闭显示set nu!:set nonumber#高亮搜索,关闭:noh;实时显示匹配:set hlsearch incsearch 简写 set hls is# 忽略大小写:set ignorecase smartcase# 用sudo保存只读文件(经常用到的一个命令):w !sudo tee %# 设置终端为vi 模式:set -o vi#切换工作路径:cd ~/workspace# 将当前编辑文件第 # 行至第 # 行的內容保存到文件FILENAME:#,#w FILENAME# 读取 FILENAME文件 并将其插入到当前文件的光标位置后面:r FILENAME# 重复上一次变更. (period)编辑内容 # 复制和粘贴&amp;#34;ayy (内容存放在寄存器 &amp;#34;) / &amp;#34;ap查找 搜索光标处单词
 *(向前) 或#(向后) q/ 或/Ctrl-f (== find) /之后用上下方向键  替换  :[address]s/search-string/replacement-string[/g]
  address 为一个行号或者是用逗号隔开的两个行号。句点 (.) 代表当前行。可以使用标记或者搜索字符串表示行号。 %代表当前文件 search-string 可以是正则表达式或简单的字符串 g 表示进行全局替换 ( 针对一行可能执行多次替换 )  # 几个例子# 替换当前文件所有并确认，global:%s/old/new/gc# 列出所有行:g/old/p:g/old/s//new/gp# 匹配整个单词:s/\&amp;lt;bar\&amp;gt;/baz批量替换 :
:args *.[ch] # 替换所有*.c和*.h文件:argdo %s/&amp;lt;my_foo&amp;gt;/My_Foo/ge | update# e 忽略没有找到的错误# update 写入修改定制 设置字体  Linux: set guifont=DejaVu Sans Mono 10 Windows :set guifont=DejaVu Sans Mono:h10  Troubleshooting Q: 终端显示颜色失败A: export TERM=xterm-256color
Q： Ubuntu下中文菜单不能显示A： $sudo cp /usr/share/vim/vim72/lang/{menu_zh_cn.utf-8.vim,menu_zh_cn.utf8.vim}
Q：使用Taglist(Ctag)报错 A： apt-get install exuberant-ctags 或在WIndows把ctags.exe放到vim根目录
扩展学习 工具扩展  spf13-vim Maximum For Mac  学习资源  How I Boosted My Vim Cheat Sheet 入门图解 </content>
    </entry>
    
     <entry>
        <title>Ansible Checklist</title>
        <url>https://xulizhao.com/blog/ansible/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>automation</tag><tag>ops</tag>
        </tags>
        <content type="html"> 最早接触Ansible是在15年,后来断断续续用过几次,因为更倾向于所写即所得的Fabric,后者也更轻量级.
每次拾起来都要查文档,记录下常见用法.
基础 ansible命令行用法 ansible [options]
 -m ping : 使用模块 -a/&amp;ndash;args &amp;ldquo;&amp;hellip;&amp;quot;: 模块参数 -u xulz : 切换远程连接用户 -b/&amp;ndash;become : 等同于之前的sudo  # 复制本地文件到远程ansible all -m copy -a &amp;#39;src=./README.md dest=/tmp&amp;#39;ansible -i ./hosts -m shell -a &amp;#39;apt install nginx&amp;#39;配置选项 # ansible-config命令查看当前配置ansible-config view以下列顺序查找:
 ANSIBLE_CONFIG 环境变量 当前路径的ansible.cfg 文件 ~/.ansible.cfg 系统配置 /etc/ansible/ansible.cfg (默认)  服务器信息配置  /etc/ansible/hosts (类似ini格式:以;作为注释,[header]作为分组) inventory文件 本地目录的hosts  注: 可以使用正则匹配指定主机
常见用法 提权become  become=true/yes : 激活提权 become_user=root : 与上条命令独立使用 become_method: 可以是su或sudo，在play/task级别修改默认值 become_flags: &amp;lsquo;-s /bin/sh&amp;rsquo; 通常用来切换到nobody非登录用户  在hosts或配置文件使用：
 ansible_become_user ansible_become_pass ansible_become_method ansible_become  ansible-console 交互式shell
# 列出hostslist # 切换分组cd groupAcd db*日志及调试 # 打印详细信息到控制台ansible-playbook -vvv playbook.yaml# 查看一些信息--list-hosts--list-tasks配置日志文件
[defaults]log_path=/path/to/logfilePlaybook 用法  -i/&amp;ndash;inventory : 指定参考文件 &amp;ndash;syntax-check : 检查语法  减少执行时间
 -l/&amp;ndash;limit : 限定子集 &amp;ndash;tags/&amp;ndash;skip-tags : 标签 gather_facts: False  ansible-palybook playbook.yml# 运行adhoc命令ansible boston -i production -m command -a &amp;#39;/sbin/reboot&amp;#39;最佳实践
 命名任务 涉及状态 以角色分组  ansible-galaxy ansible-galaxy init -p playbooks/roles webansible-galaxy install oracle-java -p ./roles示例 deploy.yml样例：
文件操作 ---- hosts: alltasks:-name:copyjavacopy:src:/home/xulz/jdk-8u171-linux-x64.rpmdest:/home/xulz# remote_src: yes# 支持递归复制，yes代表远程机器内复制-name:installjavabecome:yesyum:name:/home/xulz/jdk-8u171-linux-x64.rpmstate:present-name:remove/deletefilefile:path:/home/xulz/jdk-8u171-linux-x64.rpmstate:absent-name:Movefootobarcommand:mv/path/to/foo/path/to/bar-name:ensureinstalledvimapt:pkg=vimstate=installed-name:setfiletypeindentoffforvimlineinfile:dest=/etc/vim/vimrcline=&amp;#39;filetype indent off&amp;#39;state=presentnotify:-startnginxhandlers:-name:startnginxservice:name=nginxstate=startedmsg=&amp;#34;{{lookup(&amp;#39;env&amp;#39;,&amp;#39;SHELL&amp;#39;)}}-name:installrequiredpythonpackagespip:name={{item}}virtualenv={{venv_path}}with_items:-gunicorn-psycopg2pip:name={{item.name}}version={{item.version}}virtualenv={{venv_path}}with_items:-{name:mezzanine,version:3.1.10}-name:installrequirements.txtpip:requirements={{proj_path}}/{{reqs_path}}virtualenv={{venv_path}}服务 -name:Makesureaserviceisrunningsystemd:state:startedname:httpd后台执行 -name:startjmeterslaveshell:&amp;#34;(cd /opt/jmeter/bin; ./jmeter-server &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;)&amp;#34;async:30poll:0其他工具 ansible-vault 加密secret
ansible-doc 插件文档
Rollback https://github.com/ansistrano/rollback
扩展阅读 官方文档  Ansible Configuration Settings Working with Inventory Asynchronous Actions and Polling: 异步执行长时间任务 选择指定主机或分组  常用模块  file copy： remote_src: yes 远程机器内复制 synchronize： 结合delegated_to使用，支持远程机器间复制 fetch yum/dnf git authorized_key systemd  第三方playbook  oracle-java  教程  An Ansible2 Tutorial Ansible tips  使用细分角色和tags 在角色里包含多个include和tags 使用现有的模块 使用var_prompt 并提供默认值   Ansible Galaxy </content>
    </entry>
    
     <entry>
        <title>Docker Command</title>
        <url>https://xulizhao.com/blog/docker-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>docker</tag><tag>ops</tag>
        </tags>
        <content type="html"> 实际使用中，docker的命令还是很多的，这里单列出来方便查询。
常用命令 # 停止所有运行的containersdocker stop $(docker ps -q)# 删除所有容器docker rm $(docker ps -a -q)# 显示所有exited的容器IDdocker ps -a -q -f status=exited# 显示标准输出日志docker logs --follow &amp;lt;container&amp;gt;# 复制文件docker cp foo.txt &amp;lt;container&amp;gt;:/docker cp &amp;lt;container&amp;gt;:/foo.txt /docker run docker run 选项详解
# --rm 容器关闭时自动删除容器, 通常用于运行一次性命令# -d, —detach 在后台运行(detached模式)并打印容器ID, 如果不指定,容器运行日志会打印到终端# -p &amp;lt;hostPort&amp;gt;:&amp;lt;containerPort&amp;gt; 建立宿主机到容器的端口映射# -v &amp;lt;hostDirectory/volume&amp;gt;:&amp;lt;containerDirectory&amp;gt; 建立宿主机到容器的文件目录映射, 如果不指定,则不能持久化保存变更 上面的docker volume如果不存在会自动创建, 也可以手动创建: docker volume create my-container-data
 # 指定网络docker run --net mynet123 --ip 172.18.0.22 -it ubuntu bash 从Host传递环境变量到Container 方式1: 使用-e 参数
export LOCUST_MODE=&amp;#34;master&amp;#34;;printenv |grep LOADS_MODE; docker run -e LOCUST_MODE ...方式2: 使用 &amp;ndash;env-file参数
# 指定环境变量文件docker run --env-file=runtime_env排查/调试 # 查看容器日志, 包含已Exiteddocker logs -f &amp;lt;container id/name&amp;gt;# 或者直接登录容器docker run xxx -ti bash# inspect 查看状态/LogPathdocker inspect xxxdocker network docker port &amp;lt;CONTAINER&amp;gt;docker network ls# 创建新的bridge 网络docker network create net-demodocker network create --subnet=172.18.0.0/16 mynet123docker volume/数据卷  docker volume ls  docker system  docker system prune : 删除不用的数据  -a, &amp;ndash;all : 删除所有不用镜像而不仅仅悬挂的 -f, &amp;ndash;force &amp;ndash;volumes : 不用的卷也删除 &amp;ndash;filter &amp;ldquo;key=value&amp;rdquo;   docker system info : 系统信息 docker system df : 磁盘占用  docker system prune -a# This will remove:# - all stopped containers# - all networks not used by at least one container# - all images without at least one container associated to them# - all build cache制作镜像 Dockerfile 例子
# 基础镜像 FROM python:3-onbuild # 对外暴露端口 EXPOSE 5000 # 执行命令 CMD: [&amp;#34;python&amp;#34;,&amp;#34;.app.py&amp;#34;]   # 其他 # 运行命令 RUN apt -yqq update  # 把应用添加到容器卷 ADD flask-app /opt/flask-app # 设置工作目录 WORKDIR /opt/flask-appdocker build  -t &amp;lt;版本标签&amp;gt; PATH/URL/. : 通常使用的最后的.代表当前路径  # 构建及运行示例docker build -t my-app .docker run -it --rm --name my-running-app my-app# 强制构建/不使用缓存docker build --no-cache -t my-app -f Dockerfile .RUN/ENTRYPOINT/CMD的区别  RUN: 构建新镜像层 ENTRYPOINT: 总是需要执行命令时使用,使容器可执行 CMD: 需要提供默认命令,参数可以被覆盖  两种形式:shell和exec
 shell形式 : 会调用/bin/sh -c 并执行shell处理 exce形式 [&amp;ldquo;executable&amp;rdquo;,&amp;ldquo;param1&amp;rdquo;]  直接调用executable,例如 /bin/bash写作 ENTRYPOINT [&amp;quot;/bin/bash&amp;rdquo;,&amp;quot;-c&amp;rdquo;,&amp;ldquo;echo Hello, $name&amp;rdquo;] 更多用于 CMD和 ENTRYPOINT    传递参数 # 通常组合为ENTRYPOINT [&amp;#34;/bin/bash&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;param1&amp;#34;]CMD [&amp;#34;param2&amp;#34;,&amp;#34;param3&amp;#34;]调试 # 对于直接EXITED的容器,可修改入口为ENTRYPOINT [&amp;#34;/bin/bash&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;sleep 1800&amp;#34;]# 容器启动后,再登录容器shell查看日志镜像导出/导入 保存镜像 # 格式: docker save -o &amp;lt;path for generated tar file&amp;gt; &amp;lt;image name&amp;gt;# 压缩docker save &amp;lt;docker image name&amp;gt; | gzip &amp;gt; &amp;lt;docker image name&amp;gt;.tar.gz导入镜像 docker load &amp;lt; my-image.tar.gz# 注: 对于gzip, bzip2, xz的压缩文件,导入时会自动解压docker-compose 定义及运行多个容器应用,Python写的一个工具
PS. 原来docker-compose最初也是收购来的
# 停止服务 docker-compose stop # 停止并删除container及数据卷 docker-compose down -v # 创建,启动并在后台运行container docker-compose up -ddocker-compose.yml version:services:&amp;lt;service_name&amp;gt;:image:command:ports:volumes:技巧  所有命令的Container ID可以仅使用前2/4位  扩展阅读  Docker RUN vs CMD vs ENTRYPOINT 如何在已启动的容器开启新端口映射 </content>
    </entry>
    
     <entry>
        <title>Docker最佳实践</title>
        <url>https://xulizhao.com/blog/docker-best-practice/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>docker</tag>
        </tags>
        <content type="html"> 这里主要针对制作Docker镜像，汇总常见的正确使用方式：
制作镜像 使用继承镜像 如果要制作包含Tomcat和Java运行环境的镜像， 建议先基于CentOS制作Java镜像，接着基于它做Tomcat镜像。
centos7-java8 &amp;gt; centos7-java8-tomcat8
在一个容器最好只运行一个进程 制作合适层数的镜像 避免只包含一层，也避免太多层。常用的方式例如：
 基于操作系统的定制基础镜像 新用户创建准备 安装运行时 配置 应用层  定义.dockerignore 使用WORKDIR 注意顺序，依照构建过程（不变的在前） 缩减镜像尺寸 镜像的选择：
Ubuntu &amp;gt; openjdk:8-alpine &amp;gt; tomcat:8.5-alpine
常用清除命令
# Alpineapk add --no-cache curl# CentOSyum clean all# Ubunturm -rf /var/lib/apt/lists/*使用Health Check HEALTHCHECK CMD curl --fail http://localhost || exit 1--interval=10s--timeout=10s--start-period=30s# 检查状态docker ps responseJava应用性能优化 JVM 应该指定 -Xmx
默认使用宿主机的25%或1G(取较小值)
使用docker资源限制  &amp;ndash;memory &amp;ndash;memory-reservation &amp;ndash;cpus  如果CPU被限制，需要同时设置 -XX:ParallelGCThreads
日志处理 不建议写到容器的RW层，应该发送到数据卷（NAS/SAN）或使用 Docker Log Drivers.
问题诊断 JVM命令：
GC Stats: jstat &amp;ndash;gcutil
Heap Dump/直方图: jmap
Docker命令： docker stats
ctop
一些镜像资源  Tomcat Dockfile Postgres Dockfile JBoss Dockfile  参考  SlideShare Java Docker Pipeline Dockerfile Good Practices  </content>
    </entry>
    
     <entry>
        <title>在Windows10运行增强版Ubuntu,支持复制粘贴和本地磁盘映射</title>
        <url>https://xulizhao.com/blog/hyperv-ubuntu-enhanced-mode/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ubuntu</tag><tag>windows</tag>
        </tags>
        <content type="html"> 使用Win10自带的Hyper-V运行Ubuntu虚拟机确实资源使用很小，Ubuntu虚拟机开个全屏，用起来和双系统没有区别。
前提 由于这是最新版Windows 10发布版才支持的特性（增强Linux支持），需要确保Windows已升级至1803. 升级使用官方的Windows10易升就可以。
同时Hyper-V需要专业版和企业版才支持（家庭版不行）。
主要步骤 1.下载Ubuntu 18.04（或16.04）镜像
2.在Hyper-V创建新虚拟机，可以选择&amp;quot;Generation 2/2代。 创建完成之后，在虚拟机[设置]-[硬件]-[安全],把&amp;quot;Enable Secure Boot&amp;quot;前的勾选去掉。
3.虚拟机安装完成之后，进入Ubuntu系统，在终端执行下列命令：
sudo apt-get updatesudo apt install gitgit clone https://github.com/jterry75/xrdp-init.git ~/xrdp-initcd ~/xrdp-init/ubuntu/18.04/vi install.sh# 把以下两行注释掉并保存，如下#rmmod vmw_vsock_vmci_transport#rmmod vsock# 运行sudo chmod &#43;x install.shsudo ./install.shsudo reboot# 重启后，进入该目录再次运行sudo ./install.sh# 之后关闭Ubuntu4.以管理员打开powershell，运行
Set-VM -VMName Ubuntu -EnhancedSessionTransportType HvSocket5.进入Ubuntu虚拟机，以默认的Xorg方式登录系统。
如果登录失败，进入[Hyper-V Settings]-[User]-[Enhanced Session Mode]设置项，把&amp;quot;Use enhanced session mode&amp;quot;前的勾选去掉，重新登录Ubuntu并检查日志/var/log/xrdp.log最后的错误。如果是因为私钥读失败，可执行
# 这里修改为你的用户名sudo chown xulz /etc/xrdp/key.pem参考  Windows 10: A guide how to run Ubuntu 18.04 in Enhanced Mode in Hyper-V  </content>
    </entry>
    
     <entry>
        <title>Kubernetes控制命令kubectl汇总</title>
        <url>https://xulizhao.com/blog/k8s-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html"> kubectl 作为Kubernetes集群管理的命令行工具,经常用到的几个子命令包括:
 kubectl get &amp;ndash; list resources kubectl describe &amp;ndash; show detailed information about a resource kubectl logs &amp;ndash; print the logs from a container in a pod kubectl exec &amp;ndash; execute a command on a container in a pod  按类型分 集群状态 kubectl cluster-infoget 获取信息 kubectl get nodeskubectl get deployments# -o yaml 输出yaml配置格式kubectl -n kube-system get deployment coredns -o yamlkubectl get pods# 显示更详细的信息kubectl get pods -o wide# 显示所有命名空间的kubectl get pods --all-namespaces# 指定命名空间 -n# -w 监控变化kubectl get pod -n kube-systemkubectl get componentstatuses# 等价于kubectl get csdelete 删除资源 kubectl delete pod &amp;lt;pod-name&amp;gt;describe 详细信息 kubectl describe pod &amp;lt;pod-id&amp;gt;# 描述系统命名空间Pod, 经常用于查找问题kubectl describe pod calico-node-j2ggr --namespace=kube-systemlogs 获取容器日志 POD_NAME=$(kubectl get pods -l run=nginx -o jsonpath=&amp;quot;{.items[0].metadata.name}&amp;quot;)kubectl logs $POD_NAME exec 在容器执行命令 kubectl exec -ti -- $POD_NAME &amp;lt;command&amp;gt; kubectl exec -ti k8s-demo -- /bin/bash# 查看环境变量# printenv配置/部署 # 部署Deploymentkubectl create -f deployment.yaml# 编辑Deploymentkubectl edit deployment/nginx-deployment# 基于配置文件创建podkubectl create -f &amp;lt;config.yaml&amp;gt;# 创建其他资源kubectl create secret generic kubernetes-bootcamp --from-literal=&amp;#34;mykey=mydata&amp;#34;在非Master机器使用kubectl scp root@&amp;lt;master ip&amp;gt;:/etc/kubernetes/admin.conf .kubectl --kubeconfig ./admin.conf get nodes按使用场景 部署容器镜像 ## 部署kubectl run &amp;lt;deployment name&amp;gt; —image=&amp;lt;full url&amp;gt; —port=8080# 例如kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080kubectl run busybox --image=busybox# 检查kubectl get deployments# 使用标签过滤kubectl get pods -l run=busybox升级及回滚 ## 升级kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1kubectl rollout status deployment/nginx-deploymentkubectl rollout undo &amp;lt;deployment&amp;gt; [--to-revision=2]# 手动强制更新容器镜像# 注: 仅适用于ReplicationControllerkubectl rolling-update k8s-demo --image=k8s-demo:latest --image-pull-policy Always暴露服务 # 使API Server监听本地的8001端口kubectl proxy# 使用NodePort服务方式暴露部署kubectl expose deployment nginx --port 80 --type NodePort# 标签标记kubectl label# 检查kubectl get services自动扩容 kubectl scale deployment nginx-deployment --replicas=5# 自动扩容/Horizontal Pod Autoscalerkubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80</content>
    </entry>
    
     <entry>
        <title>电音欣赏</title>
        <url>https://xulizhao.com/play/electronic-muisc/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          <tag>music</tag>
        </tags>
        <content type="html"> 去年下半年玩王者荣耀(年前已出坑)的收获之一就是接触了电音,当时找一些攻略视频看,背景音乐都很带劲,于是通过网易云音乐的歌单发现了电音的广阔天地.
从个人爱好说,超喜欢铁托,那首BOOM就很魔性. 其他DJ有Deorro(Five Hours必听),Timmy Trumpet,Zedd.
欢迎收听我的歌单: http://music.163.com/#/playlist?id=969925767
</content>
    </entry>
    
     <entry>
        <title>Kubernetes部署篇:Kubespray方式自动化</title>
        <url>https://xulizhao.com/blog/k8s-deploy/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html"> 众所周知Kubernetes集群的部署比较繁琐复杂,这里列出常见的几种部署方式及过程.
官方现在提供2种主要的部署方式:
 Kubespray : 基于Ansible的集群自动化部署,支持的平台更广泛,部署更灵活 Kubernetes Operations (kops): 生产环境集群自动化部署工具, 目前只支持AWS, GCE云环境.  Kubernetes部署/运行结构 Control Plane 包括三部分组件:
 apiServer controllerManager scheduler  kube-controller-manager实例:
管理controller状态的守护进程,包括replication controller, endpoints controller, namespace controller, serviceaccounts controller.
组件安装顺序  Docker etcd kubelet and kube-proxy network_plugin (such as Calico or Weave) kube-apiserver, kube-scheduler, and kube-controller-manager Add-ons (such as KubeDNS)  高可用 Control Plane和ETCD至少需要3个节点,才可提供HA.
添加 &amp;ndash;experimental-control-plane 选项组成control plane集群.
Kubespray部署实战 说明 由于国内网络访问docker.com及镜像, kubernates, gcr.io等相关镜像极不稳定,替换了相关安装源.
这里使用的是我的Kubespray(已更新至2018.12最新版v2.8.0) fork版本
部署节点前提 cp inventory/sample inventory/mycluster根据自己的节点信息修改inventory/mycluster/hosts.ini
我的例子
moon1 ansible_ssh_host=10.20.30.101  moon2 ansible_ssh_host=10.20.30.102  moon3 ansible_ssh_host=10.20.30.103 moon4 ansible_ssh_host=10.20.30.104  moon5 ansible_ssh_host=10.20.30.105  moon6 ansible_ssh_host=10.20.30.106  [kube-master] moon1 moon2 [etcd] moon1 moon2 moon3 [kube-node] moon2 moon3 moon4 moon5 moon6 [k8s-cluster:children] kube-master kube-node 国内镜像及加速的常见步骤 已包含于Ansible运行脚本.
docker 阿里云镜像 # step 1: 安装必要的一些系统工具sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# step 2: 安装GPG证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# Step 3: 写入软件源信息sudo add-apt-repository &amp;#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable&amp;#34;# Step 4: 更新并安装 Docker-CEsudo apt-get -y update# 查找Docker-CE的版本: apt-cache madison docker-ce# 安装指定版本的Docker-CEsudo apt-get -y install docker-ce=17.03.2~ce-0~ubuntu-xenialdocker镜像 阿里云加速 sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&amp;#39;EOF&amp;#39;{&amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://nz4awhki.mirror.aliyuncs.com&amp;#34;]}EOF# 重启以生效sudo service docker restartkubernetes镜像 cat &amp;lt;&amp;lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.listdeb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial mainEOFgcr.io和quay.io镜像 将相关镜像URL里
 gcr.io部分替换为gcr.mirrors.ustc.edu.cn quay.io部分替换为quay.mirrors.ustc.edu.cn  注1: 国内网络的问题也可以通过手动下载相关镜像并重新tag的方式解决. 注2: gcr.io的镜像列表见 官方网站
运行Ansible Playbook命令 首次运行,建议:
  开启详情日志: -v
  如果非root,切换sudo用户: -u xulz -b
  建议先运行其中一台节点: &amp;ndash;limit moon1
  ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini cluster.yml --limit moon1# 如果某步骤出错,建议修复后先重试错误,在以上命令后添加--limit @/Users/xulz/k8s/kubespray/cluster.retry删除节点 ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini remove-node.yml --limit moon11添加节点 ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini scale.yml升级节点 ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini upgrade-cluster.yml问题排查 如果ansible运行失败,根据最后的控制台错误做相应的修正并重试. 日志的存放位置为节点主机的: /var/log/containers/
 注: 如果以&amp;ndash;check的Dry Run方式运行,会造成运行错误(因为脚本依赖于某些步骤的实际运行结果为环境变量),所以不要使用这种模式.
 运行kubectl xxx命令报错: The connection to the server localhost:8080 was refused - did you specify the right host or port? 解决方式: 添加 KUBECONFIG 环境变量
vi ~/.bashrcexport KUBECONFIG=/etc/kubernetes/admin.conf在准备阶段报错: &amp;ldquo;assertion&amp;rdquo;: &amp;ldquo;ansible_swaptotal_mb == 0” 解决方式: 需要关闭swap
sudo swapoff -a运行kubectl 命令报错: Unable to connect to the server: x509: certificate is valid for &amp;hellip;, not &amp;hellip; 解决方式: 参考Invalid x509 certificate for kubernetes master
如果升级cluster出错,建议逐个命令调试. sudo kubeadm upgrade plan# 参考下面的扩展阅读部分 登录Kubernetes Dashboard ### 创建管理员账号kubectl create -f admin-role.yaml# 找到admin-token开头的token名字kubectl -n kube-system get secret# 获取相应的tokenkubectl -n kube-system get secret admin-token-tmh9v -o jsonpath={.data.token}|base64 -d# 也可以直接运行 kubectl -n kube-system describe secret admin-token-tmh9v 获取token# 访问网址: https://&amp;lt;first_master&amp;gt;:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login# 选择以token方式登录, 输入上一步获取的token# 登录成功 admin-role.yaml的具体内容见这里
 关于Dashboard的说明 Dashborad支持token和kubeconfig两种认证登录方式，而kubeconfig的方式也需要token字段。
默认命名空间有: default, kube-public, kube-system
扩展阅读  Kubernetes The Hard Way: 例子基于GCP(Google Cloud Platform) kubespray官网 Kubernetes - Upgrading Cluster  </content>
    </entry>
    
     <entry>
        <title>Kubernetes部署篇:本地开发测试环境搭建</title>
        <url>https://xulizhao.com/blog/k8s-local/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html"> 本文侧重于入门Kubernetes时的本地开发测试环境搭建,及minikube的使用.
尤其在国内使用时需要开启网络代理,否则会因为访问Google的一些服务失败而造成各种运行失败的问题.
Mac单节点体验 先安装相应的几个工具:
 下载Minikube: minikube-darwin-amd64 kuberctl  后续命令:
chmod &#43;x minikube-darwin-amd64mv minikube-darwin-amd64 /usr/local/bin/minikubebrew install kubectl验证环境正确:
注: 进行前需梯子,否则第一步下载localkube可能失败,产生如下错误Error creating localkube asset from url: Error opening file asset: open /Users/xulz/.minikube/cache/localkube/localkube-v1.8.0: no such file or directory进而导致之后Pod的状态一直是ContainerCreating # 确保本机已安装VirtualBoxminikube startkubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 --port=8080# 检查Pod是否已运行, 需要从ContainerCreating更新为Runningkubectl get pod# 如果一直是ContainerCreating, 检查错误原因kubectl describe pods# 页面应该可访问curl $(minikube service hello-minikube --url)# 查看Dashboardminikube dashboard# 不用时清除kubectl delete deployment hello-minikubeminikube stopUbuntu多节点 使用工具conjure-up搭建本地测试/开发环境, 本身基于juju部署工具.
官方支持2种部署模式:
  kubernetes-core : (Staging环境) 1个Master节点&#43;1个Worker节点
  canonical-kubernetes: (生产环境) 2 masters, 3 workers, 3 etc nodes 及API Load Balance
  # 本地安装使用kubectlsudo snap install kubectl --classic# 准备阶段sudo snap install conjure-up --classicsudo snap install lxdnewgrp lxdsudo usermod -a -G lxd xulz/snap/bin/lxd init# 需要重启机器sudo reboot# 禁用IPv6, conjure-up基于的juju暂时不支持lxc network set lxdbr0 ipv6.address none使用图像界面安装
conjure-up kubernetes# 对于Docker的虚拟网络插件,这里选择默认的Flannel# 安装过程需开启梯子, gcr.io 不可访问 Kubernetes常用网络插件: flannel, calico, weave
  这里的网络也称作SDN(软件定义网络), 通常基于CNI: Container Network Interface/容器网络接口
 juju常用命令 在查看运行环境及问题排查时常会用到的命令.
juju controllers# Models 有2个是因为包含内置的管理模块default# 查看当前的 Controller, Model, Userjuju whoami# 显示当前应用状态juju status# 远程登录到master# 日志存放在 /var/log/juju/juju ssh kubernetes-master/0# 获取当前controller名称juju switch# 卸载停止controllerjuju destroy-controller &amp;lt;上一步得到的名字&amp;gt; --destroy-all-models# 单独卸载 modeljuju destroy-model &amp;lt;model_name&amp;gt;资源  Running Kubernetes Locally via Minikube LXD入门介绍 k8s国内镜像介绍 gcr.io/google-containers Hub镜像   注: gcr(Google Container Registry)的URL结构是gcr.io/{PROJECT_ID}/{image}:tag,在国内不可访问，请使用以上镜像．
</content>
    </entry>
    
     <entry>
        <title>Web测试及工具</title>
        <url>https://xulizhao.com/blog/webtest/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 整理下测试相关的东西在这里。
说到Web网页自动化测试，事实上的唯一标准就是基于WebDriver/Selenium的实现了。
 说明: WebDriver 等同于Selenium2
 WebDriver 介绍 WebDriver 是一个跨浏览器的网站自动化测试API，主要包含以下几方面
 Browser Control： navigation, snapshotting, window control, override geolocation User input simulation： mouse, keyborad, file uploads, altert handling Web stuff： find/query elements, evaluate JavaScript, manipulate cookies  页面对象模型 页面对象模型是挺早就有的一个概念，现在也是实现的一个通用标准/最佳实践.
他的思想是应该暴露你要交互的服务而不是具体实现，即你的测试方法不应该包含最底层的WebDriver API。
如果某些复杂UI的层次结构只是用来组织UI，应该与page对象分离开。断言也应该与页面对象分离。
同时“页面”对象并不意味着为每个页面建立一个这样的对象，比如页面有重要意义的元素可以独立为一个page对象。
Martin Flower最早提出的Page Object英文版/中文版
页面对象的例子  Page(object)  init(self, testsetup) get_url(self, url) is_the_current_page get_url_current_page is_element_present(self, *locator) is_element_visible(self, *locator) return_to_previous_page   Base(Page) Regions  一些流行语言的工具和框架实现 Selenium Server  Docker images for Selenium Grid Server  # start the hubjava -jar selenium-server-standalone-2.47.0.jar -role hub -port 4444# start the nodejava -jar selenium-server-standalone-2.47.0.jar -role node -hub http://localhost:4444/grid/register# 其他java -jar selenium-server-standalone-{version}.jar -Dwebdriver.chrome.driver=/path/to/chromedriver# Chrome Onlychromedriver --port=4444 --url-base=wd/hubPython实现  Selenium with Python:Python使用文档 splinter PageObject库 RobotFramework库  Java实现 基本组成：
 UI层: selenide Report框架: allure 断言框架: assertj-core/assertj-db 基础测试框架: TestNG/JUnit  相关网站/文档：
 Selenide/示例 结合TestNG JDK:java.awt.Robot Atlassian Selenium: 供学习 Dagger:网易开源，不再维护，同样基于TestNG,供参考  Node.JS/JavaScript实现  UI Recorder:阿里的录制回放工具 Intern :全功能自动化测试工具 Karma:浏览器测试执行工具, 因AngularJS而生 WebdriverIO :Node.js库,结合BDD框架使用 Nightwatch.js :Node.JS 实现的UI测试框架 Testnium:GroupOn的Node集成测试库 Protractor : E2E测试Angular应用  响应式布局测试  Galen  Jenkins集成 SeleniumPlugin
浏览器辅助工具 Chrome
 CSS Selector Helper for Chrome Selenium Page Object Generator  Firefox
 Firebug Firefinder : Finds HTML elements matching chosen CSS selector(s) or XPath expression xpathchecker : An interactive editor for XPath expressions &amp;ndash; Firefox Extension WebDriver Element Locator 2.0  示例 元素定位 CSS Selector
 .class #id element [operator: , &amp;gt; &#43; ~ ] element [id] :checked  参考文档CSS Selector/测试页/关于Selectors
关于等待 # Waiting for an element to appear driver.wait(until.elementLocated(by.id(&amp;#39;elementappearschild&amp;#39;)), 10000, &amp;#39;Could not locate the child element within the time specified&amp;#39;);# Waiting for an element to disappear //Method1: driver.wait(until.elementIsNotVisible(element),10000);//Method2 [better]:driver.wait(function() {return driver.isElementPresent(by.id(&amp;#39;elementdisappears&amp;#39;)).then(function(present) {return !present;});}, 10000, &amp;#39;The element was still present when it should have disappeared.&amp;#39;);# Waiting for an element’s text to change to a value driver.wait(until.elementTextContains(element, &amp;#39;new&amp;#39;),10000);扩展阅读  官方文档 Architecture of Selenium Webdriver Selenium Guidebook Chrome’s Developer Console Mozillians Tests  </content>
    </entry>
    
     <entry>
        <title>接口测试及工具</title>
        <url>https://xulizhao.com/blog/apitest/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 接口（API）测试随着REST的流行有了更多使用场合，基于测试金字塔理论，偏底层的接口测试是投入产出最高的。 接口可能是面向web、客户端或其他后台服务, 着重关注于服务器端的逻辑验证。
接口测试基本操作：
 生成符合协议格式的请求数据 向指定接口发送数据并接受响应 验证响应码并解析响应内容，确保符合预期数据  接口测试的用例分以下两类：
 单接口用例： 主要测试不同参数数据组合得到的响应符合期望值 多接口业务用例 ： 更偏向业务的实际应用场景，尽量提高覆盖  通常情况下，接口测试自动化的实现会基于单元测试框架作为测试脚本的运行驱动, 为减少数据依赖通常也会引入Mock数据. 最终部署形式通常与CI系统(Jenkins)整合.
实现细节  request生成  URL Path构成 URL查询参数 header/cookie/payload:json,urlencode,multipart-form   response信息断言  响应码 header/cookie/payload:json等 响应时间 响应内容匹配   response内容断言  类型判断 正则匹配 json schema匹配和查询   显示项  详细错误 json比较    最好支持的功能  支持单个接口灵活的验证  支持测试环境/Host 正则和常见类型支持 response取值或之前变量的引用 易用的认证   支持组合场景 美观的测试报告 和CI的集成及历史趋势  参考工具/框架 Java实现：
Java的生态相对成熟丰富, 牵涉到几个常用库:
 karate: BDD测试，支持JSON、XML rest-assured： 更友好的DSL测试语法 Hamcrest ： 灵活的匹配表达式(matchers),新版JUnit已内置;支持多语言 WireMock: HTTP服务Mock工具 Diffy ： Twitter开源的回归测试工具, 通过代理的形式比较响应内容,验证新代码是否引入缺陷.用Scala开发. WeTest:(不再维护)微博开源的基于JUnit4的轻量级接口自动化测试框架  Python实现
 QTAF:腾讯的开源测试框架 HttpRunner: YAML/JSON里定义测试用例 ApiTestManage: 待考察  Node.JS实现
 rap2:阿里妈妈开源接口管理工具  Go实现
 httpexpect  </content>
    </entry>
    
     <entry>
        <title>用Makefile简化重复的多个命令</title>
        <url>https://xulizhao.com/blog/makefile/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 经常会通过编译安装一些Linux包,最熟悉的就是make test, make install 这类命令了,以为make只适用于编译安装.
实际上发现Makefile/makefile在简化一些常用命令(多行命令或长命令)时也非常方便.
# Makefileinstall:@go get github.com/revel/cmd/revel@dep ensureserver:revel run github.com/xulz/webapp Makefile规则 &amp;lt;目标&amp;gt;:&amp;lt;执行的前提条件,即有文件更新才执行&amp;gt;
(tab) 具体的命令
 默认执行第一个目标. 在命令前添加@ 表示不打印正在执行的命令  Makefile的一些语法 # 定义变量, 使用 $(LDIR) 引用LDIR =../lib 自动化变量:
  $&amp;lt; 表示所有的依赖目标集
  $@ 表示目标集
  调试 带参数 -n或&amp;ndash;just-print, 只显示命令而不执行.
扩展阅读  跟我一起写Makefile/另一个整理版本 如何调试MAKEFILE变量  </content>
    </entry>
    
     <entry>
        <title>用Jupyter/iPython Notebook做笔记</title>
        <url>https://xulizhao.com/blog/jupyter-ipython-notebook/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> ipython作为一个必备的学习/调试环境, notebook可以看做其增强版, 支持Markdown格式说明, 很适合用笔记或者演示/培训用途,基本是机器学习的标配.
安装及运行 python3 -m pip install jupyter notebookjupyter notebook# 新版的iPython要求Python 3.3以上,因此建议在python3环境使用如果要在Python2.7运行,安装IPython5.7分支.
pip install ipythonipython如果在本地没有运行环境,又想打开一个包含笔记的GitHub仓库, 可以使用binder在云端打开.
多用户版本  jupyterhub  扩展阅读  官网 用Jupyter做slides/ppt Python学习课程  </content>
    </entry>
    
     <entry>
        <title>你的网站账号密码安全吗</title>
        <url>https://xulizhao.com/blog/check-your-password/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>security</tag>
        </tags>
        <content type="html"> 今天看了Django开发者的一篇文章,关于web安全的子项目, 其中提到了一个用于检测用户密码是否安全的API.
不同于普通的密码强度检测,它的检测原理基于最近这些年大型的互联网公司数据库泄漏事件,比如CSDN,天涯,HiAPK安卓网,网易等.
对普通用户,提供两个主要的网页查询功能:
 你邮件账户的密码是否已泄漏[1] 你正在使用的密码是否存在于泄漏数据库及被其他用户泄漏的次数[2]  通过API用Python检测的例子 import hashlibpassword = &#39;swordfish&#39;digest = hashlib.sha1(password.encode(&#39;utf-8&#39;)).hexdigest().upper()print(digest)# 4F57181DCAADE980555F2CE6755CA425F00658BE 然后访问 https://api.pwnedpasswords.com/range/4F571 (URL最后的参数是以上哈希摘要的前5位)
在响应内容中搜索以上哈希摘要的剩余字符 81DCAADE980555F2CE6755CA425F00658BE
如果检索到,则冒号:后面的数字就是被泄漏的次数, 如果成百上千了,一定要修改你的密码.
密码基本原则  密码分级: 根据是否涉及支付和隐私,最起码分成强密码和弱密码两类,强密码定期更新(每年). 如果是一次性注册网站, 使用固定的弱密码. 不要使用其他人也常用的弱密码或容易猜到的内容. 强密码定义: 8位及以上,包含大小写字母,数字和符号   注: 其实很早之前使用过2次这个网站,记录下让更多人知道.
</content>
    </entry>
    
     <entry>
        <title>回到WordPress</title>
        <url>https://xulizhao.com/play/blog-wordpress/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 最近几年博客经历 3年前改用Evernote做笔记,因为很少写博客的原因停掉了国外共享主机的wordpress,之前的内容也迁移到了Blogger平台(国内不可访问,仅作为备份).
后来为了学习git和markdown,也时常在GitHub上写笔记.
久闻Go大名已久,在听了播客内核恐慌某期讲静态博客后,尝试了高性能的Hugo.
去年总收到阿里云的广告促销,也想有一个移动版调试系统,就购买了云主机,把域名也迁到了国内.
在上面部署了静态博客, 由于Hugo/Lektor缺乏好用的主题,最后使用了已有所了解的Hexo. 也就有了前两篇搭建博客的记录文章.
WordPress 又回到WordPress,其实是为了让写博客这件事变得简单. 不管静态博客还是新生代Ghost,最终用下来的感觉是表面看似简洁的新博客使用起来并不简单.
例如静态博客, 需要git版本管理,每次修改需要commit/push, Hexo需要generate/deploy(虽然这一步在Github Pages可以hook自动化),有时候还需要clean,而生成静态页面/rsync并不像Hugo那么智能高效.
由于云主机几乎没有资源占用率,实际上新版WordPress有很大改进,在插件优化之后,安装前后资源占用几乎没有变化.
之前WordPress使用时间比较长,对插件/主题比较熟悉,只记录下关键步骤.
在Ubuntu16上安装可参考DO上的这篇文章.
# 安装php7环境sudo apt-get install php-fpm php-mysqlsudo apt-get install php7.0-mysql php7.0-curl php7.0-gd php7.0-mbstring php7.0-mcrypt php7.0-xml php7.0-xmlrpcsudo systemctl restart php7.0-fpm# Nginx更新用户vi /etc/nginx/nginx.confuser www-data; # 默认nginx# 调试用,查看当前php用户组ps aux | grep php# 文件夹权限sudo chown -R xulz:www-data /var/www/htmlsudo find /var/www/html -type d -exec chmod g&#43;s {} \;sudo chmod g&#43;w /var/www/html/wp-contentsudo chmod -R g&#43;w /var/www/html/wp-content/themessudo chmod -R g&#43;w /var/www/html/wp-content/plugins</content>
    </entry>
    
     <entry>
        <title>Linux Bash笔记</title>
        <url>https://xulizhao.com/blog/linux-bash/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 这里主要记录Linux系统的默认shell Bash用法.
快捷键 当前命令编辑  Ctrl &#43; A : 光标移到开头 Ctrl &#43; E : 光标移到结尾 Ctrl &#43; U : 删除整行 Ctrl &#43; W : 删除前一个单词  历史命令  Ctrl &#43; R : 历史命令查找 ^old^new : 替换上一个命令字符串 sudo !! : sudo执行上一个命令 Alt &#43; . : 打印上一个命令的最后参数 !$ : 特殊变量,代表上一个命令的最后参数  目录切换  cd - : 切换到上一个工作目录 cd ~ : 切换到Home目录  关于dirs,pushd,popd命令的用法参加此文.
Bash特定用法 环境变量 # Linuxvi ~/.bash_profileexport PATH=&amp;#34;/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin&amp;#34;# Macvi /etc/pathsshebang #!/bin/bash# 脚本执行时告诉shell用哪个程序解释脚本#! /bin/bash -xe# -x 执行详细脚本, 等同于 set -x, 可用于调试目的# -e 遇到非0错误立即退出, 等同于 set -e重定向/管道 2&amp;gt;&amp;amp;1# 1 代表 stdout, 2 代表 stderr.# 2&amp;gt;1 可以看做重定向 stderr 到 stdout.实际上被解释为 &amp;#34;重定向 stderr 到文件名为 1的文件&amp;#34;. # &amp;amp; 指出接下来是一个文件描述符而不是一个文件制作包含二进制数据的安装脚本 参考1/2
Bash 脚本 变量 # 变量赋值=周围不能包含空格VARNAME=&amp;#34;value&amp;#34;# 单引号&amp;#39;&amp;#39;保持每个字符的字面值# 双引号&amp;#34;&amp;#34;保持每个字符的字面值,除了$,``,\# 转义字符使用\# 显示当前日期$(date &#43;%Y-%m-%d)subshell 使用(在子命令范围有效), 如临时切换目录等.
循环 while [$port -lt 1024]doport = &amp;#39;expr $port &#43; 1&amp;#39;; done多分支选择 case &amp;#34;$1&amp;#34; instart)./start.sh;;stop)./stop.sh;;*)echo &amp;#34;Usage: $0{start|stop}&amp;#34;exit 1;;esacHereDoc 也许你没听过这个名字,但一定见过这个用法.
它会把开头的单词做标记,提取中间的内容作为标准输入stdin.
# 格式&amp;lt;&amp;lt;[-]END_TEXThere-documentEND_TEXT# 示例1cat &amp;lt;&amp;lt;EOFMy home directory is $HOMEEOF# 说明: 默认会解释内容中的变量符号# 如果要保持原样,开头要加上引号&amp;#39;EOF&amp;#39;# 如果要去掉格式中的tab符号,前面加-EOF# 示例2,利用定向符cat &amp;lt;&amp;lt;EOF &amp;gt; fileMy home dir is $HOMEEOF# 精简格式fmt -t -w 20 &amp;lt;&amp;lt;&amp;lt; &amp;#39;Wrap this silly sentence.&amp;#39;Troubleshooting tab 不能自动补全?  sudo dpkg-reconfigure dash 选择no (原因: 默认创建的新用户使用的dash)
 sh脚本异常：/bin/sh^M:bad interpreter: No such file or directory  :set ff=unix
 资源  pure bash bible: 常用功能代码 interactive Shell Programming tutorial Bash新手指南 Bash Guide Advanced Bash-Scripting Guide </content>
    </entry>
    
     <entry>
        <title>Linux文件查找/内容搜索命令</title>
        <url>https://xulizhao.com/blog/linux-search/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Linux的文件检索或者日志文件关键字搜索应该是很常用的工作场景, 这里汇总常见的命令用法.
find # 只查找特定文件find . -type f -name &amp;#39;*.py&amp;#39;# 只查找特定文件find . -type f -name &amp;#39;*.py&amp;#39;# 在所有目录查找特定文件名find / -type f -name httpd.conf# 忽略大小写find . -iname# 忽略目录find / -xdev -type f -size &#43;100M find / -size &#43;100M -not -path &amp;#39;/proc/*&amp;#39;查找大文件 # large-file.shfind / -type f -not -path &amp;#39;/proc/*&amp;#39; -size &#43;100M -exec ls -lh {} \;|sort -rh -k5find / -xdev -type f -size &#43;100M -exec ls -lh {} \;|sort -rk5find . -type f -size &#43;100M -exec ls -lh {} \; | awk &amp;#39;{ print $8 &amp;#34;: &amp;#34; $5 }&amp;#39; # 支持文件名含空格 find $1 -type f -exec stat --format &amp;#39;%Y :%y %n&amp;#39; {} \; | sort -nr | cut -d: -f2- | head # 执行更快 find $1 -type f | xargs stat --format &amp;#39;%Y :%y %n&amp;#39; | sort -nr | cut -d: -f2- | head # 最常用  统计代码行数 find . -name ‘.py’ | xargs wc -l(find ./ -name &#39;.py&#39; -print0 | xargs -0 cat)|wc -l# 注: -print0 | xargs -0 == -X 规避特殊字符 grep/egrep  grep [OPTIONS] PATTERN [FILE&amp;hellip;] grep [OPTIONS] &amp;ldquo;text string to search” directory-path
 -w # 匹配单词-i # 忽略大小写-color -R, -r #recursively, 递归的查找子文件夹-n # 显示行号-a, --text # 把二进制文件当作text处理--exclude: --exclude=*.o--include: --include=*.{c,h} # 只检索匹配的文件--exclude-dir: --exclude-dir={dir1,dir2,*.dst}--include-dir: -o # 只显示匹配行-l # 只显示匹配文件名| # 匹配多个 显示上下文 -B num # 显示匹配前多少行-A num # 显示匹配后多少行# 示例grep -B 3 -A 2 foo README.txt# 如果显示相同行的上下文,可使用-C num# 或者-n 查找某时间区间 grep &amp;quot;31/Mar/2002:19:3[1-5]&amp;quot; logfileegrep &#39;^[^ ]&#43; (0[89]|1[0-9]|2[012]):&#39;# awk的方式awk -v from=&amp;quot;12:52:33&amp;quot; -v to &amp;quot;12:59:33&amp;quot; &#39;$1&amp;gt;=from &amp;amp;&amp;amp; $1&amp;lt;=to&#39; foo.logawk &#39;$0 &amp;gt;= &amp;quot;13/05/13 07:50&amp;quot; &amp;amp;&amp;amp; $0 &amp;lt;= &amp;quot;13/05/23 01:58&amp;quot;&#39;# sed的方式sed -rne &#39;/&amp;lt;timestamp&amp;gt;/,/&amp;lt;timestamp&amp;gt;/ p&#39; &amp;lt;file&amp;gt;# 示例sed -n &#39;/Feb 23 13:55/,/Feb 23 14:00/p&#39; /var/log/mail.logsed -n &#39;/Feb 21 23:08:19/,/Feb 21 23:08:23/p&#39; daemon.log awk/sed awk &#39;NR&amp;gt;=10&amp;amp;&amp;amp;NR&amp;lt;=20&#39; in.log &amp;gt; out.logsed -n &#39;100,1000 p&#39; in.log &amp;gt; out.log sed  sed -i &amp;lsquo;s/foo/bar/gI&amp;rsquo; hello.txt
  -i 直接替换原文 -i.bak 同时保存备份 s 替换 / 分割符，也常用&#43;代替 g 全局替换而不是第一项 I 不区分大小写  # 输出带填充的数字序列seq -w 1 15seq -f &amp;#34;%05g&amp;#34; 1 15sort/uniq/cut/tr sort  -n 以数字而非字母排序 -h 更可读的方式显示 -r 倒序排列 -k 5 第五列 -t, &amp;ndash;field-separator=SEP # 指定分隔符 -s, &amp;ndash;stable # 稳定排序,用于多列排序  uniq  -u 只显示唯一行 -d 只显示重复行 -c 显示重复次数  cut  -d&amp;rsquo;:&amp;rsquo; 以冒号为分隔符,默认分隔符为tab -f1-4 选取1~4列  tr 转换/替换/删除字符 tr -d &#39;input-characters&#39; # 删除字符tr -s &#39;\n&#39; # 把重复字符压缩为一个,s代表squeezetr &amp;quot;[:lower:]&amp;quot; &amp;quot;[:upper:]&amp;quot; &amp;lt; filename # 转换大小写tr -cd &amp;quot;[:print:]&amp;quot; &amp;lt; filename # 取消非打印字符, c代表complement 扩展 xargs  xargs [options] [command] 构造参数列表然后执行. 将标准输入或管道转换为命令行的参数,如果省略command则默认使用echo. 通常用作替代find的-exec参数,因为xargs如果出错不会停止执行.
 常用选项:
 -0 ,&amp;ndash;null 以空字符为结束符, 和find -print0结合使用 -I_ 以_为替换字符 -L max-lines 最多个非空行执行一次 -I replace-str 替换字符串,以换行符为分割符  -exec 系统包查找 yum # 查找包含某命令的包yum provides mpstat# 查询安装包名rpm -qpi ***.rpm  资源  SED单行脚本快速参考 </content>
    </entry>
    
     <entry>
        <title>pytest测试框架</title>
        <url>https://xulizhao.com/blog/pytest/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>python</tag>
        </tags>
        <content type="html"> 单元测试最初流行是从JUnit,而他的发明者Kent Beck大神的经典名作&amp;lt;测试驱动开发&amp;gt;这本小书却引领了TDD的风潮,产生了xUnit各个语言系列.
初次接触pytest,感觉不像个xUnit,因为既看不到对TestCase的继承,也找不到Setup/Teardown这些建立/销毁函数.当然这些基本功能肯定是支持的.
pytest虽然作为一个Python单元测试框架的扩展版, 但是它丰富的功能和灵活的特性也很适合做功能测试, 其中的精华就是fixtures.
py.test 用法 pytest提供丰富的命令行参数.
pytest -h# 其他用法-q, --quiet -s --capture=no --cache-show--cache-clear 下面以测试过程为序,展开各过程主要用法.
配置 pytest配置文件: pytest.ini|tox.ini|setup.cfg
收集 pytest.mark  注: 只作用于tests,对fixture无效
 命令行测试用例选择: -k EXPRESSION : 按正则选取-m MARKEXPR : 示例 &amp;quot;not (slow or long)”--ignore=path 忽略部分测试集 运行 基本用法:
 pytest test_mod.py::TestClass::test_method
 命令行辅助选项:
--lf, --last-failed rerun only the tests that failed at the last run (or all if none failed)# 退出条件:-x, --exitfirst 出错后退出--maxfail=num 失败N次后退出 包含上级模块到包路径 集中方式
# 在根目录创建空文件conftest.py # 或 python -m pytest tests/ # 或设置环境变量 PYTHONPATH # 或直接修改代码,添加 import sys, ostestPath = os.path.dirname(os.path.abspath(__file__))sys.path.insert(0, testPath &#43; &amp;#39;/../&amp;#39;)报告 # 需要先安装pytest-html插件py.test --html=report.html# 命令行选项:--durations=N # 显示最慢的执行 (N=0 for all) fixture fixtures通常存放在根目录的conftest.py或子文件夹的conftest.py(可用来覆盖并重新定义).
装饰器标记函数为fixture, 总体上fixtures提供:
 单元测试框架的基本功能 依赖注入: 一些共有函数值/帮助函数/Mock等 测试数据参数化 灵活性由不同的作用范围和目录级conftest.py等提供  fixture的用法 @pytest.fixture()
主要参数:
 scope: session/module/class params: 参数化,会执行多次 autouse=True  tear down函数体定义:
 代码块为yield之后的所有语句 或者使用request.addfinalizer(fin)的方式 (好处:及时发生异常也会执行)  参数化 request.params
tests之间共享数据 @pytest.fixture(scope=&amp;#34;module&amp;#34;)def data():return {&amp;#34;key1&amp;#34;: None, &amp;#34;key2&amp;#34;: &amp;#34;value2&amp;#34;}test run之间共享数据: cache
# 通过request fixturerequest.config.cache.set(&amp;#39;shared&amp;#39;,&amp;#39;a&amp;#39;)assert request.config.cache.get(&amp;#39;shared&amp;#39;,None) == &amp;#39;a&amp;#39;命令行辅助项 &amp;ndash;fixtures 显示可用的fixture &amp;ndash;setup-only only setup fixtures, do not execute tests. &amp;ndash;setup-show show setup of fixtures while executing tests. &amp;ndash;setup-plan show what fixtures and tests would be executed but don&#39;t execute anything.
内置的fixture  tmpdir pytestconfig cache monkeypatch capsys doctest_namespace recwarn  # monkeypatch： mock模块和环境 monkeypatch.setattr()monkeypatch.delattr()功能介绍 日志相关 # 命令行参数--log-level--log-cli-level报告 # 生成HTML报告，需插件支持pytest --html=report.html# 生成JUnit兼容报告，方便与Jenkins集成pytest --junitxml=junit-report.xml扩展资源 流行插件  pytest-variables : 通过json文件定义共享变量 pytest-timeout: 测试超时插件,避免长时间异常运行 pytest-ordering: 指定测试顺序 pytest-dependency: 测试依赖关系 pytest-xdist : 并行/分布式执行测试 pytest-html : HTML测试报告 pytest-selenium  示例
# 指定执行顺序 # 原理是修改hook: pytest_collection_modifyitems @pytest.mark,first@pytest.mark.order#1 @pytest.mark.run(order=1)# 超时设置 @pytest.mark.timeout(60)# 依赖 @pytest.mark.dependency(name=&amp;#34;b&amp;#34;)@pytest.mark.dependency(name=&amp;#34;e&amp;#34;, depends=[&amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;])文档  conftest的用法 配置文件 API接口和内置方法 </content>
    </entry>
    
     <entry>
        <title>Linux系统命令</title>
        <url>https://xulizhao.com/blog/linux-system-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Linux系統命令, 完成一些常見任務.
常用命令使用帮助 用示例方式的简化版man手册, tldr
sudo npm install -g tldr 用户管理 # 添加用户sudo useradd -m xulzsudo passwd xulzsudo权限 # 创建sudo组用户useradd -aG sudo xulz# 添加到sudogpasswd -a xulz sudo # Ubuntugpasswd -a xulz wheel # CentOS# sudo免密码输入echo &amp;#34;xulz ALL=(ALL) NOPASSWD:ALL&amp;#34; | sudo tee /etc/sudoers.d/nopass更改UID(user)和GID(group) usermod -u 2001 xulzgroupmod -g 2001 xulz# 注: 以上命令仅修改home目录,其他目录需手动执行组权限 groupadd perftestusermod -a -G perftest ubuntuusermod -a -G perftest jenkinschgrp -R perftest /opt/jmeter文件管理 # 创建HOME目录mkhomedir_helper xulz# 输出全路径readlink -f myfile# 创建软链接# f 代表重写原链接# T 代表把链接当做普通文件ln -sfT path/to/file path/to/symlink文件内容浏览 lessheadtailtail -f &amp;lt;file_name&amp;gt;磁盘空间占用 # 磁盘空间df -h# 文件夹占用空间大小汇总du -sh /home/xulz# 限制深度du -h --max-depth=N /home/xulz# 通配符du -ch */*.png权限 # 修改所有者和组chown user:group file_or_directory# 修改文件权限chmod u&#43;x your_file# [u]ser/[g]roup/[o]thers/[a]ll# [r]ead/[w]rite/e[x]ecute# 支持操作符 &#43;-=# -R 文件夹递归删除除某文件外的所有文件 # 如果要删除文件夹,更新为 -type d -rfind . ! -name &amp;#39;file.txt&amp;#39; -type f -exec rm -f {} &#43;# 或者# enable extglobshopt -s extglobrm -rf -- !(file.txt)mc 目录浏览和文件管理 类似 total command
Server必备 同步系统时间 # CentOSyum install ntpsystemctl enable ntpd.service # CentOS 7.x# chkconfig ntpd on # CentOS 6.xntpdate pool.ntp.org# Ubuntuapt install ntpservice ntp restart进程管理 nohup 不挂断地运行命令。 运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。 在注销后使用 nohup 命令运行后台中的程序。 要运行后台中的 nohup 命令，添加 &amp;amp; （ 表示“and”的符号）到命令的尾部。
网络 常用命令 ifconfig#ipconfig # for Windowsip a增强工具  mtr: 网络调试工具 iperf3: 网络吞吐测试  修改hostname hostnamectl set-hostname moon# 等价于修改/etc/hostname(需要重启)并执行hostname moonhostname # 查看当前值# 只应用于内部网络IP映射vi /ect/hostsvi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=newHostName# 重启服务以生效/etc/init.d/network restart更新DNS # 根据以下三个文件动态生成:head,base,tailsudo vi /etc/resolvconf/resolv.conf.d/tail# 更新DNSsudo resolvconf -u# 查看当前配置cat /etc/resolve.conf主要配置项:
search xulizhao.comnameserver 192.168.1.1系统 # 时间戳转换date -d@1234567890# 显示unix时间戳date &#43;%s# 关机shutdown -h now文件完整性校验 md5sum filesha256sum file增强命令 open# gittig# HTTP Clienthttpie# 彩显文本lolcat# 浏览器w3mlynx复制/粘贴 # 复制/粘贴apt install xclip # 类似Mac的pbcopy/pbpastealias pbcopy=&amp;#39;xclip -selection clipboard&amp;#39;alias pbpaste=&amp;#39;xclip -selection clipboard -o&amp;#39;</content>
    </entry>
    
     <entry>
        <title>Linux调优</title>
        <url>https://xulizhao.com/blog/linux-tuning/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> Linux作为服务器针对使用场景, 有许多需要调优的地方, 本文记录常用优化项.
性能基本调优 通常涉及到/etc/sysctl.conf和/etc/security/limits.conf配置文件的修改.
也可使用命令修改,使用sysctl -p 立即生效.
内核参数设置 sysctl命令可以用来实时的读取/修改内核参数
# 显示所有可用内核参数sysctl -a# 加载/etc/sysctl.conf的参数sysctl -p提高文件描述符限制 soft limit类似于warning, hard limit是真实的最大值限制.
默认的1024偏小, 有两种方式修改:
临时设置 # 查看当前值ulimit -n# 临时增加ulimit -n 65535# 单个进程的限制为soft limit# hard limit应小于当前系统打开的文件描述符# 相应增加nr_openecho 2000000 &amp;gt; /proc/sys/fs/nr_open# 系统级限制, 上限为nr_openecho 1000000 &amp;gt; /proc/sys/fs/file-maxSystemD服务设置 在CentOS7使用SystemD启动的服务不同于CentOS6, 对/etc/security/limits.conf的设置不会生效.
需要修改/etc/systemd/system.conf或/etc/systemd/system.conf.d/tomcat.conf.
# 对应下面几项DefaultLimitCORE=infinityDefaultLimitNOFILE=102400DefaultLimitNPROC=102400常用的命令:
# 查看当前进程的限制cat /proc/$(pgrep java)/limits# 查看当前进程句柄数lsof -p $(pgrep java)|wc -l## 或者使用ls /proc/$(pgrep java)/fd|wc -l永久设置 修改 /etc/security/limits.conf,重启以生效.
* soft nofile 65535* hard nofile 65535root soft nofile 65535root hard nofile 65535# 系统级内核句柄限制fs.file-max = 1000000查看当前描述符情况 # 列出打开/占用的文件描述符cat /proc/sys/fs/file-nr# 三个值分别代表 占用/未使用/最大可用值# 注: lsof只会列出进程占用lsof | wc -l# 要得到线程占用,需要使用ps -eLf# 查看某进程限制cat /proc/[Process ID]/limits增加可用端口数 默认28000, net.ipv4.ip_local_port_range
如果Nginx作代理,需要增加端口范围,否则会出现错误: Cannot assign requested address .
IPv4端口可用数:端口号是16位无符号整数,即65535
# 实时生效echo 12000 64000 &amp;gt; /proc/sys/net/ipv4/ip_local_port_range# 永久生效sysctl -w net.ipv4.ip_local_port_range=&amp;#34;12000 64000&amp;#34;可选:最大线程数 一般不需要设置
# 默认31299echo 100000 &amp;gt; /proc/sys/kernel/threads-max 查看当前线程数:
 top, then hit H to view threads top -H htop  网络调优 通用网络参数 /etc/sysctl.conf# 系统网络设置# 生效值取系统和下面TCP设置值的最大值net.core.rmem_max = 16777216net.core.wmem_max = 16777216 TCP/IP调优 Backlog Queue 最大连接数队列. 可选, 查看kernel日志决定是否需要调整
net.core.somaxconnnet.core.netdev_max_backlog = 300000 网络缓冲区大小 # TCP读取缓冲区# 格式: 最小值/默认值/最大值 字节数# cat /proc/sys/net/ipv4/tcp_rmemnet.ipv4.tcp_rmem = 4096 87380 16777216# 发送缓冲区net.ipv4.tcp_wmem = 4096 65536 16777216# TCP内存, 对应 low/pressure/high 页大小(4K)net.ipv4.tcp_mem = 786432 2097152 3145728 UDP调优 默认比较受限
#改成8Msysctl -w net.core.rmem_max=8388608 主要参数 Receive-Side Scaling (RSS) also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs.
cat /sys/class/net/eth1/queues/&amp;lt;rx-0&amp;gt;/ethtool --show-rxfh-indir eth1 CLOSE_WAIT 和 TIME_WAIT 解释 TCP是全双工的,任何一端可以是source或destination.
Due to the way TCP/IP works, connections can not be closed immediately. Packets may arrive out of order or be retransmitted after the connection has been closed.
CLOSE_WAIT indicates that the remote endpoint (other side of the connection) has closed the connection.
TIME_WAIT indicates that local endpoint (this side) has closed the connection. The connection is being kept around so that any delayed packets can be matched to the connection and handled appropriately.
The connections will be removed when they time out within four minutes.
tcp_tw_reuse和tcp_tw_recycle 不用开启 net.ipv4.tcp_tw_recycle, 最新内核4.12已结去掉该参数.
连接有incoming和outgoing之分，tcp_tw_reuse仅仅对outgoing有效.
设计协议时,尽量不用让客户端先关闭连接,应该让服务端控制.
TCP/UDP参数  Socket receive buffer size: Socket send and receive sizes are dynamically adjusted, so they rarely need to be manually edited. rmem_default : A kernel parameter that controls the default size of receive buffers used by sockets.  调优常用指标  Ping 100以下 网络延迟50ms以下 Dns解析尽量快 尽量少丢包 反向代理优化  调优辅助工具 perf-tools 开源的性能分析工具,基于perf和ftrace.
  Linux Performance Observability Tools   sysdig sysdig: Troubleshooting 工具，支持容器
SystemTap  SystemTap官方网站 CentOS有用的脚本  扩展阅读  Linux性能资源大全 RedHat官方系统调优指南 TCP的那些事儿 : TCP协议特点汇总 Linux TCP/IP 协议栈调 tcp_tw_reuse和tcp_tw_recycle调整对于过多TIME_WAIT的调研 centos7-systemd-conf-limits </content>
    </entry>
    
     <entry>
        <title>Nginx调优</title>
        <url>https://xulizhao.com/blog/nginx-tuning/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Nginx在部署服务时经常被用到, 大多时候是作为代理使用. 如果用户量比较大就涉及到一些调优, 本文做一些分类记录.
以下部分主要基于两个主要配置文件:nginx.conf和conf.d/default.conf展开.
Worker Processes # 默认为1, 应更新为一个CPU核心一个worker# 查看CPU核数 $grep ^processor /proc/cpuinfo | wc -l worker_processes auto;# 文件句柄数,默认跟随系统设置worker_rlimit_nofile 100000;# 事件驱动部分events {# 每个worker允许的连接数, 默认512worker_connections 65536;use epoll;multi_accept on;} HTTP和TCP优化 http{sendfile on;tcp_nopush on;tcp_nodelay on;} 文件访问优化 # 访问日志使用缓冲或关闭# 如果日志文件路径包含变量，需要打开open_log_file_cache以提高性能access_log buffer=size flush=time# 多使用缓存和压缩# 但是图片不应该开启压缩 Keepalive Connections   client保活
  upstream保活
http { # 以下两项为client保活配置 # 默认100, 一个keep-alive服务的最大请求数,超出后关闭连接 keepalive_requests 102400; keepalive_timeout 65;
# 以下为upstream保活配置keepalive 10240;# 默认和上游间60秒超时proxy_read_timeout 120;# 以下必须设置, 默认响应后会关闭连接proxy_http_version 1.1;proxy_set_header Connection &amp;quot;&amp;quot;; }
  限制IP连接和并发  limit_req_zone: 限制单位时间内的请求数，即速率限制,采用的漏桶算法 &amp;ldquo;leaky bucket&amp;rdquo; limit_req_conn: 限制同一时间连接数，即并发限制  扩展阅读  官方优化指南 linode优化 性能优化文章 </content>
    </entry>
    
     <entry>
        <title>分布式系统的那些论文及开源实现</title>
        <url>https://xulizhao.com/blog/distributed-paper/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 近几年总能看到大数据,云计算这些buzz word/时髦词, 可是说来惭愧,对近10来年历史上那些著名论文及主要内容却知道的很少.
之前零散的看到分布式系统的一些文章,接下来总结下主要内容,也打算读几本书系统的学习下.
今天先看看这些经典论文及衍生的开源系统.
按时间顺序/影响力最大的应该就是谷歌的老三篇了,即 GFS &#43; MapReduce &#43; BigTable.
论文列表  2003 Google File System/GFS 2004 Google MapReduce: Simplified Data Processing on Large Clusters 2006 Google The Bigtable &amp;ndash; A Distributed Storage System for Structured Data 2007 Amazon Dynamo 2010 Yahoo S4: distributed stream computing platform 2012 Google Spanner:Google&#39;s Globally-Distributed Database 2012 Google F1 &amp;ndash; The Fault-Tolerant Distributed RDBMS Supporting Google&#39;s Ad Business  对应的开源产品  GFS &#43; MapReduce &#43; BitTable : 对应Hadoop的HDFS和HBase S4(Simple Scalable Streaming System): Twitter开源的实时流计算Storm/继承者Heron Dynamo: Facebook开源的Cassandra, 之后出现了高性能C&#43;&#43;版本ScyllaDB (兼容Cassandra协议,KVM作者开发) SSTable &#43; LSM Tree(BigTable背后技术) : Google开源实现LevelDB和Facebook的分支RocksDB NoSQL(Not only SQL): 基于BigTable的实现, 主要有HBase/MongoDB/Cassandra NewSQL: 基于Spanner/F1的实现, 主要有 TiDB/CockroachDB   特点: Cassandra强调AP ，Hbase强调CP, Spanner 支持分布式事务
 其他概念  LSM: Log-Structured Merge SSTable: Sorted Strings Table paxos/raft : 一致性算法 HTAP: Hybrid transactional/analytical processing WAL: Write Ahead Logging MVCC(Multi-Version Concurrency Control): 多版本并发控制  资源 一些中文翻译和相关网页
 厦大中文版本 OpenOpen中文版本 </content>
    </entry>
    
     <entry>
        <title>NodeJS及前端开发</title>
        <url>https://xulizhao.com/blog/nodejs-and-frontend/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 因为最近使用的两个博客系统都是基于NodeJS开发的,也顺便谈谈我理解的JavaScript及前端开发.
NodeJS的是伴随Chrome的V8 Engine而出现,由于JS群众基础及高性能而快速发展,本质是它使用类似Nginx的事件循环模型可以处理极高的并发请求.异步IO及基于NodeJS的第三方库都提供的异步版本,使得较简单的编程模型带来极高的性能, JavaScipt这一应用于前端开发的古老语言焕发出新的生机.
早期前端开发的JavaScript由于要处理浏览器版本兼容且语言本身问题,充斥着丑陋的代码. 伴随着JQuery及第三方框架/库的流行,JavaScript也变得优美起来.
前端开发三剑客: HTML &#43; CSS &#43; JavaScript这些年随着新标准的发展也比我最初接触时强大易用多了, 一切事物还真得以发展的眼光看待,技术领域尤其容不得偏见.
因为偶尔会忘记,下面记些简单的笔记:
NodeJS Node是一个JS应用的平台,而不是框架. 尤其适用于数据密集型实时服务和大并发量/小数据块的长连接场景.
 匿名函数调用也被称为回调(a.k.a callback) steams是随时间进行的数据分发  Node版本 稳定版本: 10.x /最新版本: 12.x
Linux二进制安装 参考文档
# Using Ubuntucurl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -sudo apt-get install -y nodejs使用n管理多版本 npm install -g nn stable # n lts 使用nvm管理多版本 curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bashnvm install nodenvm use node 卸载 # Ubuntusudo rm -rf /usr/local/lib/node_modulessudo rm -rf ~/.npm# Macbrew uninstall --force node 包管理npm # 安装curl -0 -L https://npmjs.com/install.sh | sudo sh 选项说明:
 -g: 代表全局 &amp;ndash;save: 将模块安装到项目目录下，并在package文件的dependencies节点写入依赖  使用淘宝镜像 npm在国内的使用环境很糟,经常安装第三方包超时,强烈建议换成国内镜像.
# https://npm.taobao.org/# 相关工具镜像 https://npm.taobao.org/mirrorsnpm install -g cnpm --registry=https://registry.npm.taobao.org# 使用别名 cnpmecho &#39;\n#alias for cnpm\nalias cnpm=&amp;quot;npm --registry=https://registry.npm.taobao.org \--cache=$HOME/.npm/.cache/cnpm \--disturl=https://npm.taobao.org/dist \--userconfig=$HOME/.cnpmrc&amp;quot;&#39; &amp;gt;&amp;gt; ~/.zshrc &amp;amp;&amp;amp; source ~/.zshrc 依赖管理 Yarn Facebook出品替代npm的新工具
# https://yarnpkg.com/lang/en/docs/install/# Using Macbrew install yarn # 会自动安装Nodebrew install yarn --without-node # 使用node版本管理工具安装# Using Ubuntucurl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -echo &amp;#34;deb https://dl.yarnpkg.com/debian/ stable main&amp;#34; | sudo tee /etc/apt/sources.list.d/yarn.listsudo apt-get update &amp;amp;&amp;amp; sudo apt-get install yarn 资源  Mac使用指南 How To Install Node.js on Ubuntu 16.04  前端工具集 包管理 Bower
构建工具  注: 前面出现的较新
 自动化构建工具
Gulp vs. Grunt
把依赖全部提取到一个文件
webpack vs. browserify
桌面开发Electron 最早知道基于HTML&#43;CSS&#43;JavaScript的桌面开发是看到豌豆荚团队的访谈,知道了基于Chromium的CEF框架.
之后不断演进出优秀的Electron,该框架极大的简化了跨平台开发的成本,你很难想象VSCode,Slack等工具是基于Electron和Web开发技术做出来的.
JavaScript Babel JavaScript转换器,把高版本(ES标准)转换为浏览器兼容版本
JS语言增强  TypeScript CoffeeScript  资源  MDN学习资源  CSS CSS扩展语言  Less Stylus Saas  响应式设计 资源  @media 控制不同尺寸设备的显示 CSS3 模板 MDN学习资源  链接  百度的轮子 Babel : Facebook出品 Grunt </content>
    </entry>
    
     <entry>
        <title>静态博客Hexo</title>
        <url>https://xulizhao.com/play/blog-hexo/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 可能过于追求完美,使用Ghost博客两个多月,感觉功能还是过于简单,许多常用的功能用户早就提了Issue,官方却认为不是核心.
比如常用的文章目录,归档页,搜索功能等. 文章目录折腾下来已经可用了,搜索折腾了一半,实在没时间调试放弃了.见新博客这篇记录文章.
本来用这么个博客系统是为了不折腾,索性迁移到了之前熟知的Hexo&#43;NexT(国人最好用主题),该主题常用的扩展都提供,没想到的功能也支持,很👍.
安装及配置 npm install hexo-cli -ghexo init blogcd blognpm installhexo server## 产生静态文件，默认存放于 publichexo generate# 部署,我使用rsync的方式hexo deploy常用功能 主要参考./theme/next/_config.yml相应注释按步骤操作。
 RSS 调整主题scheme以获取不同的展示效果 增加搜索功能 使用rsync部署  // package.json{&amp;#34;name&amp;#34;: &amp;#34;hexo-site&amp;#34;,&amp;#34;version&amp;#34;: &amp;#34;0.0.0&amp;#34;,&amp;#34;private&amp;#34;: true,&amp;#34;hexo&amp;#34;: {&amp;#34;version&amp;#34;: &amp;#34;3.5.0&amp;#34;},&amp;#34;dependencies&amp;#34;: {&amp;#34;hexo&amp;#34;: &amp;#34;^3.2.0&amp;#34;,&amp;#34;hexo-algolia&amp;#34;: &amp;#34;^1.2.4&amp;#34;,&amp;#34;hexo-deployer-rsync&amp;#34;: &amp;#34;^0.1.3&amp;#34;,&amp;#34;hexo-generator-archive&amp;#34;: &amp;#34;^0.1.4&amp;#34;,&amp;#34;hexo-generator-category&amp;#34;: &amp;#34;^0.1.3&amp;#34;,&amp;#34;hexo-generator-feed&amp;#34;: &amp;#34;^1.2.2&amp;#34;,&amp;#34;hexo-generator-index&amp;#34;: &amp;#34;^0.2.0&amp;#34;,&amp;#34;hexo-generator-tag&amp;#34;: &amp;#34;^0.2.0&amp;#34;,&amp;#34;hexo-migrator-ghost&amp;#34;: &amp;#34;^0.1.0&amp;#34;,&amp;#34;hexo-renderer-ejs&amp;#34;: &amp;#34;^0.3.0&amp;#34;,&amp;#34;hexo-renderer-marked&amp;#34;: &amp;#34;^0.3.0&amp;#34;,&amp;#34;hexo-renderer-stylus&amp;#34;: &amp;#34;^0.3.1&amp;#34;,&amp;#34;hexo-server&amp;#34;: &amp;#34;^0.2.0&amp;#34;}}一些增强功能的展示 大部分功能只需要在配置中修改，非常易用。
{% note success %}
Success 说明文本
{% endnote %}
{% note info %}
info 说明文本
{% endnote %}
{% cq %} 人的一切痛苦,本质上都是对自己无能的愤怒.
** 王小波 **
{% endcq %}
{% fi /images/publication-cover.png, 测试, 好图 %}
链接  Hexo NexT主题文档 </content>
    </entry>
    
     <entry>
        <title>Linux调试命令/工具</title>
        <url>https://xulizhao.com/blog/linux-debug-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> Linux的强大之一是丰富的命令系统,尤其在调试服务端应用时.
记录在这里方便查阅.
资源统计 yum install sysstatmpstat -P ALL 1pidstat 1top -p &amp;lt;pid## 内存,IO相关free -mvmstat 1iostat -xz 1top/htop 名称解释
 RSS: Resident Set Size VmRSS: 进程除了swap外使用的物理内存大小 VmSwap: swap大小  watch # 每隔2秒更新一次内存变化watch free -hsar sar是System Activity Reporter（系统活动情况报告）的缩写
sar -n DEV 1sar -n TCP,ETCP 1vmstat vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可实时动态监视操作系统的虚拟内存、进程、CPU活动。
 cs: 代表 context switches in: 代表 interrupts  iostat 使用-x参数我们可以获得更多统计信息
 rrqm/s：每秒这个设备相关的读取请求有多少被Merge了(当系统调用需要读取数据的 时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge);wrqm/s：每秒这个 设备相关的写入请求有多少被Merge了。 rsec/s：每秒读取的扇区数;wsec/： 每秒写入的扇区数。r/s：The number of read requests that were issued to the device per second;w/s：The number of write requests that were issued to the device per second; await：每一个IO请求的处理的平均时间(单位是微秒)。这里可以理解为IO的响应时 间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。 %util：在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该 设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了(当然如果是多磁盘，即使%util是100%，因 为磁盘的并发能力，所以磁盘使用未必就到了瓶颈)。  命令参数
iostat [-c|-d] [-k] [-t] [间隔描述] [检测次数]
参 数：
-c : 仅显示cpu的状态-d : 仅显示存储设备的状态，不可以和-c一起使用-k : 默认显示的是读入读出的block信息，用-k可以改成KB大小来显示-t : 显示日期-p device | ALL : device为某个设备或者某个分区，如果使用ALL，就表示要显示所有分区和设备的信息CPU 占用情况包括四块内容%user：显示user level (applications)时，CPU的占用情况。%nice：显示user level在 nice priority 时，CPU 的占用情况。%sys: 显示 system level (kernel)时，CPU 的占用情况。%idle: 显示CPU 空闲时间所占比例。磁盘使用报告分成以下几个部分：Device: 块设备的名字tps: 该设备每秒 I/O 传输的次数。多个 I/O 请求可以组合为一个，每个 I/O 请求传输的字节数不同，因此可以将多个 I/O 请求合并为一个。Blk\_read/s, Blk\_wrtn/s: 表示从该设备每秒读写的数据块数量。块的大小可以不同，如1024, 2048 或 4048 字节，这取决于 partition 的大小。Blk\_read, Blk\_wrtn: 指示自从系统启动之后数据块读/写的合计数。也可以查看这几个文件/proc/stat，/proc/partitions，/proc/diskstats的内容。mpstat mpstat是MultiProcessor Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。
# 每隔2秒显示一次mpstat 2mpstat -P ALLmpstat -P 0 3 3 # 对第一块CPU，每隔3秒监控一次，重复3次。关键字段解释： LOC :Local interrupt Timer
CPU CPU 编号,all 那行是所有CPU的平均统计值。%user 在监控的时间间隔内，用户级进程（运用程序）占用的CPU时间百分比。%nice 在监控的时间间隔内，nice值为负的用户级进程所占用的CPU时间百分比。%sys 在监控的时间间隔内，系统及进程（内核）占用的CPU使用率。该时间包括了系统处理软、硬中断所花的时间。%iowait 在监控的时间间隔内，等待硬盘I/O的时间，CPU的闲置时间百分比。%irq 在监控的时间间隔内,CPU服务硬中断的所占的时间百分比。%soft 在监控的时间间隔内，CPU服务软中断的所占的时间百分比。%idle 在监控的时间间隔内，CPU闲置时间所占用的时间百分比，不包括等待磁盘IO请求的时间。其中最重要的字段是%idle,%iowait。如果%idle 说明CPU的负载不高。如果%iowait，说明存在I/O竞争。 也可以使用输出重定向保存mpstat对CPU的监控数据，用作CPU历史使用率分析。si 软中断太高: cat /proc/interruptsuptime dmesg 内核日志  dmesg | tail
 文件/进程类 ps # 查看用户线程数ps -fLu xulz# 根据pid找到processps -p &amp;lt;pid -o comm=# 显示不截断内容wwps auxwwps aux | less -&#43;Sps aux | most -w# 运行队列ps -eo stat,pid,user,command | egrep &amp;#34;^STAT|^D|^R&amp;#34;# D : Uninterruptible sleep (usually IO)# R : Running or runnable (on run queue)进程检索/管理 # 显示进程树pstree -ppgrepkill/pkill用法:
# 默认用SIGTERM (terminate)信号终止进程kill &amp;lt;porcess_id# 列出可用(不带SIG前缀的)信号名kill -l# 立即终止进程kill -9|KILL &amp;lt;process_id# 根据进程名称(而不是id)pkill &amp;lt;process_namepkill -f &amp;#34;command_name&amp;#34;lsof 列出文件打开情况
# 查看某进程打开连接lsof -i -a -p `pidof firefox`# 或者ss -nap | grep $(pidof firefox)# 查看端口占用 lsof -i :portNumberlsof -i :22taskset set or retrieve a process&#39;s CPU affinity
# 显示当前进程的 affinitytaskset -c -p 1162 # 设置进程的affinitytaskset -c 0,1 -p 1162taskset -c 1 proc Process information pseudo-filesystem
man proc/proc/&amp;lt;pid/status/proc/&amp;lt;pid/statm #Memoryvalgrind 查内存泄漏
网络类 # 显示所有打开连接ss -l # 或者netstat -tlpnnetstat -anp# 或者lsof -i# 更精确的方式显示打开的网络端口nmap -sT -O localhost# 如果遇到未知服务打开端口:cat /etc/services | grep 834网络连接监控ss socket stats
ss -sss -lp | grep 8080netstat 常用选项:
 -a/&amp;ndash;all: 显示监听和非监听连接 -n: 显示IP  # CentOS 7需要先安装yum install net-tools# 显示所有TCPnetstat -nat#Windowsnetstat -aon | more# 显示建立的TCP连接netstat -np | grep ESTABLISHED | wc -lnetstat -nat | grep &amp;#39;ESTABLISHED&amp;#39;netstat -s |grep &amp;#39;connections established&amp;#39; cURL 命令行文件传输工具.
常用选项:
-d, --data 使用类型 application/x-www-form-urlencoded做POST-F, --form &amp;lt;name=content-x, --proxy 代理设置-X, --request &amp;lt;command&amp;lt;/command 指定类型-I, --head 只显示响应头，在响应体较大时很有用# 在内网查看外网IPcurl ifconfig.mewget 域名解析 nslookup www.google.comdig xulizhao.comdnstracerdig &#43;trace xulizhao.com# 查找域名服务器less /etc/resolv.confnmcli device show &amp;lt;interfacename| grep IP4.DNSWindows从IP得到hostname: ping -a 10.10.10.10
修改DNS ## Ubuntuvi /etc/network/interfacesdns-nameservers 8.8.8.8# 重启服务/etc/init.d/networking restart## CentOSvi /etc/resolv.confnameserver 8.8.8.8网络调试traceroute/mtr mtr可以看做traceroute的加强版显示数据包在IP网络经过的路由器的IP地址,一直达到默认或用参数指定的追踪限制（maximum_hops）才结束追踪. [Windows] tracert响应格式: Hop RTT1 RTT2 RTT3 Domain Name [IP Address] 每个hop发送三个包, * 代表丢包使用ICMP协议 (同ping);RTT: round trip time ;延时突然增加并持续的增加通常意味着问题;网络数据统计iftop r 代表receive
# 某网口带宽占用iftop -i eth1# 子网数据流iftop -F 192.168.1.0/24网络模拟tc/netem 模拟网络延迟,丢包,重复,乱序等
软件调试类  strace/dtruss: 系统调用跟踪工具 ltrace：查询库调用  $ strace -p &amp;lt;pid&amp;gt; -c-p 指定进程ID-c 汇总输出辅助类  pv : 管道进度监控  # 相当于cat# 监控某进程文件pv -d &amp;lt;pid&amp;gt;# 管道命名pv -cN gzip扩展阅读  如何用curl做API接口测试 Linux 工具快速教程 ss命令详解 traceroute解释1/2 </content>
    </entry>
    
     <entry>
        <title>Redis</title>
        <url>https://xulizhao.com/blog/redis/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 最流行的内存数据库,Redis可以理解为Remote Dictionary Service.
基本配置 # 默认端口 6379# 配置文件 /etc/redis/redis.confbind 0.0.0.0 # 运行远程访问,开发环境 redis-cli # 常用命令ping # 检查连通性-h &amp;lt;host&amp;gt; -p &amp;lt;port&amp;gt;shutdownflushall 清数据库INFOSLAVEOF NO ONE / hostname portCONFIG SET protected-mode no 集群/高可用 Redis Cluster 提供自动分片(sharding)和部分高可用
可用性：只要集群中大多数master可达、且失效的master至少有一个slave可达时，集群都可以继续提供服务
# 两种安装方式# Ruby脚本方式yum install ruby -yyum install rubygemsgem install redis # 自带脚本cd utils/create-cluster/# 编辑create-cluster文件,更新35行 HOSTS=&amp;quot;$HOSTS &amp;lt;YOUR_SERVER_IP&amp;gt;:$PORT&amp;quot;./create-cluster start./create-cluster create# 停止/卸载./create-cluster stop./create-cluster clean## 密码认证config set masterauth p@ssw0rdconfig set requirepass p@ssw0rdconfig rewrite# 带参数 --masterauth p@ssw0rd --requirepass p@ssw0rd Redis Sentinel 提供高可用及以下功能:
  Monitoring
  通知
  自动故障转移Failover (Master -&amp;gt; Slave)
  配置提供者(为客户端提供唯一入口)
  优化 # 编辑/etc/sysctl.confnet.core.somaxconn=65535# 或及时生效sysctl -w net.core.somaxconn=65535 管理工具  RedisDesktopManager: GUI工具,提供Windows安装包 redsmin: 云端管理界面  资源  codis: 豌豆荚开源集群 </content>
    </entry>
    
     <entry>
        <title>MySQL</title>
        <url>https://xulizhao.com/blog/mysql/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag><tag>mysql</tag><tag>database</tag>
        </tags>
        <content type="html"> 最流行的开源关系型数据库,常用的MySQL版本为社区版或Percona版.
安装及配置 # 安全化安装sudo apt install mysql-serversudo mysql_secure_installation# 设置root密码, Percona/usr/bin/mysqladmin -u root password &amp;#39;new-password&amp;#39;# 配置文件/etc/mysql/my.cnf# CentOS/etc/sysconfig/mysql# Ubuntu/etc/default/mysql授权登录 GRANT ALL PRIVILEGES ON dbname.* TO &amp;#39;USERNAME&amp;#39;@&amp;#39;IP&amp;#39; IDENTIFIED BY &amp;#39;PASSWORD&amp;#39;;FLUSH PRIVILEGES; grant与on之间是各种权限，例如:insert,select,update等 on之后是数据库名和表名,第一个_表示所有的数据库，第二个_表示所有的表 ＠后可以跟域名或IP地址(%代表所有地址)，identified by后面的是登录用的密码，可以省略，即缺省密码或者叫空密码  常用命令 CREATE USER &amp;#39;newuser&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;password&amp;#39;;select current_user();-- 授予权限需要以 root@localhost 登录-- 创建数据库并授权CREATE DATABASE wordpress DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci;GRANT ALL ON wordpress.* TO &amp;#39;wordpressuser&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;password&amp;#39;;FLUSH PRIVILEGES;-- 创建相同结构CREATE TABLE new_table LIKE old_table; -- 同时复制数据INSERT INTO new_table SELECT * FROM old_table; -- 显示所有索引SHOW INDEX FROM yourtable;-- 字符集CREATE DATABASE IF NOT EXISTS `gitlabhq_production` DEFAULT CHARACTER SET `utf8` COLLATE `utf8_unicode_ci`;show variables like &amp;#34;character_set_database&amp;#34;;show variables like &amp;#34;collation_database&amp;#34;;信息查询 -- 显示基础信息mysql &amp;gt; status-- 查询各数据库大小SELECT table_schema &amp;#34;DB Name&amp;#34;, ROUND(SUM(data_length &#43; index_length) / 1024 / 1024, 1) &amp;#34;DB Size in MB&amp;#34;FROM information_schema.tables GROUP BY table_schema;-- 查询每个表的行数，注：对innodb这个是估算值SELECT table_name, table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = &amp;#39;your_db&amp;#39;;-- 查询每个表大小SELECT table_name AS `Table`, round(((data_length &#43; index_length) / 1024 / 1024), 2) `Size (MB)`FROM information_schema.TABLES WHERE table_schema = &amp;#34;your_db&amp;#34;;-- 所有用户信息select distinct concat(&amp;#39;user: &amp;#39;&amp;#39;&amp;#39;,user,&amp;#39;&amp;#39;&amp;#39;@&amp;#39;&amp;#39;&amp;#39;,host,&amp;#39;&amp;#39;&amp;#39;;&amp;#39;) as query from mysql.user;备份数据 # 备份数据mysqldump -d -uroot -p mydb &amp;gt;mydb_schema.sql--no-create-info, -t # 只包含数据--skip-triggers--no-data, -d # 备份多个数据库--databases db1 db2 &amp;gt; db12.sql# 备份全部数据库mysqldump -u xulz -p --all-databases &amp;gt; all_db.sql其他选项：
| gzip &amp;gt; database_name.sql.gz$(date &#43;%Y%m%d)执行脚本:
#!/bin/bashUSER=&amp;#34;xulz&amp;#34;PASSWORD=&amp;#34;&amp;#34;#OUTPUT=&amp;#34;/Users/xulz/DBs&amp;#34;#rm &amp;#34;$OUTPUTDIR/*gz&amp;#34; &amp;gt; /dev/null 2&amp;gt;&amp;amp;1databases=`mysql -u $USER -p$PASSWORD -e &amp;#34;SHOW DATABASES;&amp;#34; | tr -d &amp;#34;| &amp;#34; | grep -v Database`for db in $databases; doif [[ &amp;#34;$db&amp;#34; != &amp;#34;information_schema&amp;#34; ]] &amp;amp;&amp;amp; [[ &amp;#34;$db&amp;#34; != &amp;#34;performance_schema&amp;#34; ]] &amp;amp;&amp;amp; [[ &amp;#34;$db&amp;#34; != &amp;#34;mysql&amp;#34; ]] &amp;amp;&amp;amp; [[ &amp;#34;$db&amp;#34; != _* ]] ; thenecho &amp;#34;Dumping database: $db&amp;#34;mysqldump -u $USER -p$PASSWORD --databases $db &amp;gt; `date &#43;%Y%m%d`.$db.sql# gzip $OUTPUT/`date &#43;%Y%m%d`.$db.sqlfidone恢复数据 # 导入数据mysql -h host -u username -p password --default_character_set utf8 database &amp;lt; file.sqlmysqld database_name &amp;lt; file.sql# Load-data高速导入数据load data local infile /root/out.txt into table table1 fields terminated by &amp;#39;,’ (field1,field2)# 恢复全部数据库mysql -u xulz -pmysql&amp;gt; source all_db.sql# 或者mysql -u xulz -p &amp;lt; all_db.sql重置丢失的root密码 sudo mysqld_safe --skip-grant-tables &amp;amp;mysql -u rootuse mysql;update user set password=PASSWORD(&amp;#34;newpass&amp;#34;) where User=&amp;#39;root&amp;#39;;flush privileges;mysql-python的使用  mysql-python 需要的mysql_config 包含在 libmysqlclient-dev 或 libmysqld-dev sudo apt-get install mysql-server mysql-client libmysqlclient-dev
 性能 慢查询 -- 配置show variables like &amp;#39;%slow_query%&amp;#39;;SET GLOBAL log_output = &amp;#39;FILE,TABLE&amp;#39;;select * from mysql.slow_log;-- 或者mysql&amp;gt; SET GLOBAL slow_query_log = &amp;#39;ON&amp;#39;;mysql&amp;gt; SET GLOBAL slow_query_log_file = &amp;#39;/var/log/mysql/localhost-slow.log&amp;#39;;mysql&amp;gt; SET GLOBAL log_queries_not_using_indexes = &amp;#39;ON&amp;#39;;mysql&amp;gt; SET SESSION long_query_time = 1; -- 配置文件: long_query_time = 1mysql&amp;gt; SET SESSION min_examined_row_limit = 100;工具  自带工具: mysqldumpslow -t 5 -s at /var/log/mysql/localhost-slow.log 第三方：pt-query-digest  其他命令 select @@global.max_connections;show variables like ‘max_connections’;SELECT * FROM information_schema.STATISTICS WHERE TABLE_SCHEMA = DATABASE()集群及高可用 Percona XtraDB Cluster 推荐至少3节点,每个节点包含全部数据的复制.主要作为读操作的扩展方案,写操作不会成倍scale.实现基于单实例并加入了写复制(同步).限制:复制只支持InnoDB存储引擎, 系统表复制只支持DDL.写吞吐量由最差的节点决定.不支持Lock查询 用Connector/J实现负载均衡 Failover协议是“Multi-Host”链接模式中最基础的协议，“load balancing”、“replication”、“farbic”协议都基于Failover协议。 中间件 实现透明访问分布式数据库集群中的各个分库分表
 ProxySQL : High-performance MySQL proxy kingshard  一些工具  vitess: 工具集,youtube在用 orchestrator: MySQL replication topology management and HA mysql_utils:Pinterest MySQL Management Tools  资源  MySQL Yum Repository Percona Server for MySQL </content>
    </entry>
    
     <entry>
        <title>PostgreSQL</title>
        <url>https://xulizhao.com/blog/postgresql/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html"> PostgreSQL是2017年流行度上升最快的数据库.
 吐槽:官方的管理工具pgAdmin真难用啊, 命令也没有MySQL易记.
   安装 参考官方文档即可.
 CentOS Ubuntu  # CentOS例子yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm# clientyum install postgresql96# serveryum install postgresql96-server# init and auto start/usr/pgsql-9.6/bin/postgresql96-setup initdbsystemctl enable postgresql-9.6systemctl start postgresql-9.6配置  端口: 5432 默认用户: postgres 配置默认目录: /var/lib/pgsql/  postgresql.conf
# 默认localhost,如果需要远程访问修改为*listen_addresses = &amp;#39;*&amp;#39;pg_hba.conf控制认证方式
 默认认证方式: ident,以当前登录的系统用户为数据库用户名连接 密码认证: md5 无密码: trust 使用Linux系统账号: peer(仅限于本地连接)  # 开放远程访问# TYPE DATABASE USER ADDRESS METHODhost all all 192.168.100.1/24 md5注: hba 代表 host-based authentication.
Ubuntu配置
配置文件位置： /etc/postgresql/10/main/pg_hba.conf
CentOS配置
通常位于类似路径： /var/lib/pgsql/9.6/data/
常用命令 # 连接服务器psql -h hostname database user# 创建数据库sudo -u postgres createuser xulz -ssudo -u postgres createdb mydb&amp;gt; createuser-E --encrypted (store password)-s --superuser-P --pwprompt&amp;gt; createdb&amp;gt; dropdb -W -U postgres -h localhost your_db_namePSQL:
-- 连接 sudo -u postgres psql-- 创建用户 CREATE USER xulz WITH PASSWORD &amp;#39;password&amp;#39;;-- 更改密码 ALTER USER &amp;#34;user_name&amp;#34; WITH PASSWORD &amp;#39;new_password&amp;#39;;-- 修改postgres密码 alter user postgres password &amp;#39;postgres&amp;#39;; #或者　\password postgres-- 用户授权 grant all privileges on database db1 to user1;-- 重命名数据库 ALTER DATABASE people RENAME TO &amp;#34;customers&amp;#34;;PSQL Command:
\dt list tables\du list users\password user_name\dn list schemas\l list database\? \c[onnect] {[DBNAME|- USER|- HOST|- PORT|-] | conninfo} #Connection 关闭所有session连接 SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = &amp;#39;dbname&amp;#39;AND pid &amp;lt;&amp;gt; pg_backend_pid();-- 避免关闭当前连接REVOKE CONNECT ON DATABASE dbname FROM PUBLIC, username; -- Revoke CONNECT权限以避免创建新连接备份和还原 这里主要指逻辑备份（而不是物理备份）。
pg_dump的几个主要选项：
-U, --username=NAME connect as specified database user -F, --format=c|t|p output file format (custom, tar, plain text) -f, --file=FILENAME output file nameSQL格式文件备份 ## 备份pg_dump dbname -f db_bak.sql# 或者pg_dump -Fp dbname &amp;gt; db_bak.sql## psql命令还原psql -U username -f db_bak.sql dbname # 或者直接在psql终端还原postgres=# \i db_bak.sql自定义格式和tar格式备份 pg_dump -Fc dbname -f filename # 还原pg_restore -Fc -d dbname filename# tar格式与此类似，-Ft注： pg_dumpall 用于集群级别备份，使用psql命令还原。
从数据库删除所有表 -- —clean 清除数据库pg_dump -U postgres -h localhost -p 5432 --clean --file=sandbox.sql sandboxpg_dumpall -U postgres -h localhost -p 5432 --clean --globals-only --file=globals.sqlpsql -W -U postgres -h localhost your_db_name &amp;lt; backup.sqldrop schema public cascade;create schema public;方式二：
DO $$ DECLAREr RECORD;BEGIN-- 注意替换current_schema为要删除的schemaFOR r IN (SELECT tablename FROM pg_tables WHERE schemaname = current_schema()) LOOPEXECUTE &amp;#39;DROP TABLE IF EXISTS &amp;#39; || quote_ident(r.tablename) || &amp;#39;CASCADE&amp;#39;;END LOOP;END $$性能 关注几个方面:
 索引使用 IO尽量使用缓存: cache hit ratio = blks_hit /(blks_hit&#43;blks_read) 并发连接 避免死锁 长时间查询  主要参数调优 参考 官方wiki 或Performance Tuning PostgreSQL
## postgres.conf# 通常设置为几百连接max_connections = &amp;lt;num&amp;gt;# 1/4 ~ 1/3内存shared_buffers = &amp;lt;num&amp;gt;Explain  Explain SQL STATEMENT  cost 建议控制在300 以内 重点关注缺少索引的大表   EXPLAIN ANALYZE 检查规划器预估值的准确性  Startup Cost Max Time Rows    监控性能数据   内部使用 pg_stats
  监控用途
 数据库: pg_stat_database 表: pg_stat_all_tables tup : rows 查询 : pg_stat_statements 需要先enable plugin  编辑postgres.conf
shared_preload_libraries = &amp;#39;pg_stat_statements&amp;#39;pg_stat_statements.track = all  表监控
SELECT sum(idx_scan)/(sum(idx_scan) &#43; sum(seq_scan)) as idx_scan_ratioFROM pg_stat_all_tablesWHERE schemaname=‘public&amp;#39;;SELECT relname,idx_scan::float/(idx_scan&#43;seq_scan&#43;1) as idx_scan_ratioFROM pg_stat_all_tablesWHERE schemaname=&amp;#39;public&amp;#39;ORDER BY idx_scan_ratio ASC;Troubleshooting  死锁问题检查  SELECT * FROM pg_stat_activity WHERE datname = &amp;#39;deadlock database ID’;-- 找到waiting字段, procpid找到对应的列值SELECT pg_cancel_backend (&amp;#39;死锁的procpid值&amp;#39;);在Mac下使用pip安装psycopg2时报错:&amp;ldquo;pg_config executable not found&amp;rdquo;  解决: export PATH=$PATH:/Applications/Postgres.app/Contents/Versions/9.6/bin
与MySQL比较  更完整的事务支持 更快的列添加 更好的多核CPU支持  资源  [查看表/对象大小][1] [What PostgreSQL Tells You About Its Performance][2] [pgAdmin][3] How To Install and Use PostgreSQL on Ubuntu 18.04 [1]: https://wiki-bsse.ethz.ch/display/ITDOC/Check&#43;size&#43;of&#43;tables&#43;and&#43;objects&#43;in&#43;PostgreSQL&#43;database [2]: http://okigiveup.net/what-postgresql-tells-you-about-its-performance/ [3]: http://www.pgadmin.org/ </content>
    </entry>
    
     <entry>
        <title>Linux防火墙</title>
        <url>https://xulizhao.com/blog/linux-firewall/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> CentOS作为一个开发环境用还是有些繁琐了,今天因为忘了iptables防火墙默认开启,还浪费了些时间找原因.
更郁闷的是用lokkit这个工具新开通一个端口,几分钟之后之前的防火墙设置全没了.
Docker啊,赶紧给团队统一起来吧,折腾环境太无聊了.
防火墙概要 iptables  iptables是存放防火墙规则的数据库
 # 检查当前状态iptables -nvL # 或者 service iptables status# 关闭防火墙,在非生产环境service iptables saveservice iptables stopchkconfig iptables off# 开启防火墙service iptables startchkconfig iptables onlokkit CentOS简化命令行工具
# 允许某端口lokkit -p 3389:tcp ufw Ubuntu简化工具: Uncomplicated Firewall
sudo ufw allow ssh/tcpsudo ufw allow 3389/tcp# 常用命令sudo ufw logging onsudo ufw enable/disablesudo ufw status其他工具  fail2ban: python工具,根据正则匹配日志错误并触发iptables动作  GUI工具
 Gufw FirewallBuilder: 强大而复杂  iptables详解 iptables使用表结构管理防火墙规则, 底层实际上调用Linux内核的netfilter框架.
几种表类型:
 Filter: 防火墙过滤 NAT: 地址转换 Mangle: 改变数据包IP头信息或增加标记 Raw: 用于连接追踪,保持连接会话关系/状态 Security: SELinux相关  常用命令 # 列出所有规则-S # 删除所有规则-F --flush# 清除计数-Z --zero-L --list-A # 添加一条规则-I #在指定位置插入一条规则,默认chain的第一条# 显示行号--line-numbers -m --match-p --protocol-i --in-interface常用规则 # 允许本地连接iptables -A INPUT -i lo -j ACCEPT# 开启常用服务端口iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT# 或者iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT# 允许在server发起建立的outgoing连接上返回数据.iptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT# 其他# 查询对外IPw# 之后可以限定来源IPiptables -A INPUT -p tcp -s YOUR_IP_ADDRESS -m tcp --dport 22 -j ACCEPT# 允许所有outgoingiptables -P OUTPUT ACCEPT# 拒绝其他incomingiptables -P INPUT DROP# 多个端口iptables -A INPUT -p tcp -m multiport --dport 80,443 -j ACCEPT规则的保存/备份/恢复 注: 用命令配置重启后会失去作用,需要先保存并重启防火墙服务
#保存规则# Ubuntuapt-get install iptables-persistentnetfilter-persistent save# CentOSservice iptables save# 默认保存到 /etc/sysconfig/iptables# 等价于 iptables-save | sudo tee /etc/sysconfig/iptables# CentOS7有可能会开启firewalld, 检查firewalld 运行状态firewall-cmd --state# 导出规则iptables-save &amp;gt; iptables-export#恢复规则iptables-restore &amp;lt; ~/iptables-export规则使用说明 Chain是一组规则的集合,默认内置有几个Chain,包含INPUT,FORWARD,OUTPUT.
每个Chain有一个默认的policy, ACCEPT/DROP/REJECT
用户可以自定义新的Chain(必须通过jump到达),比如Docker启动容器时会默认创建几个.
Chain可以理解为有顺序的一系列规则,由上到下挨个匹配,没有匹配则使用默认策略.
规则构成:
 INPUT: 系统接收的数据包,打开/关闭(进口/incoming)端口/地址 OUTPUT: 系统发出的数据包,打开/关闭(出口/outgoing)端口/地址 FORWARD:通常用于路由转发,如LAN到互联网  包/packet 匹配规则:
 每个包以第一条规则开始 继续处理包直到匹配到一条规则 如果找到匹配,控制跳转到指定目标  目标/target : 指规则匹配时采取的行动.
 ACCEPT : 允许 REJECT : 丢掉包,通知错误消息给远程主机(connection refused) DROP : 丢掉包,不发错误通知  较少用到的:
 RETURN : 通常用于自定义Chain NOTRACK: 不做连接追踪  连接追踪 iptables也可以track connection/state(new,established,related).
可用状态:
 NEW ESTABLISHED RELATED: 与被标记为RELATED的连接关联,如FTP,ICMP INVALID UNTRACKED SNAT/DNAT: 原/目的地址已被转换  资源/参考  Set Up a Basic Iptables Firewall Deep Dive into Iptables Using FirewallD on CentOS 7 </content>
    </entry>
    
     <entry>
        <title>Tomcat</title>
        <url>https://xulizhao.com/blog/tomcat/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>ops</tag>
        </tags>
        <content type="html"> Tomcat是最常用的Java部署容器，在我最初接触Java时就是主流，特点就是稳定.
与之类似还有个Jetty，用的不多就不涉及了.
安装 Ubuntu 安装:
apt install tomcat8 tomcat8-admin tomcat8-docs tomcat8-examples# 常用路径/etc/tomcat8/server.xml/etc/default/tomcat8/var/lib/tomcat8/webapps/ROOT/index.html服務：
# /etc/systemd/system/tomcat.service[Unit]Description=Apache Tomcat Web Application ContainerAfter=network.target[Service]Type=forkingEnvironment=JAVA_HOME=/usr/java/defaultEnvironment=CATALINA_PID=/opt/tomcat/temp/tomcat.pidEnvironment=CATALINA_HOME=/opt/tomcatEnvironment=CATALINA_BASE=/opt/tomcatEnvironment=&amp;#39;CATALINA_OPTS=-Xms512M -Xmx1024M -server -XX:&#43;UseParallelGC&amp;#39;Environment=&amp;#39;JAVA_OPTS=-Djava.awt.headless=true -Djava.security.egd=file:/dev/./urandom&amp;#39;ExecStart=/opt/tomcat/bin/startup.shExecStop=/opt/tomcat/bin/shutdown.shUser=tomcatGroup=tomcatUMask=0007RestartSec=10Restart=always[Install]WantedBy=multi-user.targetCentOS 安装:
groupadd tomcatuseradd -s /bin/false -g tomcat -d /opt/tomcat tomcatcd /opt/wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.43/bin/apache-tomcat-8.5.43.tar.gzsudo tar xvf apache-tomcat-8*tar.gz -C /opt/tomcat --strip-components=1chown -hR tomcat:tomcat tomcat服务：
# vi /etc/systemd/system/tomcat.service# Systemd unit file for tomcat[Unit]Description=Apache Tomcat Web Application ContainerAfter=syslog.target network.target[Service]Type=forkingEnvironment=JAVA_HOME=/usr/java/defaultEnvironment=CATALINA_PID=/opt/tomcat/temp/tomcat.pidEnvironment=CATALINA_HOME=/opt/tomcatEnvironment=CATALINA_BASE=/opt/tomcatEnvironment=&amp;#39;CATALINA_OPTS=-Xms512M -Xmx2048M -server&amp;#39;ExecStart=/opt/tomcat/bin/startup.shExecStop=/bin/kill -15 $MAINPID#User=tomcat#Group=tomcat#UMask=0007RestartSec=10Restart=always[Install]WantedBy=multi-user.target服务管理：
# 加载服务systemctl daemon-reload# 启动systemctl start tomcat# 开机启动systemctl enable tomcat配置 常用配置 以最常用的HTTP Connector为例, 最关键的几个参数是：
 maxThreads ： 能同时处理的请求数, 默认200有些偏小。 acceptCount ： 请求队列最大值,处理不过来就放到这个队列,队列满之后会拒绝请求. 默认100有些偏小. maxConnections ： 服务器接受并处理的最大连接数,超出后新连接会被阻塞.对于BIO连接器默认=maxThreads, NIO连接器默认10000.   Connector的实现主要是BIO,NIO,NIO2 其中BIO是大多数版本的默认实现，但是在最新版Tomcat8.5，已经不再支持BIO
 开启HTTPS 关于SSL/TLS,建议使用Nginx反向代理配置而不使用Tomcat.
Tomcat开启TLS后,性能会有所下降(CPU占用更高).官方推荐使用APR,而不使用BIO或NIO(使用Java内置的安全组件JSSE)。
 APR(Apache Portable Runtime)是Tomcat的Native Library，实现网络连接和随机数生成器.主要特点:
 支持Keep-Alive请求的非阻塞I/O 使用OpenSSL 版本的TLS/SSL   关于参数调优 建议使用setenv.sh的方式调整参数，比如记录GC日志
JAVA_OPTS=&amp;#34;-Xmx6g-XX:&#43;PrintGC-XX:&#43;PrintGCDetails-XX:&#43;PrintHeapAtGC-Xloggc:/usr/local/tomcat/logs/gc.log-XX:&#43;HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/tomcat/logs/&amp;#34;开启远程监控JMX CATALINA_OPTS=&amp;#34;-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.port=1616-Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=false-Djava.rmi.server.hostname=10.120.1.99&amp;#34;开启目录列表 default servlet 负责处理静态资源和目录列表
&amp;lt;init-param&amp;gt;&amp;lt;param-name&amp;gt;listings&amp;lt;/param-name&amp;gt;&amp;lt;param-value&amp;gt;true&amp;lt;/param-value&amp;gt;&amp;lt;/init-param&amp;gt;压缩日志 # vi /etc/logrotate.d/tomcat/usr/local/tomcat/logs/catalina.out {copytruncatedailyrotate 5dateextcompressmissingoksize 1024M}调试：
 logrotate -d -f /etc/logrotate.d/tomcat
   -d = 开启调试模式 -f = 强制循环日志   其他 # 查看运行时参数ps aux | grep catalina # 或者jinfo# 调试debugset -x# 使用pidCATALINA_PID=&amp;#34;$CATALINA_BASE/bin/catalina.pid&amp;#34; AJP( Apache JServ Protocol)的特点是作为Web Server(Apache)和Servlet Container(Tomcat/JBoss)之间的反向代理, 使用二进制协议传输,没有解析开销.
 资源链接  Tocmat7 HTTP Connector Choosing Tomcat Connectors @2014 PPT Jetty How to rotate the Tomcat catalina log file </content>
    </entry>
    
     <entry>
        <title>Wireshark网络分析工具</title>
        <url>https://xulizhao.com/blog/wireshark/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>networking</tag>
        </tags>
        <content type="html"> Wireshark基础 过滤的用法 需要区分两种过滤语言
Capture Filter: Berkley Packet Filter  示例: host xulizhao.com and port 443
 Display Filter 常用过滤器
# 地址/端口ip.addr == 10.0.0.1ip.src ==ip.src_host ==tcp.port==4000tcp.port == 8080 and ip.addr==127.0.0.1# HTTPhttphttp.request # 显示所有GET请求# 其他# 显示所有 TCP resetstcp.flags.reset==1 # 显示所有retransmissionstcp.analysis.retransmission tcp.analysis.lost_segmenttcp.analysis.ack_lost_segment# 显示包含关键字 traffic 的包tcp contains traffic frame contains ... 配置 如果SSL端口不是默认的443端口,需要修改配置项以显示TLS/SSL协议抓包:
位于 Edit -&amp;gt; Preferences -&amp;gt; Protocols -&amp;gt; HTTP -&amp;gt; SSL/TLS Ports,把值修改为 443,8443
知识点  Wireshark的时间戳存在偏差,非标准时间 每个包在Info存在唯一标识 DUP ACK/TCP Retransmission 是正常的 协议  802.11即以太网,在frames Internet Protocol/IP: 包含在每个以太frame,在packets Transmission Control Protocol/TCP: 包在每个IP packet,在segments Transport Layer Security/TLS: 通过TCP字节流,在records/messages Hypertext Transfer Protocol/HTTP: 在加密的TLS连接中携带,一般不可见   名词解释  TCP Spurious Retransmission: 发送方重传了接收方已确认的数据, 通常因为发送方认为该数据包丢失而重发. TCP post number reused: 可能意味网络存在重复包.    编辑/合并文件 editcap -c 10000 in.pcap out.pcapeditcap -A &amp;quot;2017-05-11 12:00:00&amp;quot; -B &amp;quot;2017-05-11 13:00:00&amp;quot; in.pcap out.pcapmergecap out.pcap in1.pcap in2.pcap 高级用法 解密SSL抓包  使用服务端私钥：  Edit → Preferences - Protocols → TLS; RSA keys list： 需要从服务器导出证书,不支持DHE加密算法 （填写 &amp;ldquo;any&amp;rdquo; 应用到所有IP地址） 可在ServerHello中搜索是否包含EDH或EECDH，以确定密钥交换算法   SSLKEYLOGFILE: 只支持Chrome、Firefox,但支持DHE  注： DHE算法符合完全正向保密协议/perfect forward secrecy，中间人即使得到私钥也破解不了密文。
流程图 [Statistics]-[Flow Graph]
相关工具 tcpdump  sudo tcpdump -n -s 4096 -w l.log port 80
 常用选项:
 -n: 不做地址和端口的数字/名称转换 -i: 捕获的网卡名 -w: 把原始包写到文件, 而不是解析并打印(默认行为). 可以用-r选项再次打印  tcpflow tcpflow, 轻量级网络包分析
扩展阅读  TLS的Wireshark例子 tcpdump命令详解 如何通过Wireshark查看HTTPS、HTTP/2网络包  </content>
    </entry>
    
     <entry>
        <title>网络分析工具</title>
        <url>https://xulizhao.com/blog/network-tools/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>networking</tag>
        </tags>
        <content type="html"> 这里的网络分析工具可以归为两大类:
  网络代理: 用的最多的是 Fiddler
  分析工具: 比较熟悉的是Wireshark
  代理类 Fiddler 以Android客户端抓包为例,主要步骤为:
 [Tools]-[Options], 检查Connections和HTTPS选项,开启代理模式 安卓浏览器访问 &amp;lt;YOUR_IP&amp;gt;:8888, 下载并安装根证书 设置安卓WIFI代理为以上地址和端口  Charles (付费)  默认端口8888 [Proxy]-[SSL Proxy Settings]-[SSL Proxying],添加location。 访问 [Help]-[SSL Proxying]-[Install Charles Root Certificate on a Mobile Device or Remote Browser]，找到代理地址和端口。  注: 如果response中文显示乱码，需要确保本地已安装证书。[Help]-[SSL Proxying]-[Install Charles Root Certificate]即可。
限制： 从Android 7开始，需要修改app配置信任用户证书，才能显示HTTPS内容。
如果targets API为24&#43;或应用使用了certificate pinning(使用okhttp等)，也可能不工作。
步骤如下：
在应用工程添加文件 res/xml/network_security_config.xml:
&amp;lt;network-security-config&amp;gt; &amp;lt;debug-overrides&amp;gt; &amp;lt;trust-anchors&amp;gt; &amp;lt;!--Trust user added CAs while debuggable only --&amp;gt;&amp;lt;certificates src=&amp;#34;user&amp;#34; /&amp;gt; &amp;lt;/trust-anchors&amp;gt; &amp;lt;/debug-overrides&amp;gt; &amp;lt;/network-security-config&amp;gt;然后添加到应用的manifest文件:
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;&amp;lt;manifest&amp;gt;&amp;lt;application android:networkSecurityConfig=&amp;#34;@xml/network_security_config&amp;#34; &amp;gt;...&amp;lt;/application&amp;gt;&amp;lt;/manifest&amp;gt;Burp Suite 默认端口8080
mitmproxy Python写的开源调试工具, 解析/修改/重放/保存。
mitmproxy -b PORT -w outfilemitmdump -w outfile# -n 不绑定代理端口# 过滤所有POSTmitmdump -nr outfile -w outfile2 &amp;#34;-m post&amp;#34;# 客户端重放, -c filenamemitmdump -nc outfileAndroid全局抓包分析(HTTP/HTTPS&#43;TCP) 最近遇到的问题是，App也使用了TCP协议，如果使用Fiddler这类HTTP代理工具会造成应用使用问题。
所以要同时抓取HTTP/HTTPS和TCP数据，安卓自带的WiFi代理便局限了。
抓包方案有2个：
Android机已ROOTED 手机端安装tcpdump，因为安卓本身就是基于*Nix的嘛，在电脑用Wireshark抓包。
其实就是一条命令：
adb exec-out &amp;quot;tcpdump -i any -U -w - 2&amp;gt;/dev/null&amp;quot; | wireshark -k -S -i - 电脑建立WiFi热点 由于是公司的手机，不能随便ROOT。思路是通过电脑的无线网络建立一个代理WiFi热点。
在Windows7/10都可以，如果是台式机，需要自备无线网卡。
# 确定 Hosted network supported/支持的承载网络为 Yes/是netsh wlan show drivers# 建立虚拟WiFinetsh wlan set hostednetwork mode=allow ssid=testWiFi key=password# 设置网络连接共享: 右键点击正在使用的以太网络连接，[属性]-[共享]标签-勾选 [Internet共享连接]并从下拉列表选择刚创建的网络。# Windows10位置：[Windows Settings]-[Network&amp;amp;Internet]-[Change Adapter Options]#开启无线APnetsh wlan start hostednetwork 资源 链接  Fiddler Charles SSL Certificates mitmproxy tcpflow  扩展阅读  fiddler安卓配置图文教程 fiddler各图标的意思 TLS的Wireshark例子 tcpdump命令详解 Android抓包方法(三) Android 抓包实践总结 Charles 从入门到精通 Burp Suite 抓包 </content>
    </entry>
    
     <entry>
        <title>聊聊监控系统</title>
        <url>https://xulizhao.com/blog/monitoring/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html"> 2017很快就要过去了,也顺便整理下散落在印象笔记的一些片段.
监控系统本来是运维的一个重要组成,因为工作需要也接触了一些开源的监控系统, 下面简要的聊聊我所知道的.
接触监控系统历史 开始接触监控系统是在之前公司时通过运维的Nagios访问一些数据,这个古老的系统之前有很高的占有率, 能很好的提供系统级检测和告警, 感觉界面易用性差些.后来偶然看到Cacti这个网络监控的界面,感觉清爽了许多.
第一个用起来的Munin也是同样基于RRDTool的,当时起码能满足系统和Java应用的性能监控需求.
之后了解到新浪在用Zabbix这个大而全的方案,而且提供了不少扩展. 我对这个复杂的系统有些抵触,并没有使用.
因为最熟悉Python, 也有试用过Graphite,感觉部署和配置都稍显复杂.
近两年随着大数据和时序数据库的火热, 在2016年中开始使用 InfluxDB和Grafana这对组合, 总体功能强大而灵活.
在国内,小米开源的Open-Falcon也有较多应用,我的项目太小暂时用不到:)
总的来说,最近几年的趋势是监控系统用Go开发,一般由专门的时序数据库存储数据.
监控系统组成 监控系统一般由两部分构成:
 度量数据收集和可视化 收集尽可能多的性能和状态数据 图形化做有意义的展示 如果发现可疑问题,可以关联其他图表找到原因 错误检测 按需告警, 触发条件越宽松则告警应该越少 避免误报  从监控的层次划分的话,一般包含三层监控:
 基础层: 主机的CPU,内存,网络及IO等 中间层: 应用运行的中间件层,Nginx,Tomcat,MySQL,Redis 应用层: 服务端及客户端性能数据,如API访问次数和响应时间等  现代的监控越来越关注应用层和其他层数据的整合能力,具有快速找到系统瓶颈,方便扩容或代码优化.
Java应用的监控  Tomcat大部分通过插件形式监控 Jolokia: Remote JMX with JSON over HTTP Servo : Netflix的一个Java库,JMX的方式 jmxtrans: 也是通过JMX的方式  jolokia jolokia agent 默认使用8778端口.
# 下载agentwget -O jolokia-jvm-1.6.2-agent.jar https://search.maven.org/remotecontent?filepath=org/jolokia/jolokia-jvm/1.6.2/jolokia-jvm-1.6.2-agent.jar# 监控已有java进程java -jar jolokia-jvm-1.6.2-agent.jar start 10110 # 验证是否成功curl http://127.0.0.1:8778/jolokia/其他方案  StatsD: 这已经成为事实上的通用协议,聚合功能很强大. 作为插件配合telegraf工作 bosun : StackExchnage出品,侧重于告警 Cabot NetData: 轻量级极简监控 monit: 轻量级监控  资源链接 Prometheus : SoundCloud开源的Graphite的替代品/ Prometheus与其他系统比较 Open-Falcon Graphite Sensu Zabbix RRDtool / Cacti / Munin Nagios 大家族  Nagios / 扩展 nagios-herald 客户端AgentNSClient&#43;&#43; 分支/继任Icinga 2   </content>
    </entry>
    
     <entry>
        <title>Grafana指标展示仪表盘</title>
        <url>https://xulizhao.com/blog/grafana/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>data</tag><tag>ops</tag>
        </tags>
        <content type="html"> Grafana本身已经足够成熟，也有了广泛的应用。
从聊聊监控系统独立出Grafana。
安装及启动 # 启动服务systemctl start grafana-server# 默认地址 http://127.0.0.1:3000/# 默认用户名/密码:admin/admin# 配置文件 /etc/grafana/grafana.ini# 开机启动systemctl enable grafana-server.service升级 grafana的跨大版本升级基本也没有问题。
 需要先备份数据库，默认在 /var/lib/grafana/grafana.db
 wget https://dl.grafana.com/oss/release/grafana_6.5.2_amd64.debsudo apt-get install -y adduser libfontconfig1sudo dpkg -i grafana_6.3.4_amd64.debgrafana-cli plugins update-allsudo service grafana-server restart扩展阅读  Grafana官方 官方文档 升级文档  Dashboard  Percona的数据库Dashboards grafanalib: Python library for building Grafana dashboards Hosts Overview: 2864 JVM Metrics - Jolokia 2: 8991 Apache JMeter Dashboard Using-Core-InfluxDBBackendListenerClient </content>
    </entry>
    
     <entry>
        <title>InfluxDB时序数据库</title>
        <url>https://xulizhao.com/blog/influxdb/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>data</tag><tag>ops</tag>
        </tags>
        <content type="html"> InfluxData提供的开源方案
开源的几个产品简称TICK. 相对于付费的企业版/云版少了集群和高可用等支持.
我主要使用的Telegraf和InfluxDB, 后两者感觉易用性太差.
展示这部分使用Grafana替代,它自带基本的告警.
 Telegraf : 性能数据的收集,插件支持丰富 InfluxDB: 核心的时序数据库,负责存储 Chronograf : 前端图形化展示 Kapacitor: 流数据处理,异常检测并触发报警  Telegraf备忘 # 安装# Ubuntuwget https://dl.influxdata.com/telegraf/releases/telegraf_1.11.5-1_amd64.debsudo dpkg -i telegraf_1.11.5-1_amd64.deb# CentOSwget https://dl.influxdata.com/telegraf/releases/telegraf-1.11.5-1.x86_64.rpmsudo yum localinstall telegraf-1.11.5-1.x86_64.rpm# 常用插件 procstat/ netstat/ jolokia/ postgres/ statsd# 测试配置telegraf -config /etc/telegraf/telegraf.conf -input-filter processes -test# 启动服务sudo service telegraf startInfluxDB备忘 几个概念:
 measurement : 概念上对应SQL表,主索引是时间戳 tags : 对应表列,有索引 fields : 对应表列,无索引  # 查看日志sudo journalctl -u influxdb.service# 命令行工具influx## 性能提高# 走UDP协议# insert走批量接口# 如果内存够大,增加 LRU大小InfluxQL 类SQL查询
show databases;use udp;SHOW MEASUREMENTSLIST SERIES# 查询select * from mem where host=&amp;#39;moon&amp;#39;select \* from /.\*/ order by time desc limit 3SHOW TAG VALUES FROM &amp;#34;mem&amp;#34; WITH KEY = &amp;#34;host&amp;#34;# 删除drop measurement memdelete from com\_load\_avg_one where time &amp;lt; now() -1h# 时间查询, 格式now() 或者2016-11-01 HH:MM:SS# 注: 操作符和时间之间需要 空格; 时间串需要使用 单引号 &amp;#34;; 如果不指定时间,默认为 00:00:00# 正则匹配, 支持 measurements 和 tags/.\*abc.\* / # 包含字符串/^abc/ # 以指定字符串为开头/[ab]/ #包含 a 或 b# WHERE子语句, =~ 匹配, !~ 不匹配学习资源  InfluxDB </content>
    </entry>
    
     <entry>
        <title>微服务</title>
        <url>https://xulizhao.com/blog/microservices/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>cloud</tag><tag>architecture</tag>
        </tags>
        <content type="html"> 微服务是最近两年流行起来的一种架构设计方法,可以很好的和Docker,Kubernetes结合起来.
从最早的&amp;quot;单体应用&amp;quot;到&amp;quot;SOA(面向服务的架构)&amp;ldquo;再到&amp;quot;微服务架构&amp;rdquo;,这些新东西都是大公司搞出来的最佳实践.
软件界的真理是没有银弹,所以如果要上微服务,你就得在部署,测试和监控等其他地方做的更好(自动化),否则系统的复杂度伴随分布式系统反而上升了,得不偿失.
 不得不说ThoughtWorks搞敏捷,微服务这些新概念真的很六,但是中小公司得沉住气,晚点上车
 下面记录之前的一些整理.
什么是微服务 这里必须提到大神Martin Flower早在2014年的这篇文章.大致为:
 服务组件化  组件: 可以独立更换和升级的单元 服务件HTTP通讯   按业务组织团队  全栈的要求   做产品的态度(而非项目)  持续关注并提升   智能终端和哑管道: 粗粒度通讯(非RPC)  HTTP Rest 轻量级消息 强调性能用二进制   去中心化治理  技术选型独立   去中心话数据管理/存储  每个服务管理自己的数据库 数据一致性保证  服务件&#39;无事务&#39;调用 保证最终一致性     基础设施(运维)自动化  持续交付  自动化测试 自动化部署     容错设计  快速检测故障并自动恢复  监控和日志  服务状态,断路由状态,吞吐量,延迟       演进式设计  单体monolith 到 (部分)微服务    微服务网络 Service Mesh
十二要素应用宣言  这个宣言是Heroku发布的构建SaaS(软件即服务)应用的方法论。虽然和微服务不直接相关,也适合作为参考。
   使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入项目； 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性； 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源； 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发； 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展；   这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。
 基准代码:一份基准代码,多份部署 依赖:显式声明依赖关系 配置: 推荐将应用的配置存储于环境变量 后端服务: 将后端服务当作附加资源 构建,发布,运行: 严格区分三个步骤 进程:以一个或多个无状态进程运行应用 端口绑定 并发 易处理: 快速启动和优雅终止可最大化健壮性 开发环境和线上环境等价 日志 管理进程  概念  循证架构:架构基于实践的证据、来自历史项目或亲自试验的经验(适合应用需求的架构), By Rod Johnson. ESB: 企业服务总线, SOA的组成部分. OSGi: Open Service Gateway Initiative, Java模块化技术,慎用.  资源  &amp;lt;微服务设计&amp;gt; by Sam Newman &amp;lt;微服务：从设计到部署&amp;gt;在线阅读 Chris Richardson 微服务系列 十二要素 设计一个容错的微服务架构 </content>
    </entry>
    
     <entry>
        <title>利器之ZSH</title>
        <url>https://xulizhao.com/blog/zsh/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 有些工具真的很能提高效率, 比如oh-my-zsh这个扩展(zsh本身比bash更强大).
纵观软件世界,一个软件系统能流行起来很大原因是其生态是不是够丰富和繁荣,比如容器docker,Spring框架.
oh-my-zsh提供了丰富的插件及主题,是我的装机必备. 在这里记录下常用设置.
安装及扩展 安装zsh和on-my-zsh sudo apt install zshsh -c &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&amp;quot; 安装插件 # Ubuntusudo apt install zsh-syntax-highlighting autojump# Mac brew install zsh-syntax-highlighting autojump 安装插件管理工具 antigen
https://github.com/zsh-users/antigen# Ubuntusudo apt-get install zsh-antigen# Mac brew install antigen 更友好的显示 使用powerline
sudo apt install powerline# 或者用pip安装pip install --user powerline-status 常用配置 根据偏好修改 ~/.zshrc
# 我喜欢的主题 agnosterZSH_THEME=&amp;quot;agnoster&amp;quot;# 常用插件, git和autojump必备plugins=(git autojump git-flow git-extras python sudo extract zsh-syntax-highlighting)# 配置默认用户DEFAULT_USER=xulz 常用命令
# 重新加载配置以生效source ~/.zshrc# 更新默认shell为zshchsh -s /bin/zsh 缩短路径显示 如果文件路径层级较多,显示路径比较占视野. 可以修改为:
# cd ~/.oh-my-zsh/themescp agnoster.zsh-theme xulz.zsh-themevi xulz.zsh-theme# 修改 prompt_dir()方法prompt_dir() {# 如果路径超过5个层级,只显示最后2级目录, Home显示为~prompt_segment blue black &#39;%(5~|%-1~/.../%2~|%4~)&#39;}</content>
    </entry>
    
     <entry>
        <title>Go语言入门</title>
        <url>https://xulizhao.com/blog/go-learn/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 接触Go有段时间了，感觉有几个学习资源很有帮助：
 官方Go指南 : 边写边学, 最轻松简单的方式 系统的学习: 推荐书 &amp;lt;Go程序设计语言&amp;gt;， 我是先看的[中文电子版][1]之后买的实体书。 官方文档&amp;quot;Effective Go/实效Go编程&amp;rdquo; : 理解Go的必读文档  自己的体会是如果只看不写，等写代码时会发现实际没记住多少。这些好资料有的地方需要多看几遍，再结合平时多写代码去理解。
下面是一些Go语言学习笔记，作为学习的汇总。
基础参考 本地运行Go指南 go get github.com/Go-zh/tour/gotourgotour 如果以上命令失败,访问[中文在线版本][2]
 本地运行Go文档 go get golang.org/x/tools/cmd/godocgodoc -http=:6060//之后用浏览器访问 http://127.0.0.1:6060/doc/特性 new和make函数  new返回指针,make返回值
   new(T) : 为类型T的新对象申请零值内存并返回内存地址,(不初始化内存)的好处是不需要初始化函数.     make(T, args) ： 为slice,map,channel等返回初始化类型T后的值(非指针)   type Thing struct {Name stringNum int}// 如果包里只有一个类型，函数名可以简写为New// 构造函数使用的简写格式func NewThing(someParameter string) *Thing {return &amp;amp;Thing{someParameter, 33}}扩展阅读  [Go库文档查询][3] [Effective Go中英双语版][4] [Go如何初始化][5] [Effective Go: new和make的区别][6] Go 101 Go 和 Swift 语法比较 如何写出优雅的 Golang 代码 用TDD的方式学习Go [1]: https://xulizhao.com/docs/gopl [2]: https://tour.go-zh.org [3]: https://godoc.org [4]: https://www.gitbook.com/book/bingohuang/effective-go-zh-en/details [5]: https://stackoverflow.com/questions/18125625/constructors-in-go/18125682#18125682 [6]: https://golang.org/doc/effective_go.html#allocation_new </content>
    </entry>
    
     <entry>
        <title>Go网络开发笔记</title>
        <url>https://xulizhao.com/blog/go-networking/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 用Go开发网络很常见,由于对系统库还不是很熟,做下简单的笔记.
系统库模块  net : TCP连接 net.Conn net/http : HTTP处理 crypto/tls : SSL/TLS处理网络数据处理 encoding/json encoding/binary  JSON的要点  Go对象与JSON转换：  Marshal : 把对象编码为JSON数据格式 Unmarshal： 把JSON数据解码为Go 对象   streams形式的JSON数据读写(Reader/Writer)：  NewDecoder 从输入读取并编码 NewEncoder 编码并写入输出    type Foo struct {Bar string}body := new(bytes.Buffer)foo1 := Foo{&amp;#34;barTest&amp;#34;}json.NewEncoder(b).Encode(foo1)res, _ := http.Post(&amp;#34;https://httpbin.org/post&amp;#34;, &amp;#34;application/json; charset=utf-8&amp;#34;, body)foo2 := new(Foo) // new返回指针json.NewDecoder(r.Body).Decode(foo2)foo3 := Foo{} // 或者 var foo3 Foojson.NewDecoder(r.Body).Decode(&amp;amp;foo3)  *RawMessage:指针,处理嵌套json  // 接受收到json嵌套格式的响应, {&amp;#34;name&amp;#34;:{&amp;#34;first&amp;#34;:&amp;#34;Michael&amp;#34;,&amp;#34;last&amp;#34;:&amp;#34;Xu&amp;#34;},&amp;#34;gender&amp;#34;:&amp;#34;male&amp;#34;} //var dat map[string]*json.RawMessage var dat map[string]interface{}json.Unmarshal(response, &amp;amp;dat)r := dat[&amp;#34;name&amp;#34;].(map[string]interface{})firstName := r[&amp;#34;first&amp;#34;].(string) 代码示例 HTTP的例子 // 忽略HTTPS证书检查,因为本地用的自签名 tr := &amp;amp;http.Transport{TLSClientConfig: &amp;amp;tls.Config{InsecureSkipVerify: true}}// 自定义客户端 client := &amp;amp;http.Client{Transport: tr}payload := `{&amp;#34;username&amp;#34;:&amp;#34;xulz&amp;#34;}`// 创建请求,注:为简单期间忽略了错误检查 req, _ := http.NewRequest(&amp;#34;POST&amp;#34;, &amp;#34;https://xulizhao.com/api/login&amp;#34;, bytes.NewBuffer([]byte(payload)))// 定制头信息 req.Header.Set(&amp;#34;Content-Type&amp;#34;, &amp;#34;application/json&amp;#34;)resp, _ := client.Do(req)// 记得关闭连接 defer resp.Body.Close()// 把响应转换为对象 var ret LoginResponseif err := json.NewDecoder(resp.Body).Decode(&amp;amp;ret); err != nil {log.Warn(&amp;#34;error in json decode&amp;#34;, err)} TCP的例子 type LoginReq struct {Username string `json:&amp;#34;username&amp;#34;`Password int `json:&amp;#34;password`}// 读数据 func handleRead(conn net.Conn) []byte {buf := make([]byte, 1024)// 注: 返回读到的字节数 rLen, err := conn.Read(buf)checkError(err)r := buf[:rLen-1]// 假设前2个字节为实际数据大小 size := binary.BigEndian.Uint32(r[:2])log.Debug(&amp;#34;Recv:&amp;#34;, string(r))return r}// 写数据 func handleWrite(conn net.Conn, cmd []byte) {_, err := conn.Write(cmd)log.Debug(&amp;#34;Sent:&amp;#34;, string(cmd))checkError(err)}func main() {// 客户端忽略TLS检查 conf := &amp;amp;tls.Config{InsecureSkipVerify: true}server := ServerHost &#43; &amp;#34;:&amp;#34; &#43; ServerPort// 建立TCP连接 conn, err := tls.Dial(&amp;#34;tcp&amp;#34;, server, conf)checkError(err)defer conn.Close()auth := LoginReq(&amp;#34;xulz&amp;#34;, &amp;#34;password&amp;#34;)handleWrite(conn, auth)handleRead(conn)} 扩展阅读  json的用法讲解 官方博客, 代码示例 Go socket编程实践 </content>
    </entry>
    
     <entry>
        <title>IntelliJ IDEA</title>
        <url>https://xulizhao.com/blog/idea/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 接触最早最多的IDE是Eclipse,当时一有大版本我就下载更新,却总感觉变化不大.
后来时不时有人安利IntelliJ,我试用后体会不深,再说商业版很贵(早期没有社区版),没有继续使用.
做Python开发后,慢慢从Eclipse&#43;PyDev逐渐切换到PyCharm,感觉这才是IDE的样子,也就是足够智能.
之后越来越喜欢全家桶,IDEA,DataGrip,GoLand, 毕竟操作习惯了,而且我每次安装完必须给界面换成Darcula的黑色主题.
 话说最早喜欢JetBrains家的产品可以追溯到他出品的RSS阅读器:Omea Reader
 说这些只想分享鼓励更多人使用这个全球最好用的IDE系列.
下面是一些使用技巧,也许你已经知道.
快捷键    功能 Key (Mac) Linux Windows 说明     插入模板 Command &#43; J  Ctrl &#43; J Live templates   自动导入依赖库 Alt &#43; Enter  Alt &#43; Shift &#43; Enter    生成getter,setter等 Ctrl &#43; N  Alt &#43; Insert    自动结束代码，行末自动添加分号 ⌘⇧↩  Ctrl &#43; Shift &#43; Enter    删除当前行   Ctrl &#43; Y    注释当前行   Ctrl &#43; /    文档注释   /** &#43; Enter    参数文档提示 Cmd &#43; P  Ctrl &#43; P    增量选择 Cmd &#43; W  Ctrl &#43; W    格式代码 Option &#43; Cmd &#43; L  Ctrl &#43; Alt &#43; L    历史粘贴列表 Cmd &#43; Shift &#43; V  Ctrl &#43; Shift &#43; V    快速打开类   Ctrl &#43; N    快速打开文件   Ctrl &#43; Shift &#43; N    快速查看当前文件成员 Cmd &#43; F12  Ctrl &#43; F12    快速查看项目成员 Cmd &#43; Alt &#43; Shift &#43; N  Ctrl &#43; Alt &#43; Shift &#43; N    最近文件 Cmd &#43; Shift &#43; E  Ctrl &#43; E    回到上次编辑位置 Cmd &#43; Shift &#43; Backspace  Ctrl &#43; Shift &#43; Backspace            注:Windows的Ctrl通常等价于Mac的Command按键，可查看搜索[Settings]-[Keymap]
Java插件  lombok-intellij-plugin  运行Go代码前先格式化 问题: 做调试临时注释后,每次运行要先注释掉不用的import,真的挺烦人
解决: 先下载 File Watchers这个官方插件,之后到 [Preference]-[Tools]-[File Watchers]建立规则(程序路径根据本机情况调整):
  Go Imports   扩展阅读  12-intellij-idea-keyboard-shortcuts </content>
    </entry>
    
     <entry>
        <title>Go错误排查</title>
        <url>https://xulizhao.com/blog/go-fix-it/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 由于之前主要用的是Python这类动态语言,切换到Go还有些不适应.
这些出错信息看的一头雾水,记下来供参考.
问题1: 无效的内存地址或空指针  invalid memory address or nil pointer dereference
  原因1 := 会重新赋值,有可能造成nil赋值 原因2 原因3: 我使用的URL是自签名的https服务,需要声明忽略SSL检查  // 场景: 用http包给指定的api发送POST一段json数据 tr := &amp;amp;http.Transport{TLSClientConfig:&amp;amp;tls.Config{InsecureSkipVerify:true},}client := &amp;amp;http.Client{Transport:tr}</content>
    </entry>
    
     <entry>
        <title>Go性能测试</title>
        <url>https://xulizhao.com/blog/go-perf/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go用下来最深的体会就是其极其高效的性能。
官方调优工具  pprof：调优分析和可视化工具  测试工具    名称 教程 备注     hey  ❤ 替代ab   boomer  Locust扩展   Vegeta      Hargo   解析HAR文件并回放    # boomerbrew install zeromq czmq libsodium# vegetaecho &amp;#34;PUT http://127.0.0.1/user/xulz&amp;#34; | vegeta attack -keepalive=false -duration=60s | tee results.bin | vegeta report扩展阅读  best practices for writing high-performance Go code </content>
    </entry>
    
     <entry>
        <title>Kubernetes</title>
        <url>https://xulizhao.com/blog/kubernetes/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html"> Kubernetes(缩写为k8s)是最流行的开源容器管理平台, 现在也是事实上的容器编排调度标准.
打算写系列的相关文章,记录自己的学习过程.
 Kubernetes部署篇:本地开发测试环境搭建 Kubernetes部署篇:Kubespray方式自动化 用kubeadm手动搭建Kubernetes集群 kubectl命令汇总 Kubernetes命名空间的应用  一些其他笔记.
最佳实践  不要设置比必要的默认值 不要使用裸Pod, 使用Deployment,ReplicaSet,Job 使用前提前创建Service, 使用域名 善用label 容器镜像不要使用:latest标签 (默认的imagePullPolicy是IfNotPresent,即本地不存在镜像时才pull) 灵活使用目录, kubectl apply/create -f  快速创建单容器的部署/服务: kubectl run/expose  缩写    缩写 描述     CRD Custom Resource Definition, k8s 1.7引入    运行应用 Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义(declarative)方法，用来替代以前的ReplicationController 来方便的管理应用。
在新版本的Kubernetes中建议使用ReplicaSet来取代ReplicationController。
将kubectl的 &amp;ndash;record 的 flag 设置为 true可以在 annotation 中记录当前命令创建或者升级了该资源。
# 检查 Deployment 升级的历史记录kubectl rollout history deployment/nginx-deployment# 单个变更的详情kubectl rollout history deployment/nginx-deployment --revision=2集群资源管理 Label  &amp;ldquo;release&amp;rdquo; : &amp;ldquo;stable&amp;rdquo;, &amp;ldquo;release&amp;rdquo; : &amp;ldquo;canary&amp;rdquo; &amp;ldquo;environment&amp;rdquo; : &amp;ldquo;dev&amp;rdquo;, &amp;ldquo;environment&amp;rdquo; : &amp;ldquo;qa&amp;rdquo;, &amp;ldquo;environment&amp;rdquo; : &amp;ldquo;production&amp;rdquo; &amp;ldquo;tier&amp;rdquo; : &amp;ldquo;frontend&amp;rdquo;, &amp;ldquo;tier&amp;rdquo; : &amp;ldquo;backend&amp;rdquo;, &amp;ldquo;tier&amp;rdquo; : &amp;ldquo;cache&amp;rdquo;  扩展阅读  Configuration Best Practices Kubernetes中文指南  注: 官方文档是学习的开始,博客文章通常有时效性,而Kubernetes的版本更新很快.
</content>
    </entry>
    
     <entry>
        <title>Docker基础</title>
        <url>https://xulizhao.com/blog/docker/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>container</tag><tag>docker</tag><tag>ops</tag>
        </tags>
        <content type="html"> 最近两年随着微服务而流行起来的Docker是一种轻量级容器技术(相对于VMWare,KVM等Hypervisor解决方案).
它能给开发,测试,运维各团队提供一个统一的运行环境, 这点很实用.
Docker可以看做在内核容器技术(Cgroup和Namespace)的基础上提供更高级功能的控制工具,主要特性:
(1)跨主机部署(2)以应用为中心 (3)自动构建 (4)版本管理 (5)组建重用 (6)共享 (7)工具生态链
 补充: 关于虚拟化的主流分类
   操作系统(服务器)级别的虚拟化: 在硬件层之上做Hypervisor,内核级隔离. 常见的有VMWare vsphere, XEN,KVM, Hyper-V     进程(容器)级别的虚拟化: Docker 和LXC(Linux Container)   配置国内镜像 国内使用前Docker的第一件事,必须先配置国内镜像加速器,否则下载容器镜像龟速(最近安装docker也不用了)
 中科大镜像(推荐):docker CE源使用手册/Docker HUB源使用手册 Aliyun DaoCloud : 需要先注册 Docker 中国官方镜像加速:运行了几个月就不可用了,够坑爹的😤  使用示例：
# 如果想永久保存，编辑/etc/docker/daemon.json并添加{&amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://docker.mirrors.ustc.edu.cn/&amp;#34;]}# 必须重启服务以生效sudo service docker restart安装  Ubuntu Guide Docker CE for Mac Docker CE for Windows  Ubuntu环境安装 # 安装Dockersudo apt-get -y install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository &amp;#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable&amp;#34;sudo apt-get -y updatesudo apt-get -y install docker-ce# 安装docker-composesudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-composesudo chmod &#43;x /usr/local/bin/docker-composeCentOS离线安装 依赖库: libcgroup和device-mapper-*
# 离线包下载: http://rpmfind.net/linux/rpm2html/search.phprpm -ivh clibcgroup-*rpm -ivh device-mapper-* --force --nodeps# 追加一行到/etc/fstabnone /sys/fs/cgroup cgroup defaults 0 0# 重启以生效shutdown -r now# 启动cgroupservice cgconfig start# 下载docker: https://yum.dockerproject.org/repo/main/centos/6/Packages/rpm -ivh docker-engine-*.rpmservice docker start基础命令  docker docker-compose : 编排 docker-machine (Docker Toolbox已过时,不推荐使用)  # 把当前用户添加到docker组sudo usermod -aG docker xulz## dockerdocker run # 在新容器运行命令docker start # 启动容器# 查看所有容器docker ps -a docker ps -a --no-trunc # 显示完整的命令# 查看所有镜像docker imagesdocker stop/rm xxx# 删除docker rm &amp;lt;container_id&amp;gt;docker rmi &amp;lt;image_id&amp;gt;# 加载镜像docker load &amp;lt; &amp;lt;image_file&amp;gt;# 复制文件到容器docker cp source_file &amp;lt;container_name&amp;gt;:destination# 切换到容器终端docker exec -it container_name /bin/bash# 在后台启动docker start `docker ps -q -l` # restart it in the backgrounddocker attach `docker ps -q -l` # reattach the terminal &amp;amp; stdin# Detatch: Ctrl&#43;p &#43; Ctrl&#43;q## 常用compose命令# --build 意味着在启动前先构建容器# -d 在detached模式运行docker-compose up --builddocker-compose psdocker-compose stop## docker-machinedocker-machine ipdocker-machine envDocker Hub 到hub.docker.com注册自己的ID, 提供一个私有仓库及不限共有仓库．
今天为了国内访问kubernetes的学习项目方便，建立了一个镜像，步骤如下：
# 需要先在网页创建仓库# 再命令行登录hubdocker logindocker pull gcr.io/google-samples/kubernetes-bootcamp:v1docker tag gcr.io/google-samples/kubernetes-bootcamp:v1 xulz/kubernetes-bootcamp:v1docker push xulz/kubernetes-bootcamp:v1用Docker部署Flask Web App的示例 主要用到的配置文件:
 Dockerfile : 存放自动化的创建镜像的全部指令&amp;gt; docker build docker-compose.yml : 创建多个容器的模板文件,主要包含services,volumns,network .env : 设置环境变量 .dockerignore : 忽略文件  扩展  Portainer : Docker管理 Web界面 docker-compose-ui: Docker Compose Web界面  与Vagrant比较  docker-compose exec CONTAINER /bin/sh == vagrant ssh docker cp == vagrant scp  资源参考  Docker从入门到实践 Docker入门教程-英文 Awesome Docker Docker Cheat Sheet </content>
    </entry>
    
     <entry>
        <title>利器之TMUX</title>
        <url>https://xulizhao.com/blog/tmux/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> 用法  tmux ls : list sessions tmux attach -t 0 : -t 代表“target” , 0 是session名 tmux kill-session -t 0 : 结束会话 tmux source ~/.tmux.conf : 重新加载配置 复制和粘贴: 使用Shift临时禁用tmux,然后Ctrl&#43;Shift&#43;C  常用快捷键    Key Description     C-b (Ctrl-b) Send the prefix key   M (Alt, meta key)    prefix c new-window   prefix &amp;quot; split-window   prefix % split-window -h   prefix z resize-pane -Z   prefix $ Rename the current session   prefix , Rename the current window   prefix M-1 select-layout even-horizontal   prefix M-2 select-layout even-vertical   prefix M-3 select-layout main-horizontal   prefix M-4 select-layout main-vertical   prefix M-5 select-layout tiled    流行配置 如果懒得折腾，有个流行的通用配置已经够用。见一套常用配置
cdgit clone https://github.com/gpakosz/.tmux.gitln -s -f .tmux/.tmux.confcp .tmux/.tmux.conf.local .# 编辑～/.tmux.conf.local 以定制自己的新需求使用会话保存和恢复插件 我精彩使用自动保存和恢复的功能，用到了插件管理和几个插件。 使用步骤如下：
# 1. 安装 Plugin Managergit clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm# 2. 编辑 .tmux.conf 或.tmux.conf.localset -g @plugin &amp;#39;tmux-plugins/tpm&amp;#39;set -g @plugin &amp;#39;tmux-plugins/tmux-resurrect&amp;#39;set -g @plugin &amp;#39;tmux-plugins/tmux-continuum&amp;#39;set -g @continuum-restore &amp;#39;on&amp;#39;run &amp;#39;~/.tmux/plugins/tpm/tpm&amp;#39;# 3. 安装配置里的插件prefix &#43; I # 大写的I代表Installprefix &#43; U # 更新插件# 4. 重启后恢复会话prefix &#43; Ctrl-s # 保存prefix &#43; Ctrl-r # 恢复其他插件 # .tmux.confset -g @plugin &amp;#39;tmux-plugins/tmux-sensible&amp;#39; # 常用配置set -g @plugin &amp;#39;tmux-plugins/tmux-yank&amp;#39; # 复制/粘贴 Vim Tmux Navigator Tmuxinator 也是用于管理会话的  小技巧 技巧1: 总是保留一个会话 终端启动时先运行 tmux attach -t base || tmux new -s base
技巧2: 多面板命令同步 把当前输入发送到当前窗口的所有面板 setw synchronise-panes
技巧3: 缩放 prefix &#43; z放大当前面板, 再次输入恢复。
资源及参考  Manual 10 Killer Tmux Tips  </content>
    </entry>
    
     <entry>
        <title>Go流行库简介</title>
        <url>https://xulizhao.com/blog/go-lib/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go作为最近几年随大数据,Docker而火热起来(依然偏小众)的服务端语言,最近接触下来的感觉是第三方库/框架还是不够稳定和丰富,很多应用场景还没有一个绝对地位的首选库.
偶尔发现LibHunt还不错,可以在库选型时做些对比.
用Go开发的著名系统：etcd, kubernetes, docker
微服务    名称 教程 备注     Go kit     Micro  1 灵感于go-kit,支持pub-sub   Kratos  bilibili   Gizmo   New York Times    数据处理    名称 教程 备注     go.uuid     gjson          GORM  ORM   MySQL Driver     sqlite3 driver          statsd  statsd相关   veneur  stripe   go-metrics     gostatsd  atlassian   Pachyderm  数据管道    消息    名称 教程 备注     NSQ  bitly, 实时的分布式消息平台、高可用、可靠消息   machinery  异步任务队列    测试    名称 教程 备注     Agouti  WebDriver client    Web    名称 教程 备注     beego  build-web-application-with-golang    Gin      Gogs  Git service   QOR   CMS    系统扩展    名称 教程 备注     Viper  配置库   Cobra   CLI   logrus     zap  Uber,日志   GolangCI-Lint  静态检查   GoReleaser  与GitHub集成，打包构建   cron  定时任务    分布式系统    名称 教程 备注     jaeger  分布式追踪系统   M3  Uber,时序数据库    用Go开发的工具    名称 教程 备注     nps  内网穿透代理服务器    import (// UUID生成,支持v1~v4 &amp;#34;github.com/satori/go.uuid&amp;#34;// logging/日志扩展必备 // 使用别名 log替代系统模块 log &amp;#34;github.com/sirupsen/logrus&amp;#34;//JSON Parser,尤其适用于嵌套多层的json &amp;#34;github.com/tidwall/gjson&amp;#34;)// UUID示例id := uuid.NewV4().String()// 支持定义日志级别log.SetLevel(log.DebugLevel)log.Debug(resp.StatusCode)log.WithFields(log.Fields{&amp;#34;username&amp;#34;: username}).Debug(&amp;#34;Login info:&amp;#34;)// 用内置json处理会比较繁琐const json = `{&amp;#34;name&amp;#34;:{&amp;#34;first&amp;#34;:&amp;#34;Michael&amp;#34;,&amp;#34;last&amp;#34;:&amp;#34;Xu&amp;#34;},&amp;#34;age&amp;#34;:30}`value := gjson.Get(json, &amp;#34;name.last&amp;#34;)</content>
    </entry>
    
     <entry>
        <title>SSH使用及扩展</title>
        <url>https://xulizhao.com/blog/ssh/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 经常和Linux服务器打交道就离不开SSH.
常用命令 # 生成keyssh-keygen -t rsa -C &amp;#34;admin[at]xulizhao.com&amp;#34;# 删除无效的公钥,通常由于变更IP造成ssh-keygen -f &amp;#34;~.ssh/known_hosts&amp;#34; -R 8.8.8.8# 复制公钥信息到粘贴板xclip -selection clipboard &amp;lt; ~/.ssh/id_rsa.pub# 如果服务器没有开启SSH服务, 需要先安装apt install openssh-server# 打印DEBUG信息用以调试ssh -v ...# 远程运行本地脚本ssh xulz@moon bash &amp;lt; /path/to/local/script.sh目录结构 一般ssh相关文件存放在~/.ssh目录, Windows在 %userprofile%/.ssh
 公钥: id_rsa.pub 私钥: id_rsa 认证公钥: authorized_keys 配置文件: config  # 样例ServerAliveInterval 60TCPKeepAlive yes# 配置别名,很有用Host moonHostName moon.xulizhao.comuser ubuntuPort 22IdentityFile ~/.ssh/github.key 服务端配置: /etc/ssh/sshd.config  无密码登录 # Mac需要先安装brew install ssh-copy-id# 关键命令ssh-copy-id username@remotehost# 有时也需要修改权限chmod 600 ~/.ssh/authorized_keystimed out waiting for input: auto-logout echo $TMOUTvi /etc/profileexport TMOUT=600source /etc/profile扩展应用 Mosh 更稳定的SSH,适合移动端等网络不可靠环境
sshfs 把远程服务器的路径映射为本地路径
# 安装sudo apt-get install sshfs# 映射远程文件系统mkdir ~/remote_codesshfs remote.xulizhao.com:/home/$USER/code ~/remote_code客户端工具 免费/开源的:
 bitvise ssh client : Windows下最好用的 XShell/XFtp Remmina : Linux标配 PAC Manager Dropbear : 轻量级客户端和服务器端  收费中最好用的:
 SecureCRT&#43;SecureFX  扩展阅读  SSH Examples, Tips &amp;amp; Tunnels sh连接远程主机执行脚本的环境变量问题 </content>
    </entry>
    
     <entry>
        <title>Nginx</title>
        <url>https://xulizhao.com/blog/nginx/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html"> 时常会用到Nginx,一直没有好好的梳理下,以后更新在这里.
基础使用 安装 照官方教程来就好,没啥好说的.
# CentOS中 $releasever替换为主版本号,比如7; $basearch 替换为架构, 用arch命令查看# Ubuntu中 用以下命令修复错误: GPG error: http://nginx.org/packages/ubuntu xenial Release: The following signatures couldn&#39;t be verified because the public key is not available: NO_PUBKEY $key;# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys $key # CentOSsudo tee /etc/yum.repos.d/nginx.repo &amp;lt;&amp;lt;-&amp;#39;EOF&amp;#39;[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1EOF常用命令:
# 手动启动/etc/init.d/nginx start# 开机启动服务chkconfig nginx on# 修改配置文件后,验证语法正确nginx -t# 重新加载配置让修改立即生效sudo nginx -s reload# 查看当前版本信息nginx -V配置  /etc/nginx/nginx.conf 默认常用Document Root : /var/www/, /srv, /usr/share/www  指令: Location  使用正则:必须以下面2种前缀开始  &amp;ldquo;~&amp;rdquo; 大小写匹配 &amp;ldquo;~*&amp;rdquo; 忽略大小写匹配 不做匹配检查使用空block,即 &amp;ldquo;/ /&amp;rdquo;   不使用正则(literal): 逐字匹配,一旦匹配停止继续检索  = 前缀强制URI和Location参数的匹配     正则备忘: ^ 代表以xx开始, $代表以xx结尾
 location = / {# 只匹配 / 查询}location /test {# 开启目录自动索引autoindex on;} URL重写 rewrite (PCRE, perl兼容正则)
try_files # 首先找相应的URI# 如果没有,尝试添加/作为目录去匹配# 如果还是找不到,转发给代理try_files $uri $uri/ @proxy; 主要变量:  $server_name : 虚拟主机名  日志 默认的错误日志位于/var/log/nginx/error.log
# 开启debug日志对调试很有用error_log /var/log/nginx/error.log debug;本地开发环境 Mac安装 brew install nginx# 以服务的形式随系统启动brew services start nginx# 主要配置目录/usr/local/var/www # Doc Root/usr/local/etc/nginx/nginx.conf/usr/local/etc/nginx/servers/ ## 虚拟server  Windows使用服务 借助于 winsw 可以把Nginx安装成服务.
 winsw.exe install/uninstall/start/stop/restart/status
 Troubleshooting Q: 在CentOS安装完,绑定8443端口出错: bind() to 0.0.0.0:8443 failed, Permission denied A: 原因: SELinux 阻止了连接 解决1: semanage port -a -t http_port_t -p tcp 8443 解决2: tsebool httpd_can_network_connect on -P
# 辅助调试命令sestatustail -f /var/log/audit/audit.logsemanage port -l | grep http_port_tgetsebool -a | grep httpd# 如果找不到semanage命令:yum provides /usr/sbin/semanageyum -y install policycoreutils-python 常见配置场景 端口重定向  location /test {# 重写URLs,把请求/testXXXX转换成/XXXX交给AppServer.rewrite ^/test(.*) /$1 break;proxy_pass http://127.0.0.1:8000;proxy_set_header X-Forwarded-For $remote_addr;proxy_set_header Host $http_host;} 启用HTTPS 各主流中间件容器对于ssl的配置可参考Mozilla自动生成网站
# 利用多核worker_processes auto;http {# 缓存ssl session以提高性能ssl_session_cache shared:SSL:10m;ssl_session_timeout 10m;server {listen 443 ssl;ssl_certificate /etc/ssl/xulizhao.com.crt;ssl_certificate_key /etc/ssl/xulizhao.com.key;# 优先采用server端算法ssl_prefer_server_ciphers on;...# 生成曲线参数openssl dhparam -out dhparam.pem 2048# 列出支持的曲线算法openssl ecparam -list_curves# 查看系统ssl版本rpm -qa openssl# 关于椭圆曲线配置ssl_dhparam /path/to/dhparam.pem;ssl_ecdh_curve secp384r1;对某路径启用认证密码保护 # 使用htpasswd工具加密密码sudo apt-get install apache2-utilssudo htpasswd -c /etc/nginx/.htpasswd admin# 编辑配置,添加sudo vi /etc/nginx/sites-available/defaultauth_basic &amp;quot;Private Property&amp;quot;;auth_basic_user_file /etc/nginx/.htpasswd;sudo service nginx reload 修改超时设置 Nginx连接Tomcat的默认超时是1分钟
vi /etc/nginx/conf.d/default.conf# 修改proxy_read_timeout的值location / {proxy_pass http://127.0.0.1:8080;proxy_read_timeout 180;} 状态页 location /nginx_status {stub_status on;access_log off;# Securityallow 192.168.1.100;deny all;} blog 二级域名与子目录映射 location / { rewrite ^/(.*)$ /blog/$1 last; } location ~* ^/blog/.*$ { proxy_pass http://127.0.0.1:8080; }  日志记录响应时间 # 在预制格式combined的最后# 添加 $request_time 和 $upstream_response_timelog_format combined_timed &amp;#39;$remote_addr - $remote_user [$time_local] &amp;#34;$request&amp;#34; &amp;#39;&amp;#39;$status $body_bytes_sent &amp;#34;$http_referer&amp;#34; &amp;#39;&amp;#39;&amp;#34;$http_user_agent&amp;#34; &amp;#34;$http_x_forwarded_for&amp;#34; $request_time $upstream_response_time&amp;#39;;access_log /var/log/nginx/access.log combined_timed;语言支持 支持php # 添加以下内容location ~ \.php$ {try_files $uri =404;fastcgi_split_path_info ^(.&#43;\.php)(/.&#43;)$;fastcgi_pass unix:/var/run/php/php7.0-fpm.sock;fastcgi_index index.php;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;include fastcgi_params;} 资源  location指令官方文档 Nginx 配置 HTTPS 服务器/Nginx配置更安全的SSL证书 Open Resty: Nginx增强版, 使用Lua扩展功能.  特点: 可以直接访问 Redis/MemCached; 使用场景: 安全过滤模块, 数据报表; 应用: 淘宝量子统计, 去哪网   OpenResty 最佳实践  </content>
    </entry>
    
     <entry>
        <title>Python学习系列</title>
        <url>https://xulizhao.com/blog/python/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> Python记录系列.
编程学习系列  Python开发环境 Python编码风格 Python编程基础 Python高级笔记 Python高性能技巧 Python Unicode 迁移到Python3  第三方框架/库系列  Python流行库 Ansible Fabric Flask Django  工具  Jupyter Notebook/iPython  网络教程  Python最佳实践指南 python-patterns: A collection of design patterns and idioms Visualize Python Tutor Learning Python Interactive Tutorials Google&#39;s Python Class  书籍  流畅的Python Automate the Boring Stuff with Python 在线版：中文名为&amp;lt;Python编程快速上手&amp;gt;,新手入门 A Byte of Python/简明 Python 教程  读代码  Werkzeug </content>
    </entry>
    
     <entry>
        <title>Python开发环境配置</title>
        <url>https://xulizhao.com/blog/python-dev/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> Python开发环境问题记录.
Python基础环境 Anaconda conda config --add channels conda-forgeconda install -c conda-forge peewee安装pip3 python3 -m ensurepip镜像加速  阿里云镜像: https://mirrors.aliyun.com/pypi/simple/ 清华镜像： &amp;ndash;pypi-mirror https://pypi.tuna.tsinghua.edu.cn/simple  在国内访问官方的库比较慢，建议使用国内的镜像站。
Windows配置在 %HOMEPATH%\pip\pip.ini
mkdir ~/.pipvi ~/.pip/pip.conf[global]timeout = 6000index-url = https://pypi.doubanio.com/simple/trusted-host = pypi.doubanio.com[install]use-mirrors = truemirrors = https://pypi.doubanio.com/清华镜像
# 临时使用pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pipenv# 设为默认, 修改# ~/pip/pip.conf (Linux)# %APPDATA%\pip\pip.ini (Windows 10)# $HOME/Library/Application Support/pip/pip.conf (macOS)[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simpleAnaconda镜像
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes# 第三方源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/Ubuntu sudo apt install python-pip python-setuptools python-wheel在Mac上同时安装Python2和Python3 缘起: 在High Sierra 10.12及更高版本,给系统自带的Python2安装一些第三方库(如gevent)会因为系统开启SIP导致失败.
 SIP即系统完整性保护,要查看SIP的状态:&amp;gt; csrutil status
  受到SIP保护的路径：/System, /usr, /bin, /sbin
 比较好的方式是使用brew安装最新版的Python2/3
brew install python2# 有问题重装# brew reinstall python@2brew install python3# 安装之后也相应的安装了对应的pip2, pip3python2 -Vpip2 -V# 建立快捷方式brew link python3### pip3安装第三方库# 需要添加到PATHexport PATH=/Users/xulz/Library/Python/3.6/bin:$PATH开发环境 pip用法  pip/python package installer
  &amp;ndash;force-reinstall 重装所有包,即使已经最新 -I, &amp;ndash;ignore-installed 重现安装包(忽略已安装) -e, &amp;ndash;editable &amp;lt;path/url&amp;gt; 从本地或VCS安装一个项目为编辑模式(setuptools开发模式)  # 安装git仓库# @和#之间可以是tag或branchpip install -e git://github.com/xulz/locust.git@0.13.6#egg=locustiopip install some-package.whl# 使用本地存储pip install --use-wheel --no-index --find-links=/where/its/downloaded package_name# 创建依赖# 导出当前环境下的所有第三方库 pip freeze &amp;gt; requirements.txt #将当前所有第三方库打成wheel包并保存在当前目录的backup文件夹下 pip wheel --wheel-dir=&amp;#34;.\backup&amp;#34; -r requirements.txt #从备份文件夹中安装第三方库 pip install --use-wheel --no-index --find-links=&amp;#34;.\backup&amp;#34; -r requirements.txt本地开发包 # 在本地的site-packages创建指向开发环境的软链接 pip install -e .#或者 python setup.py develop使用pipenv 推荐用pipenv的方式方便使用.
# 安装pip3 install pipenv# 安装第三方库pipenv install requests# 在virtualenv运行pipenv run python main.py# 或激活virtualenvpipenv shell# 使用镜像pipenv install --pypi-mirror https://pypi.tuna.tsinghua.edu.cn/simple# 或者替换项目Pipfile对应urlvirtualenv 直接使用
# 指定python版本virtualenv -p python3 &amp;lt;project_name&amp;gt;# 也可使用pip3 install virtualenvwrapper# 用法source /usr/local/bin/virtualenvwrapper.shmkvirtualenv workonrequirements.txt 一些限定用法:
requests&amp;gt;=2.11.1lxml&amp;gt;=3.8.0,!=4.2.0ipaddress; python_version &amp;lt; &amp;#39;3.0&amp;#39;colorama; sys_platform == &amp;#39;win32&amp;#39;环境依赖 Q: fatal error: Python.h: No such file or directory
A:
sudo apt install python3-devTroubleshooting 版本冲突 坑: 先发布了版本1.0, 之后发布了1.0.1, 结果pip install package_name总是得不到更新
原因: pip版本判断时会认为 1.0 &amp;gt; 1.0.1
最佳实践: 命名发布版本时要遵循x.x.x的格式
显示详细日志 pip install -vvv requests locale.Error Q: pip install get error: &amp;lsquo;locale.Error: unsupported locale setting&amp;rsquo;
A: export LC_ALL=C, then check locale settings
参考  清华大学开源软件镜像站 </content>
    </entry>
    
     <entry>
        <title>Jenkins持续集成工具</title>
        <url>https://xulizhao.com/blog/jenkins/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html"> 时不时会和持续集成工具Jenkins打交道.
安装 直接安装系统安装包 推荐安装方式,以Ubuntu为例:
wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add -sudo vi /etc/apt/sources.list.d/jenkins.list# 添加deb https://pkg.jenkins.io/debian-stable binary/sudo apt-get updatesudo apt-get install jenkins用Docker容器的方式安装 注: 用容器的方式看似更方便,但实际使用中由于Jenkins经常会调用外部工具, 比如在Jenkins(容器里)调用docker, 会增加使用的复杂度,不太推荐这种方式.
docker run -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts# 为了在jenkins调用docker,需要在上面命令行增加两个文件映射# -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker 初始密码文件通常位于/var/lib/docker/volumes/jenkins_home/_data/secrets/initialAdminPassword
更多配置参考官方文档.
常用配置 git添加ssh key  首先生成Jenkins用户的ssh-key 在git仓库设置项添加公钥以只读权限. 通常位于[Repository settings]-[Access keys].  # 登录Jenkins机器su - jenkinsssh-keygen -t rsa -P &amp;#39;&amp;#39;修复错误 stderr: Host key verification failed 复制ssh公钥到 .ssh文件夹, 对于Ubuntu在/var/lib/jenkins/.ssh, 可能需要相应的修改文件夹权限.
传递参数 #!/usr/bin/env bashpipenv run python3 -m pytest tests/test_smoke.py -x --html=report.html --junitxml=junit-report.xml调用docker解决权限问题 如果遇到&amp;quot;permission denied&amp;quot;错误,需要把jenkins加到docker用户组里:
sudo usermod -a -G docker jenkinsAndroid 构建 android update project -p &amp;lt;project_path&amp;gt;# 更新SDK./tools/android update sdk --no-ui修改时区 -Duser.timezone=&amp;quot;Asia/Chongqing&amp;rdquo;
流水线/Pipeline CD(Continous Delivery) 引入了流水线/工作流的概念,即可以把构建,测试,部署分阶段执行, 最终实现产品的持续部署. Jenkins通过官方插件支持两种任务: 流水线和多分支流水线. 具体的流水线任务通过脚本的形式定义, 使用的语法为Groovy, 看起来还是很简洁的. 一个例子如下,大致层次为 pipeline-stage-step:
pipeline {agent anystages {stage(&amp;#39;Deploy&amp;#39;) {steps {retry(3) {sh &amp;#39;./flakey-deploy.sh&amp;#39;}timeout(time: 3, unit: &amp;#39;MINUTES&amp;#39;) {sh &amp;#39;./health-check.sh&amp;#39;}}}}}添加Slave sudo useradd -d /var/lib/jenkins jenkinspasswd jenkinsPython API调用 无认证 import requestsapi_url = &amp;#34;http://jenkins.xulizhao.com/job/test_job/api/json?tree=lastSuccessfulBuild[number]&amp;#34;r = requests.get(api_url)build_number = r.json()[&amp;#39;lastSuccessfulBuild&amp;#39;][&amp;#39;number&amp;#39;]需要认证 # 先安装依赖库 pip install python-jenkins# 代码示例 import jenkinsserver = jenkins.Jenkins(&amp;#39;http://jenkins.xulizhao.com&amp;#39;, username=&amp;#39;user&amp;#39;, password=&amp;#39;password&amp;#39;)last_build_number = server.get_job_info(&amp;#39;test_job&amp;#39;)[&amp;#39;lastSuccessfulBuild&amp;#39;][&amp;#39;number&amp;#39;]curl方式 # 检索最近变更记录curl -u xulz:0f945a8f -s &amp;#34;http://jenkins.xulizhao.com/job/test-job/123/api/xml?wrapper=changes&amp;amp;xpath=//changeSet//comment&amp;#34;比较遗憾的是Jenkins 的API Token只适用于构建job,其他接口需要用户名/密码登录.* build_job_url(name, parameters=None, token=None)* build_job(name, parameters=None, token=None)高级配置 脚本调试 访问&amp;lt;JENKINS_URL&amp;gt;/script, 输入要调试的内容
# 查看遗忘的credentials密码println( hudson.util.Secret.decrypt(&amp;#34;${ENCRYPTED_PASSPHRASE_OR_PASSWORD}&amp;#34;) )常用插件  Email Extension Plugin: 邮件增强扩展 Extended Choice Parameter Plug-In: 参数选择扩展 EnvInject plugin : 传递构建参数和环境变量  报告  HTML Publisher: HTML Publisher插件不显示CSS的解决 Junit Publisher  扩展阅读  Jenkins官方网站 GoCD :另一个持续交付工具 pipeline构建参数的使用 Jenkins API使用文档 python-jenkins文档 how-to-add-linux-slave-node-agent-node/ssh-slaves-plugin)  </content>
    </entry>
    
     <entry>
        <title>Golang开发环境</title>
        <url>https://xulizhao.com/blog/go-dev/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 简单记录下Go语言开发环境的搭建和基本用法.
安装 如果要使用系统命令安装:
# Ubuntuapt install golang# Macbrew install golang如果想安装最新版本的话,可以直接到镜像站下载系统对应版本或者参考Ubuntu安装最新版.
# 安装1.12版本sudo add-apt-repository ppa:longsleep/golang-backportssudo apt-get updatesudo apt-get install golang-go如果在Linux的话解压缩之后需要设置下环境变量:
# vi ~/.zshrc 添加export GOPATH=$HOME/goexport GOBIN=$HOME/go/binexport PATH=$GOPATH/bin:$PATH 注: 在新版命令行安装之后, GOROOT(设置安装路径)和GOPATH都不用设置.
  GOPATH 默认位置为 $HOME/go, 该目录用来在标准Go目录之外存放get, build和install等下载的依赖包. 放置源代码(src)、归档文件(pkg)和可执行文件(bin) go env 查看当前环境变量
 Go扩展包的下载 优先选择: 可以使用阿里的goproxy
 export GOPROXY=https://mirrors.aliyun.com/goproxy/
 如果要编译一个开源项目,在国内的环境下, go get 的方式通常会因为访问 golang.org/x 而失败.
绕过方式为手动下载依赖:
cd $GOPATH/srcmkdir -p golang.org/xcd golang.org/x# 通常下边几个库就够用了,具体以错误提示相应的下载git clone https://github.com/golang/net.gitgit clone https://github.com/golang/sys.gitgit clone https://github.com/golang/crypto.git# 显示调试信息 verbosego get -v常用命令 # 运行go run hello.go# 编译并指定运行环境GOOS=linux GOARCH=amd64 go build -o hello hello.go# 打包go install hello.go# 格式化, -w:直接覆盖原代码,不输出到控制台gofmt -w hello.go## 查看文档godoc fmt依赖管理 可以通过Dep这个工具来管理项目依赖.
# Mac安装brew install dep# 或者Linuxcurl https://raw.githubusercontent.com/golang/dep/master/install.sh | shdep init# 会在项目目录创建依赖配置文件Gopkg.toml[[constraint]]branch = &amp;#34;master&amp;#34;name = &amp;#34;golang.org/x/net&amp;#34;构建 set GOARCH=amd64set GOOS=linuxgo build -o demo demo.go扩展阅读  官方推荐项目结构 Go安装包清华镜像 Go库本地下载 </content>
    </entry>
    
     <entry>
        <title>Git备忘</title>
        <url>https://xulizhao.com/blog/git/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Git常用命令解释  pull： 合并远程代码 fetch: 从远程下载最新代码，但不会merge或rebase  -all: 下载所有分支   reset: 重置master到fetch的最新代码  &amp;ndash;hard： 改变本地工作树以匹配origin/master    Git常见场景用法 新建项目仓库 # 把当前项目加入git版本管理git init# 提交文件变更echo &amp;#34;xulz&amp;#34; &amp;gt;&amp;gt; contributors.txtgit add contributors.txtgit commit -m &amp;#39;Initial commit with contributors&amp;#39;推送变更 # 关联远程仓库git remote add origin git@github.com:xulz/test.git# 推送本地变更到远程仓库git push -u origin master# 以上简写为$ git pushgit push -u origin --all # pushes up the repo and its refs for the first timegit push -u origin --tags # pushes up any tags# push遇到错误 ! [rejected] master -&amp;gt; master (non-fast-forward)# 风险: 可能会造成remote丢失提交git push --force --set-upstream origin master强制pull/处理本地冲突 如果需要保存
 本地提交： git branch new-branch-to-save-current-commits 未提交变更： git stash 然后 git stash pop  # git force pullgit fetch origin mastergit reset --hard origin/master# 删除本地untracked文件git clean -f -d其他常用场景 从git删除而保留本地文件 # untrack/从git删除而保留本地文件git rm -r --cached foldergit rm --cached file1 file2git push部分合并分支 git checkout dev -- FILE_YOU_WANTgit cherry-pick $COMMIT_ID_YOU_WANT基本配置 # 列出当前项目主要配置git config --list# 编辑当前项目配置文件vi .git/config# 修改全局配置vi ~/.gitconfig Branch 分支 分支的习惯用法:
origin/master 应该始终保持生产环境可用的状态,即可部署.
origin/develop 代表最新的code, 是nightly测试的重点. 如果稳定到可以release,需要为新发布创建新tag,并merge回 master.
常用命令 # 同步远程分支git fetch# 列出所有分支git branch -a# 切换分支git checkout new_branch# push到远程git push --set-upstream origin new_branchFork同步上游仓库 # 查看当前远程仓库git remote -vgit remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git# 获取更新git fetch upstreamgit checkout mastergit merge upstream/masterTag 标签 推荐为每次软件发布创建标签.
# 为当前版本创建taggit tag v1.0.0 Git工作流  Git 工作流程  扩展阅读  学习资源：如果是新手,强烈推荐阅读Git简明教程, 进阶必读 Pro Git中文版 how-to-merge-specific-files-from-another-branch </content>
    </entry>
    
     <entry>
        <title>新博客</title>
        <url>https://xulizhao.com/play/blog-ghost/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 本博客基于Ghost开源博客平台搭建,系统基于Node.js开发.
主要看中她的简洁和轻量,编辑器使用Markdown,资源占用比较低(性能比WordPress好很多).
说下安装完需要定制的部分,供参考:
代码高亮 由于经常使用代码片段,用PrismJS添加了代码高亮,主要使用了Code injection功能,可参考网上这篇文章.
开启评论 系统没有评论功能,集成了第三方的Disqus,整合方式参考这里.
使用HTTPS 最近关联域名后启用了HTTPS.
ghost config url https://xulizhao.comghost setup nginx ssl# 之后需要更新Ngxin的配置并reload# 使用Let&amp;#39;s Encrypt的免费证书,这个自动获取证书acme.sh脚本太好用了文章目录 折腾了多半天,添加了文章目录(TOC).
主要使用了jQuery-TOC插件,并仿照floating-header做了一个新图层
cd &amp;lt;GHOST_DIR&amp;gt;/content/themes/casper/assets/js wget https://github.com/idiotWu/jQuery-TOC/raw/master/dist/jquery.toc.min.jscd ../..// 修改 default.hbs,在fitvids以下添加一行引入 &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;{{asset &amp;#34;js/jquery.fitvids.js&amp;#34;}}&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;{{asset &amp;#34;js/jquery.toc.min.js&amp;#34;}}&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; // vi assets/css/screen.css.sidebar {visibility: visible;position: fixed;right: 0;top: 300px;z-index: 1000;display: flex;align-items: center;width: 300px;border-bottom: rgba(0,0,0,0.06) 1px solid;background: rgba(255,255,255,0.95);}// 手机不显示文章目录@media screen and (max-width: 600px) {#toc {visibility: hidden;}}// vi post.hbs&amp;lt;div id=&amp;#34;toc&amp;#34; class=&amp;#34;sidebar&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; // 在结束标记前添加{{/post}}// 在脚本部分的ready部分添加 $(document).ready(function () { $(&amp;#39;#toc&amp;#39;).initTOC({selector: &amp;#39;h1, h2, h3, h4&amp;#39;,scope: &amp;#39;.post-full-content&amp;#39;,overwrite: false,prefix: &amp;#39;toc&amp;#39;});PS:
从博客开始流行时的第三方博客平台到后来自己搭建Wordpress,最近几年又流行的基于github静态建站都有所尝试, 可是似乎脱离了建站的初心: 记录成长历程,练习表达.
希望在这坚持下去.
</content>
    </entry>
    
     <entry>
        <title>Flask开发笔记</title>
        <url>https://xulizhao.com/blog/flask/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>web</tag><tag>python</tag>
        </tags>
        <content type="html"> 开发基础 创建 Flask Starter Project pip3 install cookiecuttercookiecutter https://github.com/realpython/cookiecutter-flask-skeleton.git具体使用参考 项目地址
常用第三方 # requirements.txt FlaskFlask-BcryptFlask-LoginFlask-WTFFlask-BootstrapFlask-DebugToolbarFlask-TestingFlask-MigrateFlask-SQLAlchemycelery例子 # -- coding: utf-8 -- from flask import Flask, request, make_response, redirect, abortapp = Flask(__name__)# route建立请求路径和函数之间的映射 # 等同于 app.add_url_rule() # app.url_map 存放所以映射 @app.route(&amp;#34;/&amp;#34;)# 视图函数 def index():return &amp;#34;&amp;lt;h1&amp;gt;Hello World!&amp;lt;/h1&amp;gt;&amp;#34;# route支持类型: int, fload, path, 比如 &amp;lt;int:id&amp;gt; @app.route(&amp;#34;/user/&amp;lt;name&amp;gt;&amp;#34;)def greeting(name):return &amp;#34;Hello, %s&amp;#34; % name@app.route(&amp;#34;ua&amp;#34;)def user_agent():ua = request.headers.get(&amp;#34;User-Agent&amp;#34;)return &amp;#34;Your UA:%s&amp;#34; %ua@app.route(&amp;#34;/error/400&amp;#34;)def error400():return &amp;#34;&amp;lt;h1&amp;gt;Bad Request&amp;lt;/h1&amp;gt;&amp;#34;, 400# 第三个参数可以传入其他headers @app.route(&amp;#34;/cookie&amp;#34;)def respone_with_cookie():response = make_response(&amp;#34;Response with Cookie&amp;#34;)response.set_cookie(&amp;#39;user&amp;#39;, &amp;#39;xulz&amp;#39;)return response# 302 Response @app.route(&amp;#34;/redirect&amp;#34;)def redirect_test():return redirect(&amp;#34;http://127.0.0.1:5000&amp;#34;)# abort 会把控制权交给web server然后抛出异常 @app.route(&amp;#34;/abort&amp;#34;)def abort_test():abort(404)if __name__ == &amp;#34;__main__&amp;#34;:# 激活 debugger和reloader app.run(debug=True)Context    变量名 Context 描述     current_app 应用上下文 当前活跃的应用实例   g 应用上下文 用于一个request的临时存储,每次会重置   request 请求上下文 request对象   session 请求上下文 回话,requests间可访问    request Hooks  before_first_request before_request after_request: 没有发生异常时,注册 teardown_request 每次request之后注册,即使发生异常   一般把hook和functions view的共享数据存放在g应用上下文
 约定  templates static  Blueprint 应用的子集
app.register_blueprint(simple_page, url_prefix=&amp;#39;/pages&amp;#39;)SQLAlchemy filter_by(**kwargs)的使用：
db.users.filter_by(name=&amp;#39;Joe&amp;#39;)# 注意下面是重载符号==db.users.filter(db.users.name==&amp;#39;Joe&amp;#39;)db.users.filter(or_(db.users.name==&amp;#39;Ryan&amp;#39;, db.users.country==&amp;#39;England&amp;#39;))Flask 扩展 Flask App Builder 偶然发现一个增强版Flask项目,提供了更好的安全和自动CRUD操作等许多常用特性(有点学习Django的意思), 强烈推荐.
 celery -A application.celery workerform.my_field.render_kw = {&amp;#39;disabled&amp;#39;: &amp;#39;disabled&amp;#39;}技巧 禁止控制台输出 log = logging.getLogger(&amp;#39;werkzeug&amp;#39;)log.setLevel(logging.ERROR)增加响应延迟 def get_fake_latency():return random.uniform(0.1, 0.2)@app.after_requestdef apply_latency(response):time.sleep(get_fake_latency())return response部署 生产环境  不要使用｀app.run()｀方式运行 使用gunicorn  python实现，简单易用 运行: gunicorn app:app   使用uWsgi  C实现，CPU占用低 通常与Nginx反向代理一起使用    链接  Patterns for Flask 官方进阶 Explore Flask /Explore Flask中文翻译 Flask Web Development 作者博客 使用Docker部署Flask应用  </content>
    </entry>
    
     <entry>
        <title>Go基础笔记</title>
        <url>https://xulizhao.com/blog/go-basic/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go语言学习笔记。
语法和特性  main包比较特殊。它定义了一个独立可执行的程序，而不是一个库。 编译器会主动把特定符号后的换行符转换为分号, 因此换行符添加的位置会影响Go代码的正确解析.  作用域 名字的开头字母的大小写决定了名字在包外的可见性。如果一个名字是大写字母开头的，那么它将是导出的，也就是说可以被外部的包访问。
通常来说，如果一个名字的作用域比较大，生命周期也比较长，那么用长的名字将会更有意义。推荐使用 驼峰式 命名。
声明和赋值  变量会在声明时直接初始化 符号:=是短变量声明（short variable declaration）的一部分, 这是定义一个或多个变量并根据它们的初始值为这些变量赋予适当类型的语句. 通常在函数内部使用.请记住“:=”是一个变量声明语句，而“=”是一个变量赋值操作 自增和自减是语句，而不是表达式  逻辑结构  习惯在if中处理错误然后直接返回，这样可以确保正常执行的语句不需要代码缩进。 不要将一个控制结构if、for、switch、select的左大括号放在下一行 switch 不需要显式地在每一个case后写break switch还可以不带操作对象, tagless switch（注：switch不带操作对象时默认用true值代替，然后将每个case的表达式和true值进行比较） break会中断当前的循环，并开始执行循环之后的内容 continue会跳过当前循环，并开始执行下一次循环。  类型 Go语言将数据类型分为四类：
 基础类型: 数字、字符串和布尔型 复合类型: 数组和结构体 引用类型: 指针、切片、字典、函数、通道 接口类型:  对于每种类型T，如果转换允许的话，类型转换操作T(x)将x转换为T类型
&amp;amp;&amp;amp;对应逻辑乘法，||对应逻辑加法，乘法比加法优先级要高
字符串  文本字符串通常被解释为采用UTF8编码的Unicode码点（rune）序列 (rune是int32等价类型) 一个字符串是包含只读字节的数组，一旦创建，是不可变的。相比之下，一个字节slice的元素则可以自由地修改。 字符面值通过一对单引号直接包含对应字符。字符使用%c参数打印，或者是用%q参数打印带单引号的字符 一个原生的字符串面值形式是...，使用反引号代替双引号。 原生字符串面值同时被广泛应用于正则表达式、HTML模板、JSON面值、命令行提示信息以及那些需要扩展到多行的场景。  字符串处理包：bytes、strings、strconv和unicode
 bytes包还提供了Buffer类型用于字节slice的缓存 将一个字符串解析为整数，可以使用strconv包的Atoi或ParseInt函数 fmt.Scanf来解析输入的字符串和数字，特别是当字符串和数字混合在一行的时候，它可以灵活处理不完整或不规则的输入。 iota常量生成器初始化，用于生成一组以相似规则初始化的常量 (类似枚举)  fmt 后缀f指format，ln指line
字符串的格式化：
 fmt.Printf，它会把结果写到标准输出 fmt.Sprintf，它会把结果以字符串的形式返回。  这两个函数都使用了另一个函数fmt.Fprintf来进行封装, 前缀F表示文件(File)也表明格式化输出结果应该被写入第一个参数提供的文件中
// 返回格式化后的错误fmt.Errorf()// 处理时间fmt.Println(time.Now().Format(&amp;#34;2006-01-02 15:04:05&amp;#34;))结构体 在初始化结构体时使用带有标签的语法。
 将 slice 或 map 定义成自定义类型可以让你的代码更容易维护。 点操作符也可以和指向结构体的指针一起工作.调用函数返回的是值，并不是一个可取地址的变量 考虑效率的话，较大的结构体通常会用指针的方式传入和返回。如果要在函数内部修改结构体成员的话，用指针传入是必须的；因为在Go语言中，所有的函数参数都是值拷贝传入的，函数参数将不再是函数调用时的原始变量。  数组  数组是由同构的元素组成 (很少直接使用, 一般使用slice来替代数组)，结构体则是由异构的元素组成的。 数组和结构体都是有固定内存大小的数据结构。相比之下，slice和map则是动态的数据结构，它们将根据需要动态增长。 在数组字面值中，如果在数组的长度位置出现的是“&amp;hellip;”省略号，则表示数组的长度是根据初始化值的个数来计算 通常是将append返回的结果直接赋值给输入的slice变量  Slice切片  slice底层是数组，保存了len、capacity和对数组的引用 从slice创建新slice时，注意原slice的操作可能导致底层数组变化 如果创建很长的slice，尽量创建成一个slice里存引用，这样可以分批释放  Map Map是引用类型，不需要指针（类似指针类型, 切片）
json json.Marshal返回[]byte和error，必须先判断error是否为空，再进一步解析 []byte
指针 指针是可见的内存地址，&amp;amp;操作符可以返回一个变量的内存地址，并且*操作符可以获取指针指向的变量内容
一个指针的值是另一个变量的地址
 &amp;amp;x表达式（取x变量的内存地址），指针对应的数据类型是*int，指针被称之为“指向int类型的指针” *p表达式对应p指针指向的变量的值，变量有时候被称为可寻址的值  new只是一个预定义的函数
 在现实的程序里，一般会约定如果Point这个类有一个指针作为接收器的方法，那么所有Point的方法都必须有一个指针接收器。 只有类型(Point)和指向他们的指针(*Point)，才可能是出现在接收器声明里的两种接收器 不管你的method的receiver是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。 在声明一个method的receiver该是指针还是非指针类型时，你需要考虑两方面的因素，第一方面是这个对象本身是不是特别大，如果声明为非指针变量时，调用会产生一次拷贝；第二方面是如果你用指针类型作为receiver，那么你一定要注意，这种指针类型指向的始终是一块内存地址，就算你对其进行了拷贝。  模块 init()函数总是被执行，一个package的多个init()都会被执行
//函数返回不定数量参数func multiArgs(a ...interface{}){fmt.Println(a...)}IO  io ioutil  body, _ := ioutil.ReadAll(resp.Body)Reader // 从Reader读取内容body, err := ioutil.ReadAll(r.Body)错误处理  error是一个值 error是可恢复的,panic却不是  如果导致失败的原因只有一个，额外的返回值可以是一个布尔值，通常被命名为ok
fmt.Errorf函数使用fmt.Sprintf格式化错误信息并返回。我们使用该函数添加额外的前缀上下文信息到原始错误信息。
错误信息中应避免大写和换行符
log.Fatalf 等价于输出错误并退出
// 注意错误处理的位置resp, err := http.Get(url)if err != nil {//handle error without panicing }// there was no error, so resp.Body is guaranteed to exist. defer resp.Body.Close()接口 接口只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要。
对于接口设计的一个好的标准就是 ask only for what you need（只考虑你需要的东西）
实用工具  time.Tick 定时执行 </content>
    </entry>
    
     <entry>
        <title>Java8学习</title>
        <url>https://xulizhao.com/blog/java8/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Java系列记录文章。
学习笔记 lambda 允许通过::关键字获取方法(可以是类的静态方法,也可以是对象的方法)或者构造函数的的引用.
范围: 与匿名函数类似,可以访问对应外部区域的final变量,成员变量和静态变量. 默认方法无法在lambda表达式内部被访问.
内置函数式接口:
 Comparator Runnable Predicate 布尔型函数判断 Function 接受一个参数,处理并返回 Supplier 与Function的区别是没有输入参数 Consumer  工具接口Optional 用来防止NullPointerException
 isPresent()  Streams/流 某种元素的序列,可在其上进行各种中间操作或完结操作
构造流:
 Collections.stream() Collection.parallelStream()  常用类:
 IntStream.rangeClosed(1,10),forEach()  常用函数式接口
 Filter接受一个predicate接口类型的变量，并将所有流对象中的元素进行过滤 (中间操作) Sorted能够返回一个排过序的流对象的视图,但不会改变原来集合中元素的顺序(中间操作) map是一个对于流对象的中间操作 ForEach接受一个function接口类型的变量，用来执行对每一个元素的操作。ForEach是一个中止操作,不返回流。 Match匹配操作是终结操作，只返回一个boolean类型的结果 Count是一个终结操作 Reduce该操作是一个终结操作,操作的结果会放在一个Optional变量里返回  日期和时间 这些时间对象都是不可变的，因此是线程安全的。
 Clock 当前时区相关 LocalDateTime 与时区无关的本地时间 Duration 时间区间 DateTimeFormatter 新实现  常用方法：
Clock clock = Clock.systemDefaultZone();// 替代 System.currentTimeMillis()long millis = clock.millis();Instant instant = clock.instant();Date legacyDate = Date.from(instant); // legacy java.util.Date// 时区ZoneId zone = ZoneId.of(&amp;#34;Asia/Chongqing&amp;#34;);LocalTime now = LocalTime.now(zone);Instant instant = dateTime.atZone(ZoneId.systemDefault()).toInstant();LocalDateTime dateTime = LocalDateTime.now();LocalDate.of(2019, Month.OCTOBER,16);dateTime.toLocalDate();dateTime.getMonth();// 更新时间dateTime.withDayOfMonth(13).withYear(2018);dateTime.plusDays(25).plusYears(2);dateTime.with(TemporalAdjusters.lastDayOfMonth());LocalTime t2 = LocalTime.parse(&amp;#34;10:15:30&amp;#34;);t2.truncatedTo(ChronoUnit.MINUTES);时间和字符串转化
LocalTime time = LocalTime.parse(&amp;#34;17:07:30&amp;#34;);DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&amp;#34;MMM dd yyyy&amp;#34;);LocalDate date = LocalDate.of(2019, Month.OCTOBER, 16);System.out.println(date.format(formatter));学习资源  Java Date and Time API in Java 8 - Tutorial   Java 8 简明教程 </content>
    </entry>
    
     <entry>
        <title>Java核心库</title>
        <url>https://xulizhao.com/blog/java-core/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 回归基础。
类型 Java类型必定是class, abstract class，interface, enum ,annotation之一.
基本类型 变量的类型有：
primitive/原语数据类型: byte/char/short/int/long/float/double/boolean 占用字节&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-8 &amp;mdash;16 &amp;mdash;16&amp;mdash;32&amp;ndash;64&amp;mdash;32&amp;mdash;&amp;ndash;64&amp;mdash;&amp;mdash;&amp;mdash; 对应封装类型: Byte/Character/Short/Integer/Long/Float/Double/String (不可变)
当变量指向一个对象时，变量被称作对象的引用
注：float和double类型不应该用于精确计算，在需要的场合要使用BigDecimal类
Object 所有对象的超类，常用方法：
 equals(o1) 对象比较 hashCode() 返回当前对象唯一标识 getClass() 返回实例类 toString() 返回当前对象的字符表示  String/字符串 不可变对象。在Java内部使用bytes表示，使用UTF-16编码（即双字节）
 substring(包含的,不包含的) trim():去掉头尾部空白，包括空格、Tab、换行符 很多次的字符串连接要使用StringBuilder  String three = new StringBuilder(one).append(two).toString();数组/Arrays 数组用以存储同一类型的对象，一旦创建后后无法改变大小。
 length是数组对象的一个属性 Arrays是针对数组对象进行操作的工具类 Arrays.binarySearch 返回插入位置的索引-1  // 初始化，{}被称为array literalint[] ints = { 1,2,3,4,5,6,7,8,9,10 };// 装箱Integer boxedValue = Integer.valueOf(18);// 拆箱int intValue = boxedValue.intValue();// 注：Java虽然支持自动装箱和拆箱,但以上显式的写法可读性更好// 解析字符串Integer convertedValue = Integer.parseInt(&amp;#34;123&amp;#34;);String characterNumeric = convertedValue.toString();// 注：在String表达式中使用串联运算符时会自动装箱并调用toString()逻辑结构 for for(Loop initializer;Loop condition;Post iteration operation)
 continue: 直接跳到下一迭代，而不继续执行之后的循环体 break: 立即跳出循环，即使循环条件仍满足  注：do while循环在条件被测前至少执行一次
foreach for的增强简化版本。一般结合泛型使用,适用于不需要引用数组或者集合的索引的情况。
for(元素类型t 元素变量x : 遍历对象obj){引用了x的java语句;}switch 支持类型有 byte, short, char, int, String, enum
break跳出switch语句.
类 修饰符static  静态类意味着在类加载时（类第一个被引用时）执行，并且只运行一次 静态方法或字段属于类，而不是类实例  修饰符final final字段不能更改它的值，通常与static连用，表示常量
访问修饰符 protected 类似于包修饰符，除了子类可以访问（即使子类在包外）
构造函数  扩展类不需要集成构造函数 子类必须在构造函数调用父类的构造函数  变量 四类变量：
 Non-static fields ( instance variables) Static fields ( class variables) Local variables ( declared inside a method) Parameters  数据处理  java.security.SecureRandom  字符 Scanner以文本格式读，PrintWriter以文本格式写
字符集：字符集名字大小写不敏感，中文和日文是可变字节编码
I/O // 复制二进制数据:System.arraycopy()Arrays.copyOfRange(buf, i, buf.length)接口  InputStream/OutputStream Writer/Reader  编码/解码  Java.util.Base64 (1.8&#43;)  System  System.identityHashCode()  缩略语  JAX-RS: Java API for RESTful Services JAX-WS: Java API for XML-Based Web Services  资源  Hierarchy For Package java.lang Java NIO概述 </content>
    </entry>
    
     <entry>
        <title>Java日志</title>
        <url>https://xulizhao.com/blog/java-logging/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Java日志的使用笔记。
现在流行的日志库通常包含Log Facade和Log Implementation两部分，可以理解为上层抽象和底层实现。
具体的组合用法为：
 SLF4J(Simple Logging Facade for Java) &#43; Logback Log4j2 (2.x版本) : log4j-api &#43; log4j-core  背景介绍：SLF4J,Logback是log4j 1.x版本的重新实现，作者为同一人。
日志简介 记录日志的三个原因:
 记录操作轨迹 监控系统运行状况 回溯系统故障  日志级别从低到高: TRACE、DEBUG、INFO、WARN、ERROR、FATAL
Appender 主要职责：
 接受日志事件 使用Layout格式化日志 转发到指定目标输出  SLF4J SLF4J 是Java日志框架的抽象接口和门面实现。
最常见的日志使用方式：
import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class Log4jExample {// 定义为static，与当前类绑定，避免每次都new一个新对象 private static final Logger logger = LoggerFactory.getLogger(Log4jExample.class);public static void main(String[] args) {logger.debug(&amp;#34;Debug log message&amp;#34;);logger.info(&amp;#34;Info log message&amp;#34;);logger.error(&amp;#34;Error log message&amp;#34;);}}添加依赖
&amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;slf4j-api&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;1.7.28&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;Log4J 2 添加库依赖log4j-api和log4j-core：
&amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;org.apache.logging.log4j&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;log4j-api&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;2.12.1&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;&amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;org.apache.logging.log4j&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;log4j-core&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;2.12.1&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;&amp;lt;!--异步日志依赖 --&amp;gt;&amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;com.lmax&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;disruptor&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;3.4.2&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;配置文件log4j2.xml
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&amp;lt;Configuration status=&amp;#34;INFO&amp;#34;&amp;gt;&amp;lt;Appenders&amp;gt;# Console appender&amp;lt;Console name=&amp;#34;stdout&amp;#34; target=&amp;#34;SYSTEM_OUT&amp;#34;&amp;gt;&amp;lt;PatternLayout pattern=&amp;#34;%d{yyyy-MM-dd HH:mm:ss} %p %m%n&amp;#34;/&amp;gt;&amp;lt;/Console&amp;gt;# File appender&amp;lt;File name=&amp;#34;fout&amp;#34; fileName=&amp;#34;logs/log4j2.log&amp;#34;immediateFlush=&amp;#34;false&amp;#34; append=&amp;#34;false&amp;#34;&amp;gt;&amp;lt;PatternLayout pattern=&amp;#34;%d{yyyy-MM-dd HH:mm:ss} %p %m%n&amp;#34;/&amp;gt;&amp;lt;/File&amp;gt;&amp;lt;/Appenders&amp;gt;&amp;lt;Loggers&amp;gt;# Override log level for specified package&amp;lt;Logger name=&amp;#34;com.xulizhao.logging&amp;#34; level=&amp;#34;TRACE&amp;#34;/&amp;gt;&amp;lt;AsyncRoot level=&amp;#34;DEBUG&amp;#34;&amp;gt;&amp;lt;AppenderRef ref=&amp;#34;stdout&amp;#34;/&amp;gt;&amp;lt;AppenderRef ref=&amp;#34;fout&amp;#34;/&amp;gt;&amp;lt;/AsyncRoot&amp;gt;&amp;lt;/Loggers&amp;gt;&amp;lt;/Configuration&amp;gt;Logback  依赖  &amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;ch.qos.logback&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;logback-classic&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;&amp;lt;!--会自动下载依赖的logback-core 和 slf4j-api--&amp;gt;配置文件logback.xml  &amp;lt;configuration&amp;gt;# Console appender&amp;lt;appender name=&amp;#34;stdout&amp;#34; class=&amp;#34;ch.qos.logback.core.ConsoleAppender&amp;#34;&amp;gt;&amp;lt;layout class=&amp;#34;ch.qos.logback.classic.PatternLayout&amp;#34;&amp;gt;&amp;lt;Pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss} %p %m%n&amp;lt;/Pattern&amp;gt;&amp;lt;/layout&amp;gt;&amp;lt;/appender&amp;gt;# File appender&amp;lt;appender name=&amp;#34;fout&amp;#34; class=&amp;#34;ch.qos.logback.core.FileAppender&amp;#34;&amp;gt;&amp;lt;file&amp;gt;logs/logback.log&amp;lt;/file&amp;gt;&amp;lt;append&amp;gt;false&amp;lt;/append&amp;gt;&amp;lt;encoder&amp;gt;&amp;lt;pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss} %p %m%n&amp;lt;/pattern&amp;gt;&amp;lt;/encoder&amp;gt;&amp;lt;/appender&amp;gt;&amp;lt;appender name=&amp;#34;roll-by-time-and-size&amp;#34;class=&amp;#34;ch.qos.logback.core.rolling.RollingFileAppender&amp;#34;&amp;gt;&amp;lt;file&amp;gt;logs/roll-by-time-and-size/app.log&amp;lt;/file&amp;gt;&amp;lt;rollingPolicyclass=&amp;#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&amp;#34;&amp;gt;&amp;lt;fileNamePattern&amp;gt;logs/roll-by-time-and-size/app.%d{yyyy-MM-dd-mm}.%i.log.zip&amp;lt;/fileNamePattern&amp;gt;&amp;lt;maxFileSize&amp;gt;5KB&amp;lt;/maxFileSize&amp;gt;&amp;lt;maxHistory&amp;gt;20&amp;lt;/maxHistory&amp;gt;&amp;lt;totalSizeCap&amp;gt;1MB&amp;lt;/totalSizeCap&amp;gt;&amp;lt;/rollingPolicy&amp;gt;&amp;lt;encoder&amp;gt;&amp;lt;pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss} %p %m%n&amp;lt;/pattern&amp;gt;&amp;lt;/encoder&amp;gt;&amp;lt;/appender&amp;gt;# Override log level for specified package&amp;lt;logger name=&amp;#34;com.xulizhao.logging&amp;#34; level=&amp;#34;TRACE&amp;#34;&amp;gt;&amp;lt;appender-ref ref=&amp;#34;roll-by-time-and-size&amp;#34;/&amp;gt;&amp;lt;/logger&amp;gt;&amp;lt;root level=&amp;#34;INFO&amp;#34;&amp;gt;&amp;lt;appender-ref ref=&amp;#34;stdout&amp;#34;/&amp;gt;&amp;lt;appender-ref ref=&amp;#34;fout&amp;#34;/&amp;gt;&amp;lt;/root&amp;gt;使用规范  日志文件命名:appName_logType_logName.log。类型可以有stats,monitor,visit等,logName为日志描述 对DEBUG,INFO级别日志必须使用条件输出或使用占位符方式{}打印。 使用 additivity=&amp;quot;false&amp;rdquo; 避免打印重复日志(appender累积) ERROR级别只记录系统逻辑错误，异常或违反重要业务规则，其他错误对归为WARN 记录日志一定要输出异常堆栈信息，例如logger.error(&amp;ldquo;xxx&amp;quot;&#43;e.getMesssage(),e)  日志性能优化  关闭不必要的日志   logging.level.org.apache.zookeeper=OFF
 &amp;lt;configuration&amp;gt;&amp;lt;include resource=&amp;#34;org/springframework/boot/logging/logback/basic.xml&amp;#34;/&amp;gt;&amp;lt;logger name=&amp;#34;org.apache.zookeeper&amp;#34; level=&amp;#34;WARN&amp;#34;/&amp;gt;&amp;lt;/configuration&amp;gt; 设置高过滤级别  &amp;lt;filter class=&amp;#34;ch.qos.logback.classic.filter.ThresholdFilter&amp;#34;&amp;gt;&amp;lt;level&amp;gt;ERROR&amp;lt;/level&amp;gt;&amp;lt;/filter&amp;gt; 异步处理日志事件  NDC (Nested Diagnostic Context)和MDC (Mapped Diagnostic Context)是基于线程级的，两者的区别是MDC使用map而NDC使用stack。
其他日志和冲突解决 这块历史包袱太重了，经常遇到冲突问题或slf4j多个绑定的问题。
先解释几个名词：
 jcl : 代表commons-logging jul : 代表JDK自带的jdk-logging  解决冲突  如果遇到SLF4J: Class path contains multiple SLF4J bindings 或Could not initialize class org.apache.logging.log4j.util.PropertiesUtil 错误，需要删除其一
  jcl-over-slf4j和slf4j-jcl互相委托，删除其一 log4j-over-slf4j和slf4j-log4j12互相委托，删除其一 jul-to-slf4j和slf4j-jdk14互相委托，删除其一  资源  slf4j、jcl、jul、log4j1、log4j2、logback大总结 Log4j 2 log4j - PatternLayout slf4j /Logback Spring Boot日志文档 Java 日志框架解析(下) - 最佳实践 https://www.baeldung.com/java-logging-intro </content>
    </entry>
    
     <entry>
        <title>Java命令行及工具集</title>
        <url>https://xulizhao.com/blog/java-tools/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 工欲善其事必先利其器。
Java基础命令行 java # 运行jarjava -jar target/demoApp.jar # cp代表Class Pathjava -cp target/demoApp-0.1-SNAPSHOT.jar com.xulizhao.demo.Appjar # 列出jar内容jar tf target/demoApp.jar # 创建jar cf myJar.jar myClass.classjar cvf program.jar -C path/to/classes .# e 参数创建入口jar cfe myJar.jar myClass myClass.class 其他命令 # javap 查看编译器生成的字节码,即 class文件javap -c App监控/Profiler工具 dump方式较简单粗暴，推荐使用JMC.
dump文件可使用VisualVM或Eclipse MAT打开。
jps jps: Java Virtual Machine Process Status Tool
# 先查看已有java进程jps -v# 找到CPU占用最高的线程top -n 1 -H -p [PID]# PID代表线程ID# 生成stack tracejstack [PID] &amp;gt; jstack-out.txt# 把PID转换成hex值, %d转回printf &amp;#34;%x\n&amp;#34; 2712# 搜索,对应nid=0xcat jstack-out.txt | grep -i a98Dump HPROF是用来profile Heap和CPU的内置工具。
会造成JVM停顿，生产环境谨慎执行。
 jmap：导出内存dump jstack: 导出线程dump  Heap Dump  jmap -dump : 运行时获得(会停止java进程) 使用hprof命令: java -agentlib:hprof=help   jmap -dump:live,format=b,file=heap.hprof your-pid
 Thread Dump 获取ThreadDump
 jstack -l &amp;raquo; threadinfo.log kill -3  jcmd &amp;lt;pid&amp;gt; Thread.print &amp;gt; &amp;lt;file-path&amp;gt;  自带监控工具集  Java VisualVM (jvisualvm) JConsole (jconsole) Java Mission Control (jmc): 使用采样技术(而不是代码植入) Diagnostic Command Tool (jcmd)  第三方工具 诊断/调试  Arthas: 阿里出品的Java诊断利器 BTrace: 在生产动态监控某些方法的执行时长等信息  Arthas # 安装curl -O https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar# 常用命令syspropsysenvjvmdashboard# 高级使用# 查看CPU使用率top n线程的栈thread -n 3# 查看5秒内的CPU使用率top n线程栈thread -n 3 -i 3000# 查找线程是否有阻塞thread -b# 清除watch/trace等命令的增强代码reset # 彻底退出shutdown 付费Profiler  JProfiler Yourkit  反编译  GUI  JD-GUI Luyten   CFR: 支持新版Java的命令行反编译工具 Android dex反编译：dex2jar intellij java decompiler Hopper:付费的可执行文件反编译工具  混淆保护  ProGuard  扩展阅读  Monitoring Java Applications with Flight Recorder Guide to Java Profilers 付费:Java生产环境下性能监控与调优详解 </content>
    </entry>
    
     <entry>
        <title>RDP远程登录Linux</title>
        <url>https://xulizhao.com/blog/linux-rdp/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> 有时候为了远程调试，经常会遇到RDP到Linux主机的情况。
主要用到xrdp协议并确保Linux主机已安装桌面系统。
连接到Ubuntu sudo apt-get install -y xrdp xfce4echo xfce4-session &amp;gt;~/.xsessionsudo vi /etc/xrdp/startwm.sh之后编辑内容如下：
#!/bin/shif [ -r /etc/default/locale ]; then. /etc/default/localeexport LANG LANGUAGEfi# 注释掉下面一行，如果RDP停在登录界面. /etc/X11/Xsessionstartxfce4之后重启服务：
sudo service xrdp restart对于命令行tab失效问题的解决： Go to &amp;ldquo;Applications -&amp;gt; Settings-&amp;gt;Window Manager&amp;rdquo;, in the &amp;ldquo;Keyboard&amp;rdquo; tab, clear the binding of &amp;ldquo;Switch wndow for same application -&amp;gt; Tab&amp;rdquo;
连接到CentOS7 # 安装桌面系统yum groupinstall &amp;#34;GNOME Desktop&amp;#34; &amp;#34;Graphical Administration Tools&amp;#34;rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmyum -y install xrdp tigervnc-server# 启动xrdpsystemctl start xrdp# netstat -antup | grep xrdp# 应该能看到启动的服务systemctl enable xrdp参考  https://www.itzgeek.com/how-tos/linux/centos-how-tos/install-xrdp-on-centos-7-rhel-7.html  </content>
    </entry>
    
     <entry>
        <title>Java异常处理</title>
        <url>https://xulizhao.com/blog/java-exception/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 异常处理。
异常分层结构 checked Exception用于可恢复的情况。
通用原则是把异常重新抛给可以处理的服务层，一定不用吞掉异常。
 已检查的异常/check-mandated：已有编译器检查，Exception 的子类,在方法中使用throws声明。 未检查的异常/运行时异常/check-not-mandated： RuntimeException 的子类  用法 try-with-resources 用来替代try-catch-finally, 资源需要实现Closeable或AutoCloseable接口的close()方法.
try{}语句块内可包含多个资源的声明和初始化.
try (Scanner scanner = new Scanner(new File(&amp;#34;testRead.txt&amp;#34;));PrintWriter writer = new PrintWriter(new File(&amp;#34;testWrite.txt&amp;#34;))) {while (scanner.hasNext()) {writer.print(scanner.nextLine());}}规范  不要在final代码块赋值，更不要return Lock,ThreadLocal,InputStream等都要在final块强制释放和清除 lock方法可能会抛出uncheck异常，应该在try块前调用 推荐公共接口使用错误码，公司内跨应用调用用Result对象封装错误码和错误描述信息，应用内直接抛出异常对象。 关于空指针异常，推荐返回值可以为null,不强制返回空集合或空对象，但需要注释返回null的情况。防止NPE一定是调用方的责任。  扩展阅读  Understanding checked vs unchecked exceptions in Java </content>
    </entry>
    
     <entry>
        <title>Java测试</title>
        <url>https://xulizhao.com/blog/java-test/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>testing</tag>
        </tags>
        <content type="html"> 代码测试 命名约定  类名以Test为后缀 在测试方法中使用  should，比如ordersShouldBeCreated Given[ExplainYourInput]When[WhatIsDone]Then[ExpectedResult]    JUnit 以Junit5为主。
常用注解  @Test() @Tag(&amp;ldquo;&amp;rdquo;) @Disabled(&amp;ldquo;reason&amp;rdquo;) @DisplayName(&amp;ldquo;&amp;rdquo;) @BeforeEach @TestFactory  Junit4 格式：
 @Ignore(&amp;ldquo;reason&amp;rdquo;) @Test(timeout=10)  断言  assertTrue assertEquals assertNull assertSame assertTimeout assertTimeoutPreemptively assertAll 分组 expectThrows  参数化 @ParameterizedTest
支持4种方式的数据源：
 @ValueSource @EnumSource @MethodSource @CsvSource  运行 自定义运行：JUnitCore.runClasses()
执行顺序： @FixMethodOrder(MethodSorters.NAME_ASCENDING) // Test Suites,支持2种方式@RunWith(JUnitPlatform.class)@SelectPackages(&amp;#34;com.xulizhao.junit5.demo&amp;#34;)@SelectClasses({OrderTest.class, ProductTest.class})public class AllTests {}TestNG  TestNG学习笔记  AssertJ assertj是一个fluent API的断言库
import static org.assertj.core.api.Assertions.*;assertThat(frodo.getName()).isEqualTo(&amp;#34;Frodo&amp;#34;);assertThat(frodo).isNotEqualTo(sauron);assertThat(frodo.getName()).startsWith(&amp;#34;Fro&amp;#34;).endsWith(&amp;#34;do&amp;#34;).isEqualToIgnoringCase(&amp;#34;frodo&amp;#34;);JaCoCo 代码覆盖率测试
扩展阅读  junit5-samples Unit Testing with JUnit - Tutorial JaCoCo https://www.baeldung.com/testng </content>
    </entry>
    
     <entry>
        <title>Java面向对象设计</title>
        <url>https://xulizhao.com/blog/java-oo/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 面向对象编程和设计原则。
代码质量评判标准:易维护、易读、易扩展，灵活、简洁、可复用、可测试。
OO编程范式 面向对象  三/四要素： 抽象(基础)，封装，继承，多态  封装:数据隐藏保护(可维护和易用性) 抽象:方法隐藏(具体实现)，抽象类和接口类实现(可扩展性和维护行，降低复杂度) 继承:is-a(代码复用) 多态:子类可以替换父类，运行中调用子类方法实现(扩展性和复用) 实现:继承加方法重写，接口类，duck-typing(两个类具有相同的方法)   基于接口而非实现编程 多用组合少用继承  接口和抽象类  接口(协议，约定):behave-like,解决抽象行为(解耦并隔离接口和实现)，表示具有某一组行为特征。自下而上。 抽象类:is-a,解决代码复用问题。自上而下。 可包含属性和方法(可实现，也可不实现)，  面向对象使用误区  滥用setter,getter:  尽量不要给属性定义 setter 方法 getter 方法如果返回的是集合容器, 要防范集合内部数据被修改的危险   Costants和Utils类要职责单一，尽量归并到相关类  静态方法一般用来操作静态变量或者外部数据。常用于各种 Utils 类 静态方法将方法与数据分离，破坏了封装特性，是典型的面向过程风格    设计原则  SOLID KISS,YAGNI DRY LOD法则  SOLID SRP 一个类只完成一个职责或功能；每个模块负责只满足一个业务功能需求。
类职责不单一的常见表现:
 代码行数、函数、属性过多 依赖的类或被依赖太多 私有方法太多 比较难起合适名字 大量方法都集中操作某几个属性  OCP  对扩展开放（应对变化），对修改关闭（保证稳定性）（扩展和修改依粒度而言） 具备扩展、抽象、封装意识 常用提高扩展性的方法： 多态、依赖注入、基于接口而非实现  LSP 子类遵循父类约定/design by contract
扩展阅读  FitNesse :Bob大叔的项目，学习参考 </content>
    </entry>
    
     <entry>
        <title>ZooKeeper</title>
        <url>https://xulizhao.com/blog/zookeeper/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>distributed</tag>
        </tags>
        <content type="html"> 作用及原理 作用: 分布式协调, 提供操作API
 配置管理 集群管理:  群主选举 资源定位   同步状态 统一命名服务  使用案例:
 HBase Hadoop Kafka  选举算法 一个Leader,其他节点为Follower
Leader选举算法 (分布式选举算法使用ZAB,是Paxos的变种)
一致性保证:
 数据变更先写磁盘再读入内存 读写原子 同步消息原子性 事务日志和快照是持久化存储.  写请求连接Leader, 读请求连接任意节点读取本地的复制.
配置 设置根目录： ZOOKEEPER_HOME
日志文件： zookeeper.out
集群推荐不少于3台，推荐奇数个节点,只要超过半数的节点OK(有效参与选举的节点数过半), ZooKeeper就能正常服务. 最好分布在不同的物理机上。
# server.N, 在zoo.cfg指定的dataDir目录下建立以服务器节点对应的myid文件,并更新内容为NinitLimit=5syncLimit=2server.1=zoo1:2888:3888server.2=zoo2:2888:3888server.3=zoo3:2888:3888# Ubuntu 随系统启动apt-get install zookeeperd性能 性能: 在读大于写时性能更好(读写10:1)
注：来自腾讯广告团队分享
问题：如果读写操作频繁，则Zookeeper server很容易不堪重负。
workaround：用C&#43;&#43;写了一个proxy，定期load Zookeeper数据，代替Zookeeper处理读操作，把写操作proxy给后面的Zookeeper。
替代方案：etcd </content>
    </entry>
    
     <entry>
        <title>Java常用库</title>
        <url>https://xulizhao.com/blog/java-lib/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> 常用的一些第三方库。
基础扩展    名称 教程 备注     Apache Commons     Guava：Google出品     Lombok  必备,省去getter/setter等样板代码    Web服务    名称 教程 备注     dropwizard  RESTful   客户端     httpclient     OkHttp 1 HTTP，HTTP/2客户端   retrofit  类型安全的HTTP客户端   HttpUnit  用于爬虫或测试   文档     Springfox  JSON接口文档   swagger-bootstrap-ui  swagger主题    数据处理    名称 教程 备注     Flyway  数据库迁移   P6Spy  数据库调试   MyBatis-Plus  MyBatis增强   H2 ErrorCode 本地开发调试，内存数据库   数据库连接池     druid  阿里出品   HikariCP     ehcache  本地缓存   JSON     Jackson 2 0,1,2 支持JSON等各种主流格式，由annotations，core, databind 组成   Gson  Google出品   fastjson  阿里出品   jsoup  HTML Parser   XML  内置的JAXB   Email  Spring 相关模块        统计计算     Apache Commons Math     Guava Math      测试类    名称 教程 备注     Truth  Fluent assertions, Google出品，适用于Java和Android   H2 Database  内存数据库    框架    名称 教程 备注     Netty  必知必会   Spring  必知必会   Play  高性能scala框架   disruptor  高性能线程间消息库，常用于pub-sub   Atlassian Plugins  插件框架         扩展阅读  awesome-java 20种常用类库 </content>
    </entry>
    
     <entry>
        <title>Maven构建工具</title>
        <url>https://xulizhao.com/blog/maven/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag>
        </tags>
        <content type="html"> Maven是Java开发中最常用的项目依赖管理工具。
虽然喜新厌旧的更喜欢Gradle，可在Java项目中还是会常常用到Maven，干脆做些记录。
基础 安装 解压安装包后需要设置环境变量：M2_HOME，之后把M2_HOME/bin加到PATH。
# Ubuntusudo apt install mavenmvn -version通过wrapper的方式，其他人可以不用安装Maven。
# 安装设置wrappermvn -N io.takari:maven:wrapper# 执行wrapper./mvnw clean package运行命令 运行mvn会在本地目录解析pom.xml(POM即Project Object Model)，依赖下载到位于 ~/.m2/repository的本地仓库。
mvn testmvn packagemvn clean package# IDEA支持mvn idea:idea一些选项说明：
 -X,&amp;ndash;debug -o 离线模式，不检查线上依赖更新 -ff, &amp;ndash;fail-fast  生命周期 生命周期包含各种阶段，各阶段通过插件和目标实现具体的任务。
常用阶段/phase：
 clean: 先清除之前的构建目标，即./target/目录 compile: 编译源码 package: 创建jar部署包 test: 运行测试 install: 编译，构建并安装到本地仓库 deploy: 部署到远程仓库等  一些生命周期目标通过插件实现。
通过模板快速创建项目 通过archtype插件生成项目模板：
mvn archetype:generate快速创建Java项目
mvn archetype:generate-DgroupId=com.xulizhao.demo-DartifactId=java-practice-DarchetypeArtifactId=maven-archetype-quickstart-DinteractiveMode=false忽略测试 mvn clean install -DskipTestsmvn package -Dmaven.test.skip=true# maven.test.skip同时控制maven-compiler-plugin和maven-surefire-plugin两个插件的行为，即跳过编译和测试或者
&amp;lt;properties&amp;gt;&amp;lt;skipTest&amp;gt;true&amp;lt;/skipTest&amp;gt;&amp;lt;/properties&amp;gt;打包时忽略错误：
&amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;maven-surefire-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;skip&amp;gt;true&amp;lt;/skip&amp;gt;&amp;lt;!--跳过单元测试--&amp;gt;&amp;lt;!--&amp;lt;testFailureIgnore&amp;gt;true&amp;lt;/testFailureIgnore&amp;gt;--&amp;gt;&amp;lt;!--忽略单元测试类的编译错误--&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/plugin&amp;gt;配置pom.xml GAV 即构成一个POM或依赖的基本三要素，来确定一个唯一的标识：
 groupId artifactId version  &amp;lt;project&amp;gt;&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;&amp;lt;groupId&amp;gt;com.xulizhao&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;demo&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;&amp;lt;name&amp;gt;demo-project&amp;lt;/name&amp;gt;&amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt;常用属性 &amp;lt;properties&amp;gt;&amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;&amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;&amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;&amp;lt;/properties&amp;gt;多模块项目 &amp;lt;project&amp;gt;&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;&amp;lt;groupId&amp;gt;com.xulizhao&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;guava&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;0.1.0-SNAPSHOT&amp;lt;/version&amp;gt;&amp;lt;name&amp;gt;guava&amp;lt;/name&amp;gt;&amp;lt;parent&amp;gt;&amp;lt;groupId&amp;gt;com.xulizhao&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;parent-java&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;&amp;lt;relativePath&amp;gt;../parent-java&amp;lt;/relativePath&amp;gt;&amp;lt;/parent&amp;gt;&amp;lt;modules&amp;gt;&amp;lt;module&amp;gt;core-java-collections&amp;lt;/module&amp;gt;&amp;lt;module&amp;gt;core-java-networking&amp;lt;/module&amp;gt;&amp;lt;/modules&amp;gt;&amp;lt;/project&amp;gt;打包 打包jar &amp;lt;build&amp;gt;&amp;lt;finalName&amp;gt;demoApp&amp;lt;/finalName&amp;gt;&amp;lt;plugins&amp;gt;&amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;2.3.2&amp;lt;/version&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;source&amp;gt;1.8&amp;lt;/source&amp;gt;&amp;lt;target&amp;gt;1.8&amp;lt;/target&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/plugin&amp;gt;&amp;lt;!--Make this jar executable --&amp;gt;&amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;maven-jar-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;archive&amp;gt;&amp;lt;manifest&amp;gt;&amp;lt;mainClass&amp;gt;com.xulizhao.demo.App&amp;lt;/mainClass&amp;gt;&amp;lt;/manifest&amp;gt;&amp;lt;/archive&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/plugin&amp;gt;&amp;lt;/plugins&amp;gt;&amp;lt;/build&amp;gt;打包依赖 默认不会添加项目依赖到jar，
复制依赖到文件夹 &amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;maven-jar-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;archive&amp;gt;&amp;lt;manifest&amp;gt;&amp;lt;addClasspath&amp;gt;true&amp;lt;/addClasspath&amp;gt;&amp;lt;!--&amp;lt;mainClass&amp;gt;&amp;lt;/mainClass&amp;gt;--&amp;gt;&amp;lt;classpathPrefix&amp;gt;dependency-jars/&amp;lt;/classpathPrefix&amp;gt;&amp;lt;/manifest&amp;gt;&amp;lt;manifestEntries&amp;gt;&amp;lt;Class-Path&amp;gt;.&amp;lt;/Class-Path&amp;gt;&amp;lt;/manifestEntries&amp;gt;&amp;lt;/archive&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/plugin&amp;gt;&amp;lt;!--复制依赖库 --&amp;gt;&amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;maven-dependency-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;2.5.1&amp;lt;/version&amp;gt;&amp;lt;executions&amp;gt;&amp;lt;execution&amp;gt;&amp;lt;id&amp;gt;copy-dependencies&amp;lt;/id&amp;gt;&amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;&amp;lt;goals&amp;gt;&amp;lt;goal&amp;gt;copy-dependencies&amp;lt;/goal&amp;gt;&amp;lt;/goals&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;includeScope&amp;gt;runtime&amp;lt;/includeScope&amp;gt;&amp;lt;outputDirectory&amp;gt;${project.build.directory}/dependency-jars/&amp;lt;/outputDirectory&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/execution&amp;gt;&amp;lt;/executions&amp;gt;&amp;lt;/plugin&amp;gt;使用插件 Maven Shade Plugin 打包成fat jar(也叫Uber Jar)并添加Main入口，这里的shade意味着类会被重命名以避免依赖间冲突。
一些例子参考官网Maven Shade Plugin
&amp;lt;plugin&amp;gt;&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;maven-shade-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;3.2.1&amp;lt;/version&amp;gt;&amp;lt;executions&amp;gt;&amp;lt;!--Attach the shade into the package phase --&amp;gt;&amp;lt;execution&amp;gt;&amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;&amp;lt;goals&amp;gt;&amp;lt;goal&amp;gt;shade&amp;lt;/goal&amp;gt;&amp;lt;/goals&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;!--去掉不必要的类，缩小jar尺寸.需要JDK8&#43; --&amp;gt;&amp;lt;minimizeJar&amp;gt;true&amp;lt;/minimizeJar&amp;gt;&amp;lt;transformers&amp;gt;&amp;lt;transformer implementation=&amp;#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&amp;#34;&amp;gt;&amp;lt;mainClass&amp;gt;com.xulizhao.demo.App&amp;lt;/mainClass&amp;gt;&amp;lt;/transformer&amp;gt;&amp;lt;/transformers&amp;gt;&amp;lt;artifactSet&amp;gt;&amp;lt;includes&amp;gt;&amp;lt;include&amp;gt;org.apache.jmeter:*&amp;lt;/include&amp;gt;&amp;lt;/includes&amp;gt;&amp;lt;excludes&amp;gt;&amp;lt;exclude&amp;gt;org.slf4j:*&amp;lt;/exclude&amp;gt;&amp;lt;exclude&amp;gt;org.apache.logging.log4j:*&amp;lt;/exclude&amp;gt;&amp;lt;/excludes&amp;gt;&amp;lt;/artifactSet&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/execution&amp;gt;&amp;lt;/executions&amp;gt;&amp;lt;/plugin&amp;gt;提取依赖classes 使用maven-assembly插件，仅适用于依赖库不多的情况。
&amp;lt;plugin&amp;gt;&amp;lt;artifactId&amp;gt;maven-assembly-plugin&amp;lt;/artifactId&amp;gt;&amp;lt;executions&amp;gt;&amp;lt;execution&amp;gt;&amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;&amp;lt;goals&amp;gt;&amp;lt;goal&amp;gt;single&amp;lt;/goal&amp;gt;&amp;lt;/goals&amp;gt;&amp;lt;/execution&amp;gt;&amp;lt;/executions&amp;gt;&amp;lt;configuration&amp;gt;&amp;lt;descriptorRefs&amp;gt;&amp;lt;descriptorRef&amp;gt;jar-with-dependencies&amp;lt;/descriptorRef&amp;gt;&amp;lt;/descriptorRefs&amp;gt;&amp;lt;/configuration&amp;gt;&amp;lt;/plugin&amp;gt;打包资源文件 &amp;lt;build&amp;gt;&amp;lt;resources&amp;gt;&amp;lt;resource&amp;gt;&amp;lt;directory&amp;gt;src/main/java&amp;lt;/directory&amp;gt;&amp;lt;includes&amp;gt;&amp;lt;include&amp;gt;**/*.dll&amp;lt;/include&amp;gt;&amp;lt;include&amp;gt;**/*.so.*&amp;lt;/include&amp;gt;&amp;lt;/includes&amp;gt;&amp;lt;/resource&amp;gt;&amp;lt;/resources&amp;gt;&amp;lt;/build&amp;gt;依赖 显示依赖关系 # 在控制台显示依赖树mvn dependency:tree -Dverbose# 输出到文件mvn dependency:tree -Dverbose -DoutputFile=/home/xulz/maven-dependencies显示依赖新版本 mvn versions:display-dependency-updates依赖本地库 &amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;com.xulizhao.demo&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;mylib&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;1.0&amp;lt;/version&amp;gt;&amp;lt;scope&amp;gt;system&amp;lt;/scope&amp;gt;&amp;lt;systemPath&amp;gt;${project.basedir}/libs/mylib-0.0.1-SNAPSHOT.jar&amp;lt;/systemPath&amp;gt;&amp;lt;/dependency&amp;gt;指定版本 &amp;lt;dependency&amp;gt;&amp;lt;groupId&amp;gt;net.sf.json-lib&amp;lt;/groupId&amp;gt;&amp;lt;artifactId&amp;gt;json-lib&amp;lt;/artifactId&amp;gt;&amp;lt;version&amp;gt;2.4&amp;lt;/version&amp;gt;&amp;lt;classifier&amp;gt;jdk15&amp;lt;/classifier&amp;gt;&amp;lt;/dependency&amp;gt;插件 常用插件  maven-source-plugin: 打包源码 maven-surefire-plugin : 多线程加速测试执行 maven-git-commit-id-plugin: 附带git版本信息  使用技巧 库检索  官方中央仓库 另一个仓库: 速度更快些  镜像 以使用阿里云为例，修改下面的其中一个配置
 ~/.m2/settings.xml maven根目录下的conf文件夹中的setting.xml文件  内容如下：
&amp;lt;settings xmlns=&amp;#34;http://maven.apache.org/SETTINGS/1.1.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/SETTINGS/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd&amp;#34;&amp;gt; &amp;lt;mirrors&amp;gt; &amp;lt;mirror&amp;gt; &amp;lt;id&amp;gt;alimaven&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;aliyun Central&amp;lt;/name&amp;gt;&amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public/&amp;lt;/url&amp;gt;&amp;lt;mirrorOf&amp;gt;central&amp;lt;/mirrorOf&amp;gt;&amp;lt;/mirror&amp;gt;&amp;lt;/mirrors&amp;gt;&amp;lt;/settings&amp;gt;资源  maven官网 Maven for building Java applications - Tutorial  其他构建系统
 Pants构建系统: Python实现的多语言支持项目构建 Buck:Facebook开源快速模块构建工具，java实现。rule/target/file(BUCK) </content>
    </entry>
    
     <entry>
        <title>Python的Unicode使用</title>
        <url>https://xulizhao.com/blog/python-unicode/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 在做数据处理时，通常会遇到Unicode的问题。 这里对python的编码问题做简单的总结。
基础 一个字符character不是一个字节byte
unicode是一个字符数据库,每个字符对应的唯一数字被称为code point
字符编码encoding定义字符和字节表示之间的映射
python的几类字符  原始字符串操作符(r/R) Unicode字符串操作符(u/U) 特殊字符和控制字符 Unicode  python的三种字符类型定义  &amp;lsquo;unicode&#39;代表unicode strings (text strings) &amp;lsquo;str&amp;rsquo; 代表 byte strings (binary data) &amp;lsquo;basestring&amp;rsquo;, str和unicode的父类  python默认编码ASCII,该编码被用到str()和unicode()及任何涉及转换到字符型的函数上
用sys.setdefaultencoding()修改默认编码只是掩盖了问题.
正确的解决方式:
 All text strings, everywhere should be of type unicode, not str. If you&#39;re handling text, and your variable is a str, it&#39;s a bug! To decode a byte string as text, use var.decode(encoding) (eg, var.decode(&amp;lsquo;utf-8&amp;rsquo;), with the correct encoding. To encode a text string as bytes, use var.encode(encoding). Never ever use str() on a unicode string, or unicode() on a byte string without a second argument specifying the encoding. Whenever you read data from outside your app, expect it to be bytes - eg, of type str - and call .decode() on it to interpret it as text. Likewise, always call .encode() on text you want to send to the outside world. If a string literal in your code is intended to represent text, it should always be prefixed with &amp;lsquo;u&amp;rsquo;. In fact, you probably never want to define a raw string literal in your code at all.  str是字节串，由unicode经过编码(encode)后的字节组成的
unicode才是真正意义上的字符串，由字符组成
str.decode/unicode.encode
大致处理步骤  外部输入编码，decode转成unicode 处理(内部编码，统一unicode) encode转成需要的目标编码  py文件默认编码是ASCII # -*- coding: utf-8 -*-  #coding=utf-8  系统默认编码 import syssys.getdefaultencoding()# 不推荐使用sys.setdefaultencoding()` 文件编码检测 import chardetchardet.detect(...)Console/控制台 Python使用用户的locale (Linux/OS X/Un*x) 或 codepage (Windows) 设置该值.
sys.stdout.encoding PYTHONIOENCODING=&amp;#34;UTF-8&amp;#34; 参考  Getting unicode right in Python More About Unicode in Python 2 and 3 </content>
    </entry>
    
     <entry>
        <title>Python编码规范和风格</title>
        <url>https://xulizhao.com/blog/python-style/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 用Python很多年，可感觉学的比较碎片，整理下之前的笔记。 学而时习之。
py代码 ### 文件第一行加shebang #!/usr/bin/env python3 ### 源代码编码Unicode 支持 # -*- coding: UTF-8 -*- REST接口  API Creation  一些规范参考  PEP8 代码风格 Google Python Style Guide Pallets Python Styleguide </content>
    </entry>
    
     <entry>
        <title>Python高级笔记</title>
        <url>https://xulizhao.com/blog/python-advance/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 用Python很多年，可感觉学的比较碎片，整理下之前的笔记。 学而时习之。
类和面向对象 new()构造器可以实例化不可变对象，必须返回一个合法的实例
实例属性和类属性：
 两种不同属性，类属性和实例无关 不要从实例修改可变的类属性 类属性的修改会影响所有实例  类变量使用场合:
 用做常量: 被所有实例使用. 对于类变量的修改,会反映到所有实例. 方便通过类直接访问  变量的查找顺序为: 实例 &amp;gt; 类 &amp;gt; 基类
绑定binding：
 没有实例时方法就是未绑定的 self用于类实例方法中引用方法所绑定的实例 还没有实例且需要调用一个非绑定方法时必须传递self, 比如覆盖父类方法  静态方法和类方法  @classmethod： 函数参数是类对象而不是实例对象. 如果涉及工厂方法,应该使用类方法而不是静态方法. @staticmethod： 通常，有很多情况下一些函数与类相关，但不需要任何类或实例变量就可以实现一些功能. mixin 类：对两个完全不相关的类进行多重继承(联合)  如果需要在多个模块共享全局变量,通常使用模块如config.py实现.因此模块是单例设计模式的基本实现.
新式类的高级特征  __slots__类属性 描述符  get(), set(), delete() getattribute()特殊方法 优先级别  类属性 数据描述符 实例属性 非数据描述符 默认为__getattr__()   属性和@property   元类和__metaclass__  区别：
 getattr(): 获取属性;内建getattr();仅当属性没有找到时调用 getattribute(): 获取属性;内建getattr(); 总是被调用  与类相关模块:
 UserList, UserDict, UserString types operator  ABC:Abstract Base Classes import abc
函数式 iterator  itertools.islice  网络 socket  socket.getdefaulttimeout():返回超时设置，默认为None（没有超时检查） socket 一旦设置了timeout, 就进入了 non-blocking 工作模式。在设置之后要将再次调用settimeout(None)来设置socket进入阻塞模式。  网络错误处理
Q: error: [Errno 11] Resource temporarily unavailable
A: A &amp;ldquo;Broken Pipe&amp;rdquo; error occurs when you try to write to a pipe that has been closed on the other end.
try:...except IOError as e:if e.errno == errno.EPIPE:# Handle error import errno, os&amp;gt;&amp;gt;&amp;gt; errno.EAGAIN, errno.EWOULDBLOCK&amp;gt;&amp;gt;&amp;gt; os.strerror(errno.EAGAIN)&amp;#39;Resource temporarily unavailable&amp;#39;多线程 进程、线程和协程的关系：
 多进程能够利用多核优势，但是进程间通信比较麻烦，另外，进程数目的增加会使性能下降，进程切换的成本较高。程序流程复杂度相对I/O多路复用要低。 I/O多路复用是在一个进程内部处理多个逻辑流程，不用进行进程切换，性能较高，另外流程间共享信息简单。但是无法利用多核优势，另外，程序流程被事件处理切割成一个个小块，程序比较复杂，难于理解。 线程运行在一个进程内部，由操作系统调度，切换成本较低，另外，他们共享进程的虚拟地址空间，线程间共享信息简单。但是线程安全问题导致线程学习曲线陡峭，而且易出错。 协程有编程语言提供，由程序员控制进行切换，所以没有线程安全问题，可以用来处理状态机，并发请求等。但是无法利用多核优势（通过协程&#43;进程的方式来解决）。  concurrent.futures 仿Java实现，执行并行任务
 ThreadPoolExecutor ProcessPoolExecutor  GIL(Global Interpreter Lock) Python的内存管理不是 线程安全的，所以GIL被创造出来避免多线程同时运行同一个Python代码
异步IO  asyncio 内置库 Trio  Curio另一种实现，偏底层  gevent  非阻塞的网络协程库，基于系统底层的libev事件库. hub（可以理解为MainThread）对应event loop. gevent.spawn(func, args):创建一个greenlet,并将该greenlet的switch()加入hub主循环回调 join会保存当前greenlet.switch到一个队列中，并注册_notify_links回调，然后切换到hub，在_notify_links回调中将依次调用先前注册在队列中的回调。 事件(event)是一个在Greenlet之间异步通信的形式。事件对象的一个扩展是AsyncResult，它允许你在唤醒调用上附加一个值。 它有时也被称作是future或defered，因为它持有一个指向将来任意时间可设置 为任何值的引用。 范围为1的信号量也称为锁(lock)，它向单个greenlet提供了互斥访问。 信号量和锁常常用来保证资源只在程序上下文被单次使用。 上下文切换即两个子任务之间的切换。  # 放在文件头，其他导入语句前 # 会替换线程为greenlets from gevent.monkey import patch_allpatch_all()from gevent import getcurrentid(getcurrent())高级特性 Decorator 类似于macros宏和Java中的annotations,目的是提供一种修改语言元素的方式，是metaclasses(元类)的简单替代。
可以注入或修改函数和类的代码，类似于Java的Aspect-Oriented Programming (AOP)，可以放在函数的入口或出口用作security, tracing, locking等。
 Class修饰符的实现要定义__call__ 不带参数的类修饰符：init(), call() 带参数的类修饰符 带参数的函数修饰符: 需要三次嵌套,最里层是实际的替代函数。这种情况尽量用带参数的类修饰符实现  Context Manager from contextlib import contextmanager@contextmanagerdef tag(name):# 必须返回一个generator类型的iterator对象 yield其他 ctypes 支持的Python内置类型：None, integers, longs, byte strings, unicode strings
 None 作为C空指针传递 byte strings and unicode strings are passed as pointer to the memory block that contains their data (char * or wchar_t *). Python integers and longs are passed as the platforms default C int type, their value is masked to fit into the C type. create_string_buffer / create_unicode_buffer() 创建可变内存块 类转为自定义类型: self.as_parameter = number 或使用property() 指定参数格式 func_name.argtypes = [,,] from_param()实现类方法 返回类型 : 默认为int, 用.restype 指定其他类型 传递指针: byref (更高效)/ pointer(会构建指针)   定义的类是Structure或Union的子类,定义的_fields_ 必须是 a list of 2-tuples 包含名字和类型 回调: CFUNCTYPE(返回类型) 访问动态库的值 type.in_dll(pythonapi, )  扩展阅读
 与C/C&#43;&#43;库交互: swig不能处理指针？ pybind11 : Seamless operability between C&#43;&#43;11 and Python Decompyle&#43;&#43;: A Python Byte-code Disassembler/Decompiler </content>
    </entry>
    
     <entry>
        <title>Python基础笔记</title>
        <url>https://xulizhao.com/blog/python-core/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 用Python很多年，可感觉学的比较碎片，整理下之前的笔记。 学而时习之。
Python语言基础 语法  那些可以改变对象值的可变对象方法是没有返回值的  约定和语法
 4空格对其 一行一个语句，没有； 使用\分割长语句，（和，除外 大小写敏感 只有类名是TitleCased，通常全小写 常量全大写  数据类型 字符串  string.uppercase  import randomimport string&amp;#39;&amp;#39;.join(random.choice(string.ascii_uppercase &#43; string.digits) for _ in range(40))import uuid;str(uuid.uuid4().get_hex().upper()[0:6])格式化 ### 用元组或字典作参数 %(error)s %dictionary### 时间转换成字符串 time.strftime(&amp;#34;%Y%m%d%H%M%S&amp;#34;, time.localtime())### 数字转换成字符串并填充位数 &amp;#39;{:07}&amp;#39;.format(1)&amp;#39;{:.0f}&amp;#39;.format(1.0)### 转换为16进制 str.encode(“hex”)&amp;#34;61”.decode(“hex”) 元组 单元素元组应在末尾添加&amp;rsquo;，&amp;lsquo;否则会被作为分组操作符
Lists 是可变的,而strings不是
 &#43;= INPLACE_ADD str.iadd 会复制,但是list.iadd 会改变  deque 双端队列  List更适合固定大小; deque支持性能更好的append/pop, 可设定最大队列.  分支控制 # if-else 单值的简洁写法 # value_when_true if condition else value_when_false &amp;#39;Yes&amp;#39; if fruit == &amp;#39;Apple&amp;#39; else &amp;#39;No&amp;#39;常用模块 常用内置函数 信息、帮助类
 dir() help() type() getattr(object, name[, default])  操作类
 int(), str() range() input()/对于py2的raw_input() zip([iterable, &amp;hellip;]) : returns a list of tuples map(function, iterable, &amp;hellip;): 在每个元素应用函数并返回结果列表 sorted(student_tuples, key=itemgetter(2), reverse=True)  from operator import itemgetter, attrgetteritemgetter = object[item]attrgetter = object.attr字符处理  textwrap.dedent codecs: 编解码注册及基类  文件系统,I/O 常用模块
 shutil: 上层文件操作 glob: unix查找规则的文件匹配  os.path  join(dir, file) basename(), dirname() splitext() os.path.expanduser(&amp;lsquo;~&amp;rsquo;) 用户主目录  os.walk(&amp;#39;.&amp;#39;).next()[1]网络I/O import urllib.request# 下载文件 urllib.request.urlretrieve(url, file_name)uuid1: 产生唯一字符, 和机器的mac地址关联以确保不会跨机器冲突,和时间戳有关
配置 configparser模块
 值没有数据类型,默认存储为字符串型：getboolean、getint、getfloat DEFAULT部分提供所有其他section的默认值 section名是大小写敏感，但key不区分大小写并以小写存储 尽量不使用行内注释  学习大纲 基础  String, List, Dictionary Loops and Condition File I/O Functions Classes  资源  格式化字符串 </content>
    </entry>
    
     <entry>
        <title>reborn</title>
        <url>https://xulizhao.com/read/reborn/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> &amp;ldquo;书籍是人类的好朋友&amp;rdquo;,这是句真理. 在如今信息爆炸,碎片充斥的年代,一年读十几/几十本书已成奢谈.
在手机上碎片阅读李笑来老师的书可追溯到几年前的&amp;lt;把时间当作朋友&amp;gt;,去年是&amp;lt;成长-YC创业课读书笔记&amp;gt;, 最近还在读的是&amp;lt;新生-七年就是一辈子&amp;gt;.
笑来老师的书部部精品,还有正版免费可读,你还奢求什么.
新生里的话题有的在成长已经提过,最近读到人成长和计算机升级的类比,觉得很是经典.
计算机硬件的升级对应人身体的锻炼,保持健康更新; 而更频繁的软件升级则对应人脑的学习成长提高. 如果人拒绝学习提高,和老古董电脑就没啥区别了,想来也是每个人不乐意看到的.
近十几年的计算机行业高速发展,极大的改变了人的生活方式,带来了社会的巨大进步. 这个行业汇聚着许多顶级聪明的人, 有优秀的产品可用, 开源的代码可学习.
没有理由不更新自己,去关注自己实质的成长. 而不是活在信息过载里,碎片虚无里.
工作的有趣有意义,自身的提升和价值的提高, 进一步改善生活, 应该生活在一个正循环里.
</content>
    </entry>
    
     <entry>
        <title>Go In Action</title>
        <url>https://xulizhao.com/play/blog-hugo/</url>
        <categories>
          <category>play</category>
        </categories>
        <tags>
          <tag>blog</tag>
        </tags>
        <content type="html"> 更新下关于静态博客Hugo的旧文, 本博客现在就是使用Hugo生成.
最早知道Hugo是在听完&#39;内核恐慌&#39;播客的一期节目,其实之前已经通过Github Pages试用过几个静态博客系统.
最近几个月一直强迫自己用Github和Markdown做学习记录.
BTW,喜欢折腾的同学, 可以通过StaticGen这个汇总站点进一步了解更多静态博客.
Hugo笔记  内部链接  </content>
    </entry>
    
</search>