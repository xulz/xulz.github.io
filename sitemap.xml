<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
    
     <entry>
        <title>开源反向代理及负载均衡Envoy初探</title>
        <url>/blog/envoy-proxy/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>microservice</tag>
        </tags>
        <content type="html"> Envoy是Lyft于2017年开源的网络反向代理工具,现属于CNCF基金会的毕业项目.
和Nginx和HAProxy相比,功能更强大,开源更彻底(提供的许多功能是其他产品的付费功能).
更重要的是作为新兴代理,与微服务紧密结合,可以做入口代理/边缘代理/中间代理等. 流行的Service Mesh框架istio就是基于Envoy构建而成.
Envoy本身用C&#43;&#43;开发,并发模型与Nginx类似,具有很高的处理性能.
本文尽量脱离微服务和Service Mesh,聚焦于Envoy代理本身所提供的丰富功能.

部署和使用 官方提供两种部署方式.
本地编译 在Ubuntu 18.04下编译,具体参考官方说明.
安装bazel参考这里
# 安装依赖 apt-get install ninja-build # 本地编译 bazel build //source/exe:envoy-static 编译后的文件位于 /bazel-bin/source/exe/envoy-static
使用docker容器的方式 快速验证
docker pull envoyproxy/envoy-dev:8d1ad35aa724962f64f7535531e408c9a93d364c docker run --rm -d -p 10000:10000 envoyproxy/envoy-dev:8d1ad35aa724962f64f7535531e408c9a93d364c # 默认使用10000端口 curl -v localhost:10000 定制和扩展 基于配置规则创建自己的envoy.yaml
# Dockfile FROM envoyproxy/envoy-dev:8d1ad35aa724962f64f7535531e408c9a93d364c COPY envoy.yaml /etc/envoy/envoy.yaml 构建新的定制镜像
docker build -t envoy:v1 . # 9901为管理端口 docker run -d --name envoy -p 9901:9901 -p 10000:10000 envoy:v1 curl -v localhost:10000 配置 静态配置文件默认位于 /etc/envoy/envoy.yaml
动态配置 动态配置支持文件和API(配置服务器)两种方式.
基于文件的动态配置 参考文档: 动态配置路由
配置服务器实现 官方提供了Go和Java两个默认实现
监控和统计 参考文档: Envoy&#43;Prometheus&#43;Grafana实现/Demo代码
分流/蓝绿发布/流量复制 Traffic mirroring/shadowing: 用于生产环境服务的验证测试, 镜像功能发送一部分生产流量副本到镜像服务,镜像请求采用fire&amp;amp;forgot模式,响应被丢弃.
参考  官方:流量迁移和分离 流量复制示例  扩展阅读 与其他代理的比较  与其他主流代理的比较 traefik反向代理/负载均衡: Go实现,支持kubernetes编排服务和etcd/consul服务注册  学习资源  kata在线实验环境 基础 learnenvoy: 不再维护  应用  eBay是如何将 Envoy 作为边缘代理的   将硬件负载均衡器替换为软件解决方案,在每个集群的边缘上有一个“north-south”网关，用来管理所有针对外部的传入和传出流量.
</content>
    </entry>
    
     <entry>
        <title>bazel构建工具</title>
        <url>/blog/bazel-build/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>build</tag>
        </tags>
        <content type="html"> Bazel是Google开源的一个构建系统,主要支持分布式缓存和增量编译,使得大项目的构建更快速, 主要用于C&#43;&#43;,Java,Go等服务端项目构建.
有一个与之类似的快速构建系统Buck(Facebook开源)则更关注于Android和iOS客户端的构建. 两者都倾向于mono repo(而非基于项目的仓库)的构建.
之前看了眼官方教程,觉得过于复杂没有引起兴趣. 最近看到在B站代码和envoy都作为标配,所以再做些深入了解.

使用基础 在项目的根目录下创建WORKSPACE和BUILD文件.
工作区/WORKSPACE配置 bazel有工作区的概念, 该文件配置加载bazel环境需要的规则和依赖,可以为空.
### BUILD配置 构建项目信息配置文件,语法类似于python.
java_binary( name = &amp;#34;ProjectRunner&amp;#34;, srcs = [&amp;#34;src/main/java/com/example/ProjectRunner.java&amp;#34;], main_class = &amp;#34;com.example.ProjectRunner&amp;#34;, deps = [&amp;#34;:greeter&amp;#34;], ) java_library( name = &amp;#34;greeter&amp;#34;, srcs = [&amp;#34;src/main/java/com/example/Greeting.java&amp;#34;], visibility = [&amp;#34;//src/main/java/com/example/cmdline:__pkg__&amp;#34;], ) visibility = level属性改变目标的可见范围, 在上面的例子中需要改变默认当前BUILD的限制,因为用到了其他BUILD配置.
构建命令 bazel build //:ProjectRunner 构建后将生成一些输出目录的符号链接,如bazel-bin和bazel-out.
可部署 # 默认不会包含依赖,而采用加入CLASSPATH的方式确保本地可以运行 bazel build //src/main/java/com/example/cmdline:runner # jar tf bazel-bin/src/main/java/com/example/cmdline/runner.jar # 如果要求可部署,需要加_deploy后缀 bazel build //src/main/java/com/example/cmdline:runner_deploy.jar Go项目构建 WORKSPACE文件 加载Go规则,使用gazelle自动生成/更新BUILD文件.
load(&amp;#34;@bazel_tools//tools/build_defs/repo:http.bzl&amp;#34;, &amp;#34;http_archive&amp;#34;) http_archive( name = &amp;#34;io_bazel_rules_go&amp;#34;, urls = [&amp;#34;https://github.com/bazelbuild/rules_go/releases/download/0.18.5/rules_go-0.18.5.tar.gz&amp;#34;], sha256 = &amp;#34;a82a352bffae6bee4e95f68a8d80a70e87f42c4741e6a448bec11998fcc82329&amp;#34;, ) http_archive( name = &amp;#34;bazel_gazelle&amp;#34;, urls = [&amp;#34;https://github.com/bazelbuild/bazel-gazelle/releases/download/0.17.0/bazel-gazelle-0.17.0.tar.gz&amp;#34;], sha256 = &amp;#34;3c681998538231a2d24d0c07ed5a7658cb72bfb5fd4bf9911157c0e9ac6a2687&amp;#34;, ) load(&amp;#34;@io_bazel_rules_go//go:deps.bzl&amp;#34;, &amp;#34;go_rules_dependencies&amp;#34;, &amp;#34;go_register_toolchains&amp;#34;) go_rules_dependencies() go_register_toolchains() load(&amp;#34;@bazel_gazelle//:deps.bzl&amp;#34;, &amp;#34;gazelle_dependencies&amp;#34;) gazelle_dependencies() BUILD配置文件 添加
load(&amp;#34;@bazel_gazelle//:def.bzl&amp;#34;, &amp;#34;gazelle&amp;#34;) # 更新为对应项目名 gazelle( name = &amp;#34;gazelle&amp;#34;, prefix = &amp;#34;bazeltest&amp;#34;, ) 生成配置文件
 bazel run //:gazelle
 注: 在我本地测试时,没有自动生成go_binary相关配置, 则需要更新配置如下:
load(&amp;#34;@io_bazel_rules_go//go:def.bzl&amp;#34;, &amp;#34;go_binary&amp;#34;,&amp;#34;go_library&amp;#34;, &amp;#34;go_test&amp;#34;) go_binary( name = &amp;#34;bazeltest&amp;#34;, srcs = [&amp;#34;main.go&amp;#34;], deps = [&amp;#34;:go_default_library&amp;#34;], # embed = [&amp;#34;:go_default_library&amp;#34;], # visibility = [&amp;#34;//visibility:public&amp;#34;], # out = &amp;#34;cmd&amp;#34;, ) 构建 # // 来表示当前项目的根目录， ... 表示当前路径下所有的包 bazel build //... # 指定目标 bazel build //cmd/bazeltest 扩展阅读  官方教程Java/C&#43;&#43; 使用 Bazel 构建 Golang 项目 用 Bazel / Buck 构建大型项目 </content>
    </entry>
    
     <entry>
        <title>Go依赖库管理初探</title>
        <url>/blog/go-mod/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go作为一个新语言,其依赖管理系统一直不够完善,官方直到去年才在1.11加入modules(也叫vgo). 在此之前社区不满官方的官僚,还有过一阵激烈的讨论,讨论流行第三方库dep的不被采纳而官方自造轮子.
最近在项目首次使用了modules系统,但还是采用的兼容的vendor模式. 总体用下来还不错,一些github库也已经使用该方式.
下面简要列下常见用法.

开启该选项 环境变量设置为开启状态: GO111MODULE=on
如果使用Goland IDE, 到项目 [settings]-[Go modules(vgo)]- 勾选 &amp;ldquo;Enable Go modules(vgo) integration&amp;rdquo;
使用 主要通过命令 go mod 实现, 具体用法参考 go help mod
常用命令 # 列出当前模块和它的所有依赖库 go list -m all lists # 列出详细依赖信息 go list -m -json all # 查看某库的可用版本 go list -m -versions github.com/BurntSushi/toml # 删除不用的依赖 go mod tidy 使用vendor管理本项目依赖 注: 需要说明的,这些依赖只包含本项目用到的直接依赖, 第三方库的自身依赖由它本身维护.
# 生成本地依赖 go mod vendor # 构建时指定vendor go build -mod=vendor #或者  GOFLAGS=-mod=环境变量信息 语义化版本维护库 semantic import versioning的支持.
# 把模块路径定义为类似 rsc.io/quote/v3 的格式 版本管理 vendor目录和go.mod , go.sum文件都应该提交至版本库.
扩展阅读  官方博客介绍 官方wiki介绍 </content>
    </entry>
    
     <entry>
        <title>Go in Action 学习笔记</title>
        <url>/blog/go-in-action/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>go</tag><tag>read</tag>
        </tags>
        <content type="html"> 初学Go时主要读的&amp;lt;Go语言圣经&amp;gt;,正式中文版叫&amp;lt;Go程序设计语言&amp;gt;, 由于当时写的代码还很少,实际上很多是不太懂的或后来也忘了.
之后想读些其他书时,本来想读的&amp;lt;Go编程实战&amp;gt;在豆瓣的评分偏低,便一直没读. 在写过一些代码后,偶然再读这本书,发现其实战意义很高,是很好的一本进阶书.
由此看来豆瓣的评分只能当个参考,需要读读看是不是适合自己.
 做了些简单的笔记. 顺便说, 第一作者的Ultimate Go虽然是英文视频,讲的也很好很深入,有需要的可联系我.
读书笔记 Go特点和约定 在Go语言中，所有的变量都以值的方式传递。
命名惯例: 如果接口类型只包含一个方法，那么这个类型的名字以er结尾。
将工厂函数命名为New是Go语言的一个习惯。
因为大部分方法在被调用后都需要维护接收者的值的状态，所以，一个最佳实践是，将方法的接收者声明为指针。
并发 推荐使用WaitGroup(计数信号量)来跟踪goroutine的工作是否完成。
写并发程序的时候，最佳做法是，在main函数返回前，清理并终止所有之前启动的goroutine。
包 所有处于同一个文件夹里的代码文件，必须使用同一个包名。(按惯例,包和文件夹同名)
init函数在main之前执行, init函数用在设置包、初始化变量或者其他要在程序运行前优先完成的引导工作。
可以在指定包的时候使用通配符。3个点表示匹配所有的字符串。
第四章: 数组,切片和映射 主要介绍了集合数据结构:
数组: 长度固定,类型的相同的连续块.
切片: 动态数组
切片之所以被称为切片，是因为创建一个新的切片就是把底层数组切出一部分
slice := make([]int,3,5) slice := []string{&amp;#34;red&amp;#34;,&amp;#34;blue&amp;#34;} //创建有3个元素的整型数组 array:=[3]int{10,20,30} //创建长度和容量都是3的整型切片 slice:=[]int{10,20,30} nil切片和空切片是两个东西.
 在需要描述一个不存在的切片时，nil切片会很好用。 想表示空集合时空切片很有用  //创建有5个元素的整型数组 array:=[5]int{10,20,30,40,50} //创建一个新切片,其长度为2个元素，容量为4个元素 newSlice:=slice[1:3] // 生成新切片是限制第三个参数容量和长度一样,避免新切片的append操作改变原底层数组值 source:=[]string{&amp;#34;Apple&amp;#34;,&amp;#34;Orange&amp;#34;,&amp;#34;Plum&amp;#34;,&amp;#34;Banana&amp;#34;,&amp;#34;Grape&amp;#34;} slice := source[2:3:3] slice = append(slice,&amp;#34;Kiwi&amp;#34;) // 追加s2的所有值到s1 append(s1,s2...)  常用函数:append, cap, len
range 关键字range可以用于迭代数组、字符串、切片、映射和通道。
range迭代切片,返回的第二个值是对应元素值的副本
映射 是存储键值对的无序集合(散列表实现).
常用函数: delete.
将切片或者映射传递给函数成本很小，并且不会复制底层的数据结构。
第五章: 类型系统 使用组合设计模式,复用其他类型的功能. 一个类型通常由其他更小的类型组合而(避免使用复杂的继承模型).
关键字func和函数名之间的参数被称作接收者，将函数与接收者的类型绑在一起。如果一个函数有接收者，这个函数就被称为方法。
值接收者使用值的副本来调用方法，而指针接受者使用实际值来调用方法。
 内置(原始)类型: 数值类型(整型,浮点型),字符串类型,布尔类型 引用类型: 切片,映射,通道,接口,函数类型  类型的本质 大多数情况下,结构类型的本质是非原始的,需要使用指针来共享这个值.
类型的值具备非原始的本质，所以总是应该被共享，而不是被复制。
是使用值接收者还是指针接收者，不应该由该方法是否修改了接收到的值来决定。这个决策应该基于该类型的本质。 这条规则的一个例外是，需要让类型值符合某个接口的时候，即便类型的本质是非原始本质的，也可以选择使用值接收者声明方法。这样做完全符合接口值调用方法的机制。
因为不是总能获取一个值的地址，所以值(Value)的方法集(Method Receivers)只包括了使用值接收者实现的方法。
接口 是声明了一组行为并支持多态的类型。
接口允许对行为(而不是类型)建模. Go的接口更小,只倾向于定义一个单一的动作.
如果要让一个用户定义的类型实现一个接口，这个用户定义的类型要实现接口类型里声明的所有方法。
嵌入类型 嵌入类型提供了扩展类型的能力，而无需使用继承。
嵌入类型是将已有的类型直接声明在新的结构类型里。被嵌入的类型被称为新的外部类型的内部类型。
由于内部类型的提升，内部类型实现的接口会自动提升到外部类型。如果外部类型实现了notify方法，内部类型的实现就不会被提升。
扩展阅读  书籍配套代码 作者博客 Ultimate Go 培训 文档 /大纲 </content>
    </entry>
    
     <entry>
        <title>Django再记录</title>
        <url>/blog/django/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag><tag>web</tag>
        </tags>
        <content type="html"> Django作为python web开发第一框架,很早就有所了解, 上次使用是在3年多之前. 作为全栈框架来说,是个很优秀的框架.
据我所知Instagram,Mozilla等高流量/大公司都在使用.
之前几个项目特意使用了以轻量著称的Flask,两者算是各有千秋吧.
去年Django2.0推出后一直想尝试,正好最近拿来试试.
用下来感觉简化部署和可定制化相比之前改观很多,做下简要笔记. manage.py命令行工具 Django的工具真的好用很多.
# 创建项目mysite django-admin startproject mysite # 运行开发服务器,也可指定IP/端口 # python manage.py runserver 0:8000 python3 manage.py runserver # 指定配置 --settings SETTINGS  # 创建应用 python3 manage.py startapp polls # 创建超级管理员 python3 manage.py createsuperuser shell交互式命令行 python3 manage.py shell 升级/migration # 为 INSTALLED_APPS 创建必要的数据表 python3 manage.py migrate # makemigrations命令会检测对模型的修改并生成迁移文件,位于migrations文件夹 python3 manage.py makemigrations polls 开发基础 提倡开发可重用的app, 主要基于Model/View/URL 模式.
App 添加应用
# mysite/settings.py INSTALLED_APPS = [ &amp;#39;polls.apps.PollsConfig&amp;#39;,# polls/app.py # verbose_name 对应页面显示名称 class PollsConfig(AppConfig): name = &amp;#39;Polls&amp;#39; verbose_name = &amp;#39;My Polls&amp;#39; Model # polls/models.py class Poll(models.Model): name = models.CharField(max_length=256, verbose_name=&amp;#39;Poll Name&amp;#39;) created = models.DateTimeField(auto_now_add=True) updated = models.DateTimeField(auto_now=True) class Meta: verbose_name = &amp;#39;Poll Display Name&amp;#39; View # polls/views.py from django.shortcuts import render,redirect from django.http import HttpResponse from django.contrib.auth.decorators import login_required # @login_required def index(request): return HttpResponse(&amp;#34;Welcome.&amp;#34;) 添加路由/urls 注: Django2.x里的re_path() 等价于之前的url()
# mysite/urls.py urlpatterns = [ path(&amp;#39;polls/&amp;#39;, include(&amp;#39;polls.urls&amp;#39;)), path(&amp;#39;admin/&amp;#39;, admin.site.urls), Admin定制 添加model到Admin # polls/admin.py class PollsAdmin(admin.ModelAdmin): list_display = (&amp;#39;name&amp;#39;,&amp;#39;updated&amp;#39;) search_fields = [&amp;#39;name&amp;#39;] fieldsets = [ (None, {&amp;#39;fields&amp;#39;: [&amp;#39;name&amp;#39;]}), ] admin.site.register(Polls, PollsAdmin) 丰富显示 # 自定义list_filter from django.contrib.admin import SimpleListFilter 内置关联: InlineModelAdmin 的两个子类TabularInline和StackedInline
修改Admin显示 # mysite/urls.py # 以最简方式修改标题等 admin.site.site_header = &amp;#39;Test header&amp;#39; admin.site.site_title = &amp;#39;Test title&amp;#39; admin.site.index_title = &amp;#39;Test index&amp;#39; Admin功能扩展 高级功能定制经常用到的类:
django.contrib.admin.sites.AdminSite django.contrib.admin.options.ModelAdmin django.forms.models.ModelForm django.contrib.admin.options.InlineModelAdmin django.forms.formsets 模板 在项目文件夹创建templates存放模板文件
# settings.py TEMPLATE_DIR = os.path.join(BASE_DIR, &amp;#39;templates&amp;#39;) TEMPLATES = [ { &amp;#39;BACKEND&amp;#39;: &amp;#39;django.template.backends.django.DjangoTemplates&amp;#39;, &amp;#39;DIRS&amp;#39;: [TEMPLATE_DIR], ... 常用模板:
admin/base.html admin/index.html admin/change_form.html admin/change_list.html 可重载模板:
基于项目的: admin/change_form.html 基于app的: admin/&amp;lt;my_app&amp;gt;/change_form.html 基于模型的: admin/&amp;lt;my_app&amp;gt;/&amp;lt;my_model&amp;gt;/change_form.html 要点:
 使用extend而不是 重载/override 使用 {{ block.super }} 扩展 blocks 如果涉及模板的递归,使用软链接的方式 在base.html扩展全局通用块  配置 配置文件 指定配置文件: 用 DJANGO_SETTINGS_MODULE环境变量
# 在Python代码中使用settings # settings是对象而非模块，不要运行时修改 from django.conf import settings  邮件配置 # 设置邮件后端为Console用于测试目的 # EMAIL_BACKEND = &amp;#39;django.core.mail.backends.console.EmailBackend&amp;#39; EMAIL_HOST = &amp;#39;smtp.exmail.qq.com&amp;#39; EMAIL_PORT = &amp;#39;465&amp;#39; EMAIL_HOST_USER = &amp;#39;demo@xulizhao.com&amp;#39; EMAIL_HOST_PASSWORD = &amp;#39;xxxxxxxx&amp;#39; EMAIL_USE_SSL = True DEFAULT_FROM_EMAIL = &amp;#39;demo@xulizhao.com&amp;#39; 部署 总体使用Nginx&#43;gunicorn&#43;wsgi的方式部署生产环境.
生产环境一定要修改settings.py为DEBUG = False
静态文件 # settings.py STATIC_ROOT = &amp;#39;/home/xulz/www/mysite/static/&amp;#39; 之后运行
# 首次部署运行 # 或静态文件更新后运行 ./manage.py collectstatic gunicorn 之前用Apache&#43;wsgi的方式部署,相对麻烦. 这次直接使用gunicorn, 简单到再也不想提Apache.
# -D 常驻进程 # -b 可指定IP/端口 # -w 8 可指定worker进程数 gunicorn -D mysite.wsgi --log-file=log.txt --access-logfile=access.log --log-level=info Nginx server { listen 8000; server_name localhost; location / { proxy_pass http://127.0.0.1:8000; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $http_host; } location /static { autoindex on; alias /home/xulz/www/mysite/static; } } 链接 官方文档:
 多语言 设计理念  第三方应用:
 django-registration / 使用教学 DjangoPackages: 第三方app扩展汇总网站  扩展阅读:
 Customizing the Django Admin Slide  其他:
 gunicorn po文件编辑
 </content>
    </entry>
    
     <entry>
        <title>Mindset读书笔记</title>
        <url>/blog/mindset/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> Mindset是一本讲思维模式的书,作者是斯坦福大学心理学教授, 与其说这是一本心理学或成功学著作, 更重要的这是一本很好的教育理念的书, 当然对于个人的成长也是很有帮助的.
好多年前看到有人推荐这边书,当时只知道英文名字,英文版读起来也很慢. 后来才知道原来已有中译版, 人邮的&amp;lt;心理定向与成功 &amp;gt;,中信的&amp;lt;看见成长的自己 &amp;gt;和最新后浪的&amp;lt;终身成长&amp;gt;其实都是这本书.
之前只看了开头几章, 也许好书你很难错过,因为总会看到有人推荐,于是最近开始继续阅读.

概要 本书以作者10多年的研究表明我们获得的成功并不是能力和天赋决定的，更受到我们在追求目标的过程中展现的思维模式的影响。
我们通常具有两种思维模式中的一种：固定型或成长型，它们体现了应对成功与失败、成绩与挑战时的两种基本心态。
你认为才智和努力哪个重要，能力能否通过努力改变，决定了你是会满足于既有成果还是会积极探索新知。只有用正确的思维模式看待问题，才能更好地达成人生和职业目标。
通过了解自己的思维模式并做出改变，人们能以最简单的方式培养对学习的热情，和在任何领域内取得成功都需要的抗压力。
两种思维模式 要培养自己/儿童具有成长型思维模式,改变原来的固定型思维模式.
理念(前提) 固定型: 相信自己的才能是一成不变的
成长型: 能力是可以通过你的努力来培养的
生活态度(对待烦心事) 固定型: 把发生的事当作一个衡量自己的能力和价值的直接标尺
成长型: 不会给自己贴上标签,或对自己失去信心.即使感到沮丧,也准备好去承担风险,直面挑战,继续为此奋斗
对结果的态度 固定型: 所有的一切都是为了结果.
成长型: 享受过程带来的乐趣.
对于挫折和失败
固定型: 认为没有能力做好,需要另辟蹊径. 不会从失败中学习并纠正自己的失败,相反,可能只是去尝试修复自尊(找借口).
成长型: 更努力的学习和付出
成功的意义
固定型: 希望能够确保自己的成功,认为聪明的人应该永远是成功的 (不想暴露不足)
成长型: 成功意味着拓展自己的能力范畴,变得越来越聪明 (捉住机会学习)
对努力的认识 固定型: 如果需要为某事付出努力,是自己不擅长做某事. 害怕努力后依然失败.
成长型: 天才也要通过努力达到成功,努力才能激发能力.
成长型思维模式 想达成重要成就需要明确的关注点,全身心的努力,无穷无尽的策略,还有学习中的同伴.
掌握学习过程和动力,在学习方面愿意尝试各种不同的方法. (兴趣或者好奇心是主要驱动力)
爱上自己做的事,即使面对困难也会继续热爱.有时投入一件事情,恰恰是因为不擅长做这件事.
寻求挑战,挑战越大,成长空间就越大.在拓展自己的过程中感到兴奋不已.
固定型思维模式 TBC.
</content>
    </entry>
    
     <entry>
        <title>用kubeadm手动搭建Kubernetes集群</title>
        <url>/blog/kubeadm/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag>
        </tags>
        <content type="html"> 用kubespray基于Ansible自动化工具搭建集群是很方便,但是一旦遇到问题查起来经常找不到头绪,因为不知所以然.
所以回归本源,用官方提供的kubeadm一步步建立一个单主的集群,可以让我们更容易弄清它的部署架构.
这也是此文/这次实践的目的所在.

前提条件 禁用swap sudo swapoff -a # 永久性禁用 # 编辑/etc/fstab并注释掉swap那一行 保留端口 Master节点
   组件 端口 注释     API server 6443 可重新定义   etcd 2379-2380    Kubelet API 10250    kube-scheduler 10251    kube-controller-manage 10252     注: 2 CPU&#43;
Worker节点
   组件 端口 注释     Kubelet API 6443    NodePort Services 30000-32767 可重新定义    Docker 容器运行时默认使用docker
安装说明 kubeadm, kubelet, kubectl  kubeadm: 集群引导命令行 kubelet: 集群每个节点都有(Node Agent),用于启动Pod/容器等 kubectl: 交互式集群管理命令行  注: kubelet的版本号不应该超过API server
# Ubuntu apt-get update &amp;amp;&amp;amp; apt-get install -y apt-transport-https curl curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.list deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main EOF apt-get update apt-get install -y kubelet kubeadm kubectl apt-mark hold kubelet kubeadm kubectl kubeadm init # 可以先运行下面命令检查到gcr.io的连接性 # kubeadm config images pull # 解决etcd pull失败的问题 docker pull xulz/coreos-etcd:v3.2.24 docker tag xulz/coreos-etcd:v3.2.24 gcr.mirrors.ustc.edu.cn/google-containers/etcd:3.2.24 kubeadm init --kubernetes-version=v1.13.1 --image-repository=gcr.mirrors.ustc.edu.cn/google-containers --pod-network-cidr=192.168.0.0/16 # --image-repository 指定镜像mirror,默认k8s.gcr.io # 也可以通过配置文件的形式 imageRepository: &amp;lt;private-registry&amp;gt;  # root用户运行 export KUBECONFIG=/etc/kubernetes/admin.conf # 记录下关于 kubeadm join的输出用于添加节点 注: token用户master和加入节点间的双向认证,需保密. 也可用 kubeadm token命令管理token.
# kubelet环境变量 # /var/lib/kubelet/kubeadm-flags.env # kubelet配置文件 # /var/lib/kubelet/config.yaml 安装Pod网络插件 pod networking provider
这里使用的CNI network plugin是Calico,它需要提供CIDR(默认使用192.168.0.0/16), 已经在上步的init提供.
# 先获取本地镜像并tag docker pull xulz/calico-node:v3.3.2 docker tag xulz/calico-node:v3.3.2 quay.io/calico/node:v3.3.2 docker pull xulz/calico-cni:v3.3.2 docker tag xulz/calico-cni:v3.3.2 quay.io/calico/cni:v3.3.2 docker pull quay.mirrors.ustc.edu.cn/calico/typha:v3.3.2 docker tag quay.mirrors.ustc.edu.cn/calico/typha:v3.3.2 quay.io/calico/typha:v3.3.2 以Calico为例:
kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml # 检查状态, CoreDNS pod应该已经运行 kubectl get pods --all-namespaces 添加节点 kubeadm join --token &amp;lt;token&amp;gt; &amp;lt;master-ip&amp;gt;:&amp;lt;master-port&amp;gt; --discovery-token-ca-cert-hash sha256:&amp;lt;hash&amp;gt; # 获取token kubeadm token list # 获取 --discovery-token-ca-cert-hash的值 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&amp;gt;/dev/null | \  openssl dgst -sha256 -hex | sed &amp;#39;s/^.* //&amp;#39; # 检查状态 kubectl get nodes  删除节点/清除 在Master节点执行
kubectl drain &amp;lt;node name&amp;gt; --delete-local-data --force --ignore-daemonsets kubectl delete node &amp;lt;node name&amp;gt; 在要删除的节点执行:
# 重置状态 kubeadm reset # 清理iptables iptables -F &amp;amp;&amp;amp; iptables -t nat -F &amp;amp;&amp;amp; iptables -t mangle -F &amp;amp;&amp;amp; iptables -X 参考 kubeadm 命令参考 # 输出默认配置 kubeadm config print # 输出指定api对象 kubeadm config print-default --api-objects KubeletConfiguration # 列出/获取kubeadm需要的容器镜像 kubeadm config images list kubeadm config images pull # 指定版本, 跳过该地址的检查 https://dl.k8s.io/release/stable-1.txt --kubernetes-version=v1.13.1# --config指定配置文件 kubeadm init --config kubeadm-config.yaml kubelet配置 init阶段
 /var/lib/kubelet/config.yaml : 同时上传至kubelet-config-1.X的ConfigMap /etc/kubernetes/kubelet.conf : 存储客户端证书用于和API Server通讯 /var/lib/kubelet/kubeadm-flags.env : 实例特定的信息及cgroup driver,CRI runtime socket  join阶段
 读取ConfigMap并写入/var/lib/kubelet/config.yaml /etc/kubernetes/bootstrap-kubelet.conf 包含CA 证书和Bootstrap Token. 读取上步的文件生成/etc/kubernetes/kubelet.conf  systemd使用的配置
/etc/systemd/system/kubelet.service.d/10-kubeadm.conf
kubeadm init 输出日志 [init] Using Kubernetes version: v1.13.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using &amp;#39;kubeadm config images pull&amp;#39; [kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34; [kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34; [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder &amp;#34;/etc/kubernetes/pki&amp;#34; [certs] Generating &amp;#34;front-proxy-ca&amp;#34; certificate and key [certs] Generating &amp;#34;front-proxy-client&amp;#34; certificate and key [certs] Generating &amp;#34;etcd/ca&amp;#34; certificate and key [certs] Generating &amp;#34;etcd/server&amp;#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [xulz-master1 localhost] and IPs [192.168.10.1 127.0.0.1 ::1] [certs] Generating &amp;#34;etcd/peer&amp;#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [xulz-master1 localhost] and IPs [192.168.10.1 127.0.0.1 ::1] [certs] Generating &amp;#34;apiserver-etcd-client&amp;#34; certificate and key [certs] Generating &amp;#34;etcd/healthcheck-client&amp;#34; certificate and key [certs] Generating &amp;#34;ca&amp;#34; certificate and key [certs] Generating &amp;#34;apiserver&amp;#34; certificate and key [certs] apiserver serving cert is signed for DNS names [xulz-master1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.10.1] [certs] Generating &amp;#34;apiserver-kubelet-client&amp;#34; certificate and key [certs] Generating &amp;#34;sa&amp;#34; key and public key [kubeconfig] Using kubeconfig folder &amp;#34;/etc/kubernetes&amp;#34; [kubeconfig] Writing &amp;#34;admin.conf&amp;#34; kubeconfig file [kubeconfig] Writing &amp;#34;kubelet.conf&amp;#34; kubeconfig file [kubeconfig] Writing &amp;#34;controller-manager.conf&amp;#34; kubeconfig file [kubeconfig] Writing &amp;#34;scheduler.conf&amp;#34; kubeconfig file [control-plane] Using manifest folder &amp;#34;/etc/kubernetes/manifests&amp;#34; [control-plane] Creating static Pod manifest for &amp;#34;kube-apiserver&amp;#34; [control-plane] Creating static Pod manifest for &amp;#34;kube-controller-manager&amp;#34; [control-plane] Creating static Pod manifest for &amp;#34;kube-scheduler&amp;#34; [etcd] Creating static Pod manifest for local etcd in &amp;#34;/etc/kubernetes/manifests&amp;#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &amp;#34;/etc/kubernetes/manifests&amp;#34;. This can take up to 4m0s [apiclient] All control plane components are healthy after 21.502262 seconds [uploadconfig] storing the configuration used in ConfigMap &amp;#34;kubeadm-config&amp;#34; in the &amp;#34;kube-system&amp;#34; Namespace [kubelet] Creating a ConfigMap &amp;#34;kubelet-config-1.13&amp;#34; in namespace kube-system with the configuration for the kubelets in the cluster [patchnode] Uploading the CRI Socket information &amp;#34;/var/run/dockershim.sock&amp;#34; to the Node API object &amp;#34;xulz-master1&amp;#34; as an annotation [mark-control-plane] Marking the node xulz-master1 as control-plane by adding the label &amp;#34;node-role.kubernetes.io/master=&amp;#39;&amp;#39;&amp;#34; [mark-control-plane] Marking the node xulz-master1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: r4p7.6fuglhjtitmb [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstraptoken] creating the &amp;#34;cluster-info&amp;#34; ConfigMap in the &amp;#34;kube-public&amp;#34; namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes master has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run &amp;#34;kubectl apply -f [podnetwork].yaml&amp;#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of machines by running the following on each node as root: kubeadm join 192.168.10.1:6443 --token r4p7.6fuglhjtitmb --discovery-token-ca-cert-hash sha256:12345660bf8a5ff727b3563a4be19abee27785fcc806bbf2e20f82a15a82be06 添加节点输出日志 [preflight] Running pre-flight checks [discovery] Trying to connect to API Server &amp;#34;192.168.10.1:6443&amp;#34; [discovery] Created cluster-info discovery client, requesting info from &amp;#34;https://192.168.10.1:6443&amp;#34; [discovery] Requesting info from &amp;#34;https://192.168.10.1:6443&amp;#34; again to validate TLS against the pinned public key [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &amp;#34;192.168.10.1:6443&amp;#34; [discovery] Successfully established connection with API Server &amp;#34;192.168.10.1:6443&amp;#34; [join] Reading configuration from the cluster... [join] FYI: You can look at this config file with &amp;#39;kubectl -n kube-system get cm kubeadm-config -oyaml&amp;#39; [kubelet] Downloading configuration for the kubelet from the &amp;#34;kubelet-config-1.13&amp;#34; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34; [kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34; [kubelet-start] Activating the kubelet service [tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap... [patchnode] Uploading the CRI Socket information &amp;#34;/var/run/dockershim.sock&amp;#34; to the Node API object &amp;#34;xulz-node1&amp;#34; as an annotation This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run &amp;#39;kubectl get nodes&amp;#39; on the master to see this node join the cluster. 文章列表  Installing kubeadm Creating a single master cluster with kubeadm *Creating a Custom Cluster from Scratch </content>
    </entry>
    
     <entry>
        <title>再提镜像站的使用</title>
        <url>/blog/mirror/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>python</tag>
        </tags>
        <content type="html"> 把时间花在下载软件或必须翻过去访问外部网络是让人苦恼的一件事, 镜像站能很好地解决一些问题.
最早时使用Ubuntu国内镜像加速软件更新,后来使用豆瓣的pypi镜像安装Python包,因为之前的pypi站实在太慢,经常超时.
最近用Docker和Kubernetes就不得不使用镜像站,之前用阿里的较多.
其实还有两个很好的国内镜像站就是清华TUNA和中国科大镜像开源站.
这两个站点基本包括了常用的软件开发工具和环境等,举例如下:
 Linux发行版: Ubuntu,CentOS 安装镜像及软件仓库 Python: Anaconda,pypi,saltstack Docker CE Grafaba,InfluxData MySQL,PostgreSQL,Percona,MongoDB Apache各项目 Cygwin, VirtualBox, Adobe开源字体 Homebrew, MacPort Elastic Stack, Gitlab Android: AOSP Tex: CTAN  官方还提供了一个python脚本,方便本地环境一键使用.
wget https://tuna.moe/oh-my-tuna/oh-my-tuna.py python oh-my-tuna.py 科大的补充:
 Nginx Golang Kubernetes的gcr.io和quay.io (此处给科大的同学一个大大的👍)  Kubernetes的使用说明
# gcr.io/namespace/image_name:image_tag # 替换为 # gcr.mirrors.ustc.edu.cn/namespace/image_name:image_tag gcr.mirrors.ustc.edu.cn/kubernetes-helm/tiller # Kubernetes官方教程经常用到k8s.gcr.io, # 相应的 k8s.gcr.io 等同于 gcr.io/google-containers/ # 因此 k8s.gcr.io/busybox 等价于 gcr.mirrors.ustc.edu.cn/google-containers/busybox # quay.io/calico/cni 替换为 quay.mirrors.ustc.edu.cn/calico/cni P.S: 之前我使用的镜像已停止维护,参考这里.
[update]
再补一个: 阿里开源镜像站
</content>
    </entry>
    
     <entry>
        <title>书法与文字</title>
        <url>/read/shufa/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag><tag>classic</tag>
        </tags>
        <content type="html"> 最近随着对国学和唐文化的喜爱,开始重新拾起毛笔找一点空隙时间练字.

之前拿毛笔应该是上小学期间了,印象比较深的时写的字没有一个被标红圈的(写的好),也打击了当时学习的热情. 毕业后也尝试改进自己写字的优美程度(写好字一直是我的一个痛点),多年前从图书大厦买了田英章的硬笔行书技法,当时不得要领只是摹写,加上硬笔练得少后来便荒废了.
幸运的时现在互联网知识传播已很发达,于是通过知乎/公众号/电子书/视频做了简单的系统认知, 因此学起来也算走了些捷径. 同事推荐的&amp;lt;田蕴章每日一题每日一字&amp;gt;也让我受益良多.
毛笔比硬笔的好处是仪式感更强, 对写字的认识和要求体会也更深. 重要的是功利心态比较轻,更多作为放松身心的方式.
最近在读的&amp;lt;极简中国书法史&amp;gt;(刘涛著)也让我对书法的历史有了更深的了解, 更能理解中国文字本身和书写之美.
从看到鸟兽在雪地的脚印得到灵感创造文字,到最初时的象形会意无不传神, 再到后面各书体的发展.
大篆到小篆到汉隶的化繁为简,隶书发展至行草的由静到动的变化之美,到现在第一书体楷书的端庄之美.
(最开始不理解篆体现代的意思,了解后才知道不学习篆体你就不知道汉字的渊源,比如有/右的第一笔撇画为什么开始经常见到短横)
顺便说, 五四运动之后提倡白话文,解放后废除繁体字,这些对于文字书写虽然不利,但不能成为我们不学习文言文和繁体字的理由.
书法作为国学的一部分, 无疑国学这个宝库应该被更多国人发现和开发.
自己是从欧楷学起的,也许需要很长一段时间才能看到成果, 计划之后再学颜柳赵诸大家,作为一个长久的爱好吧.
</content>
    </entry>
    
     <entry>
        <title>利器之iTerm2</title>
        <url>/blog/iterm2/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>mac</tag><tag>terminal</tag>
        </tags>
        <content type="html"> 平时用的最多的系统是Windows10和Ubuntu,如果说苹果系统MacOS有什么让我离不开的特性的话,iTerm2绝对排第一.
可这个经常使用的免费终端居然有一些我不知道的好用功能,特记录与此.

友好特性 Split Panels 我经常用到tmux,居然忽视了该功能.
右键就可以看到.
快捷键: Cmd&#43;d 垂直分割/ Cmd&#43;Shift&#43;d 水平分割
Autocomplete Cmd &#43; ;调出自动提示.
Paste History Cmd &#43; Shift &#43; h
[Preferences]-[General]-&amp;ldquo;Magic&amp;rdquo;-&amp;ldquo;&amp;ldquo;Save copy/paste and command history to disk&amp;rdquo;
选中即复制 支持鼠标和查找模式(Cmd&#43;f)的Tab复制
系统热键调出 Hotkey实现类似Linux中Yakuake功能.
[Preferences]-[Keys]中设置.
常用快捷键 Cmd&#43;w : 关闭窗口/面板
</content>
    </entry>
    
     <entry>
        <title>LaTeX生成PDF实践</title>
        <url>/blog/latex/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>document</tag>
        </tags>
        <content type="html"> LaTeX最广泛的用途应该是在学术领域写论文, 其实在排版(尤其公式,格式)上也胜过Word很多,绝对专业.
最近为了在本地生成一个PDF,做了一些了解.

简介 TeX -&amp;gt; LaTeX -&amp;gt; XeLaTex
XeLaTeX 是基于TeX的一个专业排字系统, 对于Unicode 和 OpenType字体的支持很好. 可以用来创建好看的PDF文档.
编辑器和编译 TeXLive应该是第一选择,文件安装包有点大(3个G),推荐在清华开源镜像下载.
 TexLive Windows TexLive Mac - MacTex  不推荐使用BasicTeX/安装依赖包 最初我使用了简易版的BasicTeX, 使用起来很繁琐,需要安装大量的包/样式.
如果直接安装TextLive Full可忽略该阶段.
# 在使用前需要先更新PATH export PATH=/usr/local/texlive/2018basic/bin/x86_64-darwin:$PATH # 使用包管理工具 tlmgr sudo tlmgr update --self --repository http://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnet sudo tlmgr install latexmk --repository http://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnet sudo tlmgr install ctex # 其他常用依赖 cjk cjkpunct zhnumber environ trimspaces subfigure multirow tocbibind placeins datatool 解决错误
# 如果遇到类似下列错误 # LaTeX Error: File `ctexbook.cls&amp;#39; not found # LaTeX Error: File &amp;#39;&amp;#39;picins.sty&amp;#39;&amp;#39; not Found # 安装相应包 sudo tlmgr install picins 对Mac来说文件安装在/usr/local/texlive/2018basic/texmf-dist/tex/latex/, 因此也可以通过创建文件夹, 把样式复制到相应文件夹, 或者直接复制到文档目录下.
资源链接
 algorithms包 BasicTeX安装说明  生成PDF文档 安装完TexLive后, 打开TeXworks, Typeset选择XeLateX
中文排版 涉及中文一般会用到CTeX宏包
CTeX-kit 是一系列 TeX/LaTeX/ConTeXt 宏包的集合, 相关脚本和资源文件, 主要针对中文TeX用户.
中文字体 .tex文件配置
\setCJKmainfont[AutoFakeBold=true]{AdobeSongStd-Light} \setCJKsansfont{AdobeHeitiStd-Regular} \setCJKmonofont{AdobeFangsongStd-Regular} 中易宋体(SimSun)和华文宋体(STSong)分别是 Windows 和 Mac OS X 默认的简体中文宋体.
通常也会用到Adobe中文字体,可到以下网址下载:
 字体库下载 fontsmarket  # 查看当前系统中文字体 # Mac直接使用系统的Font Book/字体册 # 找到对应字体按Command&#43;i键,就会显示字体的详细信息,postScript即字体名  fc-list;lang=zh-cn 扩展阅读  ctan官方包仓库 Travis-CI与Latex构建开源中文PDF 中科大论文模板 </content>
    </entry>
    
     <entry>
        <title>Kubernetes命名空间的应用</title>
        <url>/blog/k8s-namespace/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag>
        </tags>
        <content type="html"> 在实际应用中存在一个Kubernetes集群中多个部署环境的问题,比如存在dev,qa,stage等.
如果部署在一个集群会省去不少运维成本且节省资源占用.
通常这会用到命名空间的特性.

Namespaces 命名空间 命名空间可以被看做virtual cluster/虚拟集群.
默认存在default和kube-system两个命名空间.
用户的普通应用默认是在default下，与集群管理相关的为整个集群提供服务的应用一般部署在kube-system的namespace下.
创建新的命名空间
namespace-dev.yml
kind:NamespaceapiVersion:v1metadata:name:dev-spacelabels:name:dev-space  kubectl create -f namespace-dev.yml
 kubectl get ns # 指定命名空间 kubectl -n &amp;lt;namespace&amp;gt; kubectl get services —namespace=&amp;lt;my-space&amp;gt; 给命名空间指派context/上下文 一旦切换上下文, kubectl命令的执行(增改删)会在该命名空间运行.
# 绑定命名空间和上下文的关系 kubectl config set-context dev --namespace=dev --cluster=minikube --user=minukube # 切换到Dev context kubectl config use-context dev # 核实当前context kubectl config current-context # Delete dev namespace kubectl delete namespaces dev 扩展阅读  Dynamic Environments with Kubernetes Gitlab和Kubernetes做集成部署 </content>
    </entry>
    
     <entry>
        <title>迁移至Python3</title>
        <url>/blog/python3/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 用过Python的都知道,他有两个互不兼容的大版本Python2和Python3,由于历史遗留问题许多生产环境或库还只支持老版本Python2.
实际上2.7已经发布了近8年,且是最后一个2.x的大版本,并且将于2010(两年后)彻底停止维护,退出历史舞台.
Python3在两年前及更早时的库支持和应用范围确实不太好,有选择困难症的同学都转去Go语言了:) .
幸运的是近两年主流库/框架都已支持Python3,毕竟发布已经10年多了,在新项目中毫无疑问必须用Python3.
之前我在两个新项目已经使用Python3,最近把一个老项目也彻底迁移过来, 这里记录下一些知识点.

string和unicode Python 2 的 str 是 bytes, Python 3 的 str 是 unicode.
# 字符串和二进制转换 unicode_string.encode() # 默认utf-8 byte_string.decode() # split现在是bytes的方法 # requests.get(xxx).content返回bytes类型 your_content.split(b&amp;#39;,&amp;#39;) # base64编码后返回字节类型,转换为str base64.b64encode(some_bytes).decode() 语法变化  使用print() except语句  有用的技巧 使用命令行参数提示兼容性问题:
 python2 -3参数 提示warning python3 -bb参数 提示字符串处理差异  # 判断当前运行版本 PY3 = sys.version_info[0] == 3# 安装pip3 python3 -m ensurepip 兼容2和3 除非迫不得已,应该只支持Python3
如果要兼容参考:
 官方迁移指南 Cheat Sheet: Writing Python 2-3 compatible code:如何写兼容的代码  扩展阅读  Pragmatic Unicode :关于unicode的通俗讲解  代码片段 # 对称加密移除padding的帮助函数(py2版本不适用于py3) def unpad(bytestring, k=16): &amp;#34;&amp;#34;&amp;#34; Remove the PKCS#7 padding from a text bytestring. &amp;#34;&amp;#34;&amp;#34; val = bytestring[-1] if val &amp;gt; k: raise ValueError(&amp;#39;Input is not padded or padding is corrupt&amp;#39;) l = len(bytestring) - val return bytestring[:l] def pad(bytestring, k=16): &amp;#34;&amp;#34;&amp;#34; Pad an input bytestring according to PKCS#7 &amp;#34;&amp;#34;&amp;#34; l = len(bytestring) val = k - (l % k) return bytestring &#43; bytearray([val] * val)</content>
    </entry>
    
     <entry>
        <title>设计数据密集型应用笔记</title>
        <url>/blog/ddia/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>distributed</tag><tag>database</tag>
        </tags>
        <content type="html"> 去年就看到总有人推荐这本书(简称DDIA),最初手里只有英文版,缓慢的读了个开头后来就忙别的去了.
今年偶然看到网上有中译版,惭愧的是到了年底,最近几个月才读来.
书的信息量很大,对数据库和分布式系统感兴趣的尤其值得一读.

暂时还剩第三部分没读完,先记些凌乱的笔记.
数据密集型:
 数据是主要挑战,涉及数据量,数据复杂度和数据变化速度. 于此对应的是计算密集型.  第一部分:数据系统基础 数据系统设计的基本思想
第一章: 可靠性,可扩展性,可维护性 可靠性:
 要设计具有容错/韧性的系统以应对各种故障. 常见的故障种类: 硬件故障 软件错误 人为错误  可扩展性: 用负载参数描述负载
描述性能:
 Throughout Response Time(客户端感受时间,区别于Latency). 响应时间重视时间分布,即使用百分位而不是平均数  软件系统的三个设计原则
 可操作性(运维友好) 简单性(好的抽象) 可演化性/可扩展性/可修改性/可塑性  第二章:数据模型和查询语言 数据模型: 数据的存储和查询等
 关系模型: 事务处理和批处理 文档模型: 对多对多和连接(记录之间存在关系)支持较差 图模型  关系模型 存储ID还是文本字符串是个副本(duplication)问题,去除冗余副本是数据库规范化的关键思想.
声明式查询语言(SQL)相对命令式的优势:
 比命令式API更简洁和容易 隐藏了数据引擎的实现细节  文档数据库 适用于大多数关系都是一对多关系(树状结构化数据)
文档数据库的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。
准确的说文档数据库 并不是无模式(schemaless),应该是schema-on-read(隐含的数据结构).
JSON表示比多表模式具有更好的局部性(locality).
第三章 主流的两大类存储引擎：
 日志结构（log-structured）的存储引擎 面向页面（page-oriented）的存储引擎（例如B树）  日志结构学派 日志/log:仅追加的数据文件. (只允许附加到文件和删除过时的文件，但不会更新已经写入的文件)
哈希索引: Bitcask(Riak默认存储引擎)
SSTables(排序字符串表（Sorted String Table）)制作LSM树/日志结构合并树
Bloom过滤器/布隆过滤器是用于近似集合内容的内存高效数据结构，它可以告诉您数据库中是否出现键，从而为不存在的键节省许多不必要的磁盘读取操作.
LSM树性能优势:
由于数据按排序顺序存储，因此可以高效地执行范围查询（扫描所有高于某些最小值和最高值的所有键），并且因为磁盘写入是连续的，所以LSM树可以支持非常高的写入吞吐量。
就地更新学派 将磁盘视为一组可以覆盖的固定大小的页面。例子:B树.
日志结构索引将数据库分解为可变大小的段，通常是几兆字节或更大的大小，并且总是按顺序编写段。相比之下，B树将数据库分解成固定大小的块或页面.
为了使数据库对崩溃具有韧性，B树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log）/ 重做日志(redo log)
并发控制使用锁存器（latches）（轻量级锁）保护树的数据结构来完成.
根据经验，通常LSM树的写入速度更快，而B树的读取速度更快。 LSM树上的读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。
内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。
数据仓库 数据仓库是一个独立的数据库，分析人员可以查询需要的内容，而不影响OLTP操作。 数据仓库包含公司所有各种OLTP系统中的只读数据副本。 从OLTP数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。将数据存入仓库的过程称为&amp;rdquo;抽取-转换-加载（ETL）&amp;rdquo;
 在线事务处理（OLTP, OnLine Transaction Processing） 在线分析处理（OLAP, OnLine Analytice Processing）  星型模式/维度建模
由事实表和维度表组成.
列存储
第四章:编码与演化 将数据结构转换为网络中的字节或磁盘上的字节的几种方法。我们看到了这些编码的细节不仅影响其效率，更重要的是应用程序的体系结构和部署它们的选项。
服务支持滚动升级需要提供向后兼容性（新代码可以读取旧数据）和向前兼容性（旧代码可以读取新数据）的方式进行编码.
 编程语言特定的编码 JSON，XML和CSV等文本格式 二进制模式驱动格式  二进制模式驱动格式允许使用清晰定义的前向和后向兼容性语义进行紧凑，高效的编码。
对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，因为它可以在编译时进行类型检查。
 Thrift Protocol Buffers Avro  数据流的几种模式
 数据库 RPC和REST API 异步消息传递(消息代理或Actor模型)  REST似乎是公共API的主要风格。 RPC框架的主要重点在于同一组织拥有的服务之间的请求，通常在同一数据中心内。
第二部分:分布式数据系统  共享架构:  共享内存架构（shared-memory architecture）: 垂直扩展（vertical scaling）或向上扩展（scale up） 共享磁盘架构（shared-disk architecture）: 网络附属存储（Network Attached Storage, NAS）或存储区网络（Storage Area Network, SAN）  无共享架构（shared-nothing architecture）: 水平扩展（horizontal scale） 或向外扩展（scale out）  NUMA: 非均匀内存访问（nonuniform memory access）
数据分布在多个节点上有两种常见的方式：
 复制（Replication） 分区 (Partitioning) : 不同的分区可以指派给不同的节点（node）, 亦称分片（shard）  第五章: 复制 单主复制 半同步（semi-synchronous）配置: 在数据库上启用同步复制，通常意味着其中一个跟随者是同步的，而其他的则是异步的。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库。
处理节点宕机
 从库失效：追赶恢复 主库失效：故障转移（failover）,需要认真考虑可能的情况  复制日志的实现
 基于语句的复制(副作用太大,通常不使用) 传输预写式日志（WAL） 逻辑日志复制（基于行）: 复制和存储引擎使用不同的日志格式 基于触发器的复制: 较灵活,但开销较大  多主复制 多领导者配置（也称多主、多活复制）,通常用于多数据中心.
实现: CouchDB
无主复制 leaderless
复制延迟问题(最终一致性)  读己之写 单调读（Monotonic reads）: 比强一致性（strong consistency）更弱，但比最终一致性（eventually consistency）更强的保证 一致前缀读: 如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现  第六章: 分区/Partitions 键值数据的分区
 根据键的范围分区:存在偏斜和热点的问题 根据键的散列分区  分片与次级索引
 按文档的二级索引/文档分区索引/本地索引: 分散/聚集（scatter/gather）方法 根据关键词(Term)的二级索引/全局索引  分区再平衡策略
 固定数量的分区:创建比节点更多的分区，并为每个节点分配多个分区 动态分区: 按节点比例分区  第七章: 事务 事务通常被理解为，将多个对象上的多个操作合并为一个执行单元的机制
ACID代表原子性（Atomicity），一致性（Consistency），隔离性（Isolation）和持久性（Durability）
 原子性/可中止性（abortability）: 能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。 一致性: 对数据的一组特定陈述必须始终成立。即不变量（invariants） 原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。 隔离性: 同时执行的事务是相互隔离的  并发控制常用的隔离级别  读已提交是一个非常流行的隔离级别,通过使用行锁（row-level lock） 来防止脏写 快照隔离/可重复读: 通常使用多版本对象/多版本并发控制（MVCC, multi-version concurrentcy control）实现 可序列化(Serializability）:通常被认为是最强的隔离级别。它保证即使事务可以并行执行，最终的结果也是一样的  一些可能遇到的问题:
脏读/脏写/读取偏差(不可重复读)/更新丢失/写偏差/幻读/字面意义上的串行执行(单核CPU)/两阶段锁定/可串行化快照隔离（SSI）
MySQL/InnoDB的可重复读并不会自动检测丢失的更新
比较并设置（CAS, Compare And Set）
幻读（phantoms）:即一个事务改变另一个事务的搜索查询的结果
记录系统和衍生数据系统之间的区别不在于工具，而在于应用程序中的使用方式。
第八章: 分布式系统的麻烦 分布式系统与运行在单台计算机上的程序的不同之处：
 没有共享内存，只有通过可变延迟的不可靠网络传递的消息 系统可能遭受部分失效 不可靠的时钟和处理暂停  物理时钟:时钟和单调钟
时钟: 根据某个日历（也称为挂钟时间（wall-clock time））返回当前日期和时间,通常程序返回自epoch（1970年1月1日 午夜 UTC，格里高利历）以来的秒数（或毫秒）.需要根据NTP服务器设置同步. 单调钟: 适用于测量持续时间（时间间隔），例如超时或服务的响应时间. 保证总是前进的事实（而时钟可以及时跳回）.单调钟不需要同步.
拜占庭将军问题: 在不信任的环境中达成共识的问题.
第九章: 一致性与共识 共识（consensus）：就是让所有的节点对某件事达成一致
事务隔离主要是为了，避免由于同时执行事务而导致的竞争状态，而分布式一致性主要关于，面对延迟和故障时，如何协调副本间的状态。
最强一致性模型之一: 线性一致性（linearizability）
线性一致性（linearizability）/ 原子一致性（atomic consistency）/ 强一致性（strong consistency）/ 立即一致性（immediate consistency）/ 外部一致性（external consistency ）
基本思想：使系统看起来好像只有一个数据副本,是读取和写入寄存器（单个对象）的新鲜度保证
依赖线性一致性的场景:
 锁定和领导选举 约束和唯一性保证 跨信道的时序依赖  CAP定理的正式定义仅限于很狭隘的范围，尽管CAP在历史上有一些影响力，但对于设计系统而言并没有实际价值.
因果一致性为我们提供了一个较弱的一致性模型
版本向量可以区分两个操作是并发的，还是一个因果依赖另一个；而兰伯特时间戳(更加紧凑)总是施行一个全序。
线性一致的CAS（或自增并返回）寄存器与全序广播都都等价于共识问题
共识可以解决的问题:
 线性一致性的CAS寄存器 原子事务提交 全序广播 锁和租约 成员/协调服务 唯一性约束  ZooKeeper这样的工具为应用提供了“外包”的共识、故障检测和成员服务。
第三部分: 派生数据 第十章: 批处理算法和框架 与Unix设计相通 Unix设计原则包括：输入是不可变的，输出是为了作为另一个（仍未知的）程序的输入，而复杂的问题是通过编写“做好一件事”的小工具来解决的.
在Unix世界中，允许程序与程序组合的统一接口是文件与管道；在MapReduce中，该接口是一个分布式文件系统。
分布式批处理/MapReduce 批处理的常见用途:
搜索,构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，图像识别）与推荐系统（例如，你可能认识的人，你可能感兴趣的产品或相关的搜索)
分布式批处理框架需要解决的两个主要问题是：
 分区: 在MapReduce中，Mapper根据输入文件块进行分区。 容错: MapReduce经常写入磁盘;数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态;确定性算子减少了需要重算的数据量.  分布式批处理引擎有一个刻意限制的编程模型：回调函数（比如Mapper和Reducer）被假定是无状态的. 使得批处理作业中的代码无需操心实现容错机制.
MapReduce的连接算法
 排序合并连接 广播散列连接 分区散列连接  数据流引擎的优化 Tez是一个相当薄的库，它依赖于YARN shuffle服务来实现节点间数据的实际复制，而Spark和Flink则是包含了独立网络通信层，调度器，及用户向API的大型框架。
Hive，Spark和Flink都有基于代价的查询优化器可以做到这一点，甚至可以改变连接顺序，最小化中间状态的数量.
图批量处理 在整个图上执行某种离线处理或分析,这种需求经常出现在机器学习应用（如推荐引擎）或排序系统中,最着名的图形分析算法之一是PageRank.
使用批量同步并行（BSP）计算模型,即Pregel模型.
一些概念 事件日志: 描述登录用户在网站上做的事情（称为活动事件（activity events）或点击流数据（clickstream data）.事件日志是事实表，用户数据库是其中的一个维度。
物化（materialization）: 将中间状态写入文件的过程
算子(operators)是Map和Reduce的泛化
高级API和语言:
Mahout在MapReduce，Spark和Flink之上实现了用于机器学习的各种算法
空间算法: 如最近邻搜索（k-nearest neghbors, kNN）
第十一章: 流处理(stream processing) 消息系统的分类:
 直接从生产者传递给消费者 消息代理(message broker) / 消息队列(message queue)  AMQP/JMS风格的消息代理: 适用于在消息处理代价高昂，希望逐条并行处理，顺序不重要的情况下 基于日志的消息代理: 适用于消息吞吐量很高，处理迅速，顺序很重要的情况下   一个记录/事件(event)由生产者（producer）/发布者（publisher）/发送者（sender）生成一次，然后可能由多个消费者（consumer）/订阅者（subscribers）/接收者（recipients）进行处理.
许多开源分布式流处理框架的设计都是针对分析设计的：例如Apache Storm，Spark Streaming，Flink，Concord，Samza和Kafka Streams。
流处理的几种目的:
 搜索事件模式（复杂事件处理） 计算分窗聚合（流分析) 保证衍生数据系统处于最新状态（物化视图）。  流式连接
流处理中可能出现的三种连接类型：
 流流连接 流表连接 表表连接  容错
流处理中实现容错和恰好一次语义的技术: 可以使用更细粒度的恢复机制，基于微批次，存档点，事务，或幂等写入。
Spark在批处理引擎上执行流处理，将流分解为微批次（microbatches）, 而Apache Flink则在流处理引擎上执行批处理.
幂等性（idempotence）: 幂等操作是多次重复执行与单次执行效果相同的操作。
第十二章:数据系统的未来 (串联起前边章节的汇总篇)
批处理与流处理 在维护衍生数据时，批处理和流处理都是有用的。流处理允许将输入中的变化以低延迟反映在衍生视图中，而批处理允许重新处理大量累积的历史数据以便将新视图导出到现有数据集上。
Lambda架构
核心思想是通过将不可变事件附加到不断增长的数据集来记录传入数据，这类似于事件溯源。
为了从这些事件中衍生出读取优化的视图, Lambda架构建议并行运行两个不同的系统：批处理系统（如Hadoop MapReduce）和独立的流处理系统（如Storm）。
在Lambda方法中，流处理器消耗事件并快速生成对视图的近似更新；批处理器稍后将使用同一组事件并生成衍生视图的更正版本。
</content>
    </entry>
    
     <entry>
        <title>读国学</title>
        <url>/read/guoxue/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag><tag>classic</tag>
        </tags>
        <content type="html"> 国学的火热似乎起自十多年前百家讲坛的于丹系列,最近几年也总能听到教儿童读弟子规或者各地开女德班等的无关真正国学的负面新闻.
最近读章太炎的国学讲义才知道,国学最早是在一个世纪前提出的,当时社会变革收到西方先进思想文化的冲击,人们试图重现审视中国传统文化挖掘其精华和价值.
先说定义,国学泛指中国传统文化和学术(这个涵盖各行各业). 一般使用传统分类: 经史子集, 区别于现代使用的西方学科分类法.
 经: 本意是线装经典书,在汉初定义,汉之前的经典书都算此类. 主要包括&amp;lt;诗经&amp;gt;,&amp;lt;论语&amp;gt;,&amp;lt;孟子&amp;gt;,&amp;lt;尚书&amp;gt;,&amp;lt;左传&amp;gt;等 史: &amp;lt;史记&amp;gt;,&amp;lt;汉书&amp;gt;等朝代史,前两部也有很高的文学价值. 尚书开纪传体之先,左传为编年体之先. 子: 先秦诸子及各种行业著作(九流) 集: 诗词赋文学  之前读过些华杉读懂孙子兵法,偶尔也读论语的解读,基本是汇集各家之长,同时结合现实实践. 两千来年的儒学也总有他的可取之处.
作为理科出身,确实该提高下古文学鉴赏和古文阅读能力,毕竟这是中文之本,学好母语的基础.
</content>
    </entry>
    
     <entry>
        <title>读诗词</title>
        <url>/read/poem/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag><tag>classic</tag>
        </tags>
        <content type="html"> 为了听蒙曼品最美唐诗冲了会员,也因此收听到了更多的音频,毕竟喜欢的还有郦波品读唯美诗词名篇, 虽然我之前从没看过诗词大会之类的节目.
听过一些之后的感觉是,唐诗真的是文学里最美的花, 不同于学生时代的死记硬背,在人生经历丰富后,更能体会到诗的文字精炼之美,音韵之美.
因为想理清唐诗的发展历程,又找来了闻一多的唐诗杂论,朱自清的经典常谈等经典著作来读, 也再次引发我的下篇, 对于国学的了解.
似乎职业习惯的毛病,联网化了.
这几篇文章之后慢慢更新吧,先写个点题的开头.
音韵
以前不太理解多音字,听唐诗讲课多了才理解其中原因. 比如几个缘故:
 历史发展/流变: 比如 &amp;ldquo;车&amp;rdquo;最初表示战车读ju,后来统称车类就读che 名词,动词等词性不同: 比如 &amp;ldquo;冠&amp;rdquo;四声表示动词一声表示名词 正式或口语表示: 比如 &amp;ldquo;血&amp;rdquo;的xue/xie 不同含义: 比如 &amp;ldquo;思&amp;rdquo;的一声和四声(表示心情,思绪) 押韵: 比如 &amp;ldquo;斜&amp;rdquo;在诗歌里一般读xia  总结起来,这就是汉语的博大精深之初,即大道至简. 因为在你了解了这些知识/常识后, 放在上下文里就能准确的表达含义. 比拉丁语系的不同词性都造个生词要高明的多.
</content>
    </entry>
    
     <entry>
        <title>读历史</title>
        <url>/read/history/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag><tag>classic</tag>
        </tags>
        <content type="html">  缘起 在年初的时候,因偶然机会追了一部国产剧,即网剧大军师司马懿. 当时是很着迷的, 因为看的下载版,可以说看的不舍昼夜.
评价嘛,上部明显好于下部,制作精良,演技总体给力. 缺点就是改动太随意,好多不符合历史的情景.
剧本你可以改编,但大的历史人物事件还是要尊重的,否则你搞个戏说也行,或者干脆架空历史.
也因为这点,了解了很多魏晋的历史. 更重要的时开始读易中天老师的中华史系列,一发而不可收拾,断断续续读了隋唐及之前大部分历史.
古代史 作为中华的一份子, 最想了解的就是那段光辉岁月: 秦汉和隋唐.
由于中华史做纯粹的历史书看的话,会稍显细节不够. 上个月开始在路上补隋史,而且是通过更方便碎片的喜马拉雅听书,主要听的蒙曼老师的百家讲坛音频:大隋风云.
也因此喜欢上了蒙老师,又重新引起自己对于唐诗美的欣赏(具体见下篇).
听完后,又收听了易中天说禅,作为中华智慧的一部分,收获就是做人有时要放弃执念(破执),当然做事还是要认真的.
回头把先秦(春秋战国)补上,毕竟出了那么大思想家哲学家.
秦 短暂而创造辉煌的时代, 秦始皇的功绩地位毋庸置疑, 统一中华, 开创帝国时代.
皇帝这个名词就是他发明的, 统一的不仅是领土,更是文字,度量衡等,促进沟通和繁荣.
成败都在法家和吏治,在时代大变革之际使用高压企图大一统,最终促成了起义和反抗. 过在焚书.
汉 刘邦的成和项羽的败是必然的,一个优秀团队对一个有英雄主义的人, 汉高祖有其个人魅力.
张良运筹帷幄,韩信国士无双.
众诸侯下场很惨,有其时代必然性,从封建到集权不得已而为之. 也导致了之后汉的外戚和宦官政治.
汉武帝确是一代英主,那也是一个传奇的时代,卫青霍去病生逢其时.
三国魏晋 之前一直误解曹操了,真是一代枭雄,也成就了魏. 只可惜之后两代生命短暂,最后又托孤不妥从此断送.
也是了解历史后才知道王者游戏里的甄姬原是甄宓.
蜀因为名著三国演义成就了刘备和诸葛亮等诸名将,更因为理想主义被人们传为佳话.
吴的功是发展了江南,也因为之后司马氏的善待,才有了东晋的建立和南方的开发.
蜀吴的问题是二代太差,更重要的是实力真的不能和北方抗衡,败也属必然了.
晋最大的问题是因为是篡来的王朝,制度建设和子女教育真是问题,注定了短命王朝,留下了晋惠帝立长这个反面典型和比富的故事.
好在留下士人风骨和诗歌书法的宝贵遗产,记起的有杜预(杜甫和杜牧的先祖),陆机,王谢等大家.
读到五胡乱华时真是痛心,可也因此有了南北之说. 十六国里能记得的只有苻坚了,气候确实不够.
南北朝 因为长江而有了南北,期间也促进了民族融合和文化发展.
北魏发展也算传奇,一个小部落有如此大发展,不无理由.
拓跋宏的改革和融合载入教科书,可惜的是生命太短. 另一方面改革也埋下了陇西六镇(之后的关陇贵族)反叛的隐患.
西魏的宇文泰一代枭雄,南朝梁元帝江陵焚书臭名昭著.
隋 隋唐真的和秦汉好像啊,而且隋唐的关系更近, 杨广这个炀帝的称号有些过了.
杨坚的历史地位还是很高的,以较小的代价统一南北,开创科举,建立隋律,开三省六部行政体系,确定东亚霸主地位.
当然这些名臣也功不可没的载入历史,高炯,长孙昇等.
杨广的急功近利,刚愎自用,好大喜功真是印象深刻, 也应了不作就不会死这句话.
从人的成长看,过早的一帆风顺真的有其弊病啊,一次打击(东征高句丽)就再也起不来了.
大运河通南北,东都洛阳连东西,再通西域还是很有功劳的,不过执行急了些. 也应了性格决定命运这句话,这个锅有独孤氏一份.
唐 唐是我心目中最辉煌的时代,开放和包容,文化大发展,历史影响最大.
唐诗,书法,禅宗永流传.
唐太宗李世民绝对可以上帝王排行榜前几位,虽然有玄武门政变和改史美化自己的问题,但从十八学士和重用魏征等很多史实看,却也是综合实力最强的太子.
可惜的是晚年选太子不够妥当,也因此成就了大政治家武则天的传奇.
正如无字碑一样,武则天功过很难说,却是国内史上唯一女皇帝.
唐玄宗也是晚年出了大问题,直接造成安史之乱而由极盛转衰,之后长期的宦官干政和藩镇割据这个锅他必须背.
由此看,做一辈子好人真难,能做到孟子所谓大丈夫真是需要极高的修养了.
</content>
    </entry>
    
     <entry>
        <title>自动生成SSL证书的利器acme.sh</title>
        <url>/blog/acme/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>web</tag><tag>secuirty</tag>
        </tags>
        <content type="html"> 已经使用letsencrypt的免费证书一段时间了，是之前折腾Ghost博客时自动安装的，而后台其实也是用的acme.sh这个工具。
遇到的问题是不知哪里的配置错误，我的证书自动更新有问题，每次都是遇到证书已经过期，网站彻底不能访问了，必须要手动更新。
之前用的HTTP的验证方式，由于一知半解，这块每次手动配置也会花费一些时间。
今天重读了官方文档，才发现有一些细节的使用，其实可以做到一劳永逸。

安装 curl https://get.acme.sh |sudo sh # 默认安装在~/.acme.sh/ # 每天0点自动检测是否过期，并会通过cronjob自动更新证书 生成证书 支持两种验证方式。
注：记得带上www.mydomain.com这种形式的域名。
HTTP 我之前一直用这种，相比DNS方式还是麻烦些。
acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/xulz/wwwroot/mydomain.com/ # 之前都不知道还可以指定nginx智能识别 acme.sh --issue -d mydomain.com --nginx DNS 这个是真的自动化了。
# 以阿里云为例 # 下面的信息存在~/.acme.sh/account.conf，也可以手动修改 export Ali_Key=&amp;#34;sdfsdfsdfljlbj&amp;#34; export Ali_Secret=&amp;#34;jlsdflanljkljlfdsaklkjflsa&amp;#34; acme.sh --issue --dns dns_ali -d mydomain.com -d www.mydomain.com 安装证书 这步常被忽略。
注： 默认生成的证书都放在安装目录下: ~/.acme.sh/, 请不要直接使用此目录下的文件
# 注：Nginx 的配置 ssl_certificate 需要使用 /etc/nginx/ssl/fullchain.cer  acme.sh --installcert -d &amp;lt;domain&amp;gt;.com \  --key-file /etc/nginx/ssl/&amp;lt;domain&amp;gt;.key \  --fullchain-file /etc/nginx/ssl/fullchain.cer \  --reloadcmd &amp;#34;service nginx force-reload&amp;#34; 其他 # 更新acme.sh # V2版本已支持wildcard证书 acme.sh --upgrade # 调试，打印更详细信息 acme.sh --issue ... --debug </content>
    </entry>
    
     <entry>
        <title>JVM和GC调优</title>
        <url>/blog/jvm/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>performance</tag>
        </tags>
        <content type="html"> 曾多次接触Java的GC参数调优和日志分析，零散的记录在各处，时间一长也忘的差不多了，汇总于此。

Hotspot JVM 这里的JVM特指Oracle的 Hotspot JVM.
由 class loader, the runtime data areas（含heap）, 和execution engine（含GC和JIT）三部分组成。
Heap主要用于对象数据的存放。
性能优化主要涉及heap大小和适合的GC算法的调优。
优化着重于两个目标：
 响应能力：长时间的停顿不可接受
 吞吐率：较长一段时间的处理量，快速响应不是必须的。  GC主要算法 Serial -XX:&#43;UseSerialGC
Parallel JDK8默认值。
-XX:&#43;UseParallelGC
-XX:&#43;UseParallelOldGC
CMS 新生代使用Parallel New &#43; 老年代使用CMS（Concurrent Mark-Sweep Collector）。
-XX:&#43;UseParNewGC -XX:&#43;UseConcMarkSweepGC
前三种算法的Heap堆结构：  Young Generation = eden &#43; Survivor Space(S0&#43;S1) Old Generation == Tenured Permanent Generation == Permanent  G1 代表Garbage First，适用于多核和超大内存的情况，需要JDK7u4&#43;。
是CMS的替代方案，被划分为相同大小的区域，由eden,survivor和old三部分组成。
使用场景：Heap 6G&#43; 或要求停顿时间小于0.5s
-XX:&#43;UseG1GC
其他参数：
 -XX:MaxGCPauseMillis=200 （默认200ms）
 -XX:InitiatingHeapOccupancyPercent=45 （默认45%，开始并发GC Cycle）
 -XX:G1ReservePercent=10（默认10%，提高以避免 to-space overflow错误）  通常2000个区域，每个区域1~32Mb。
注：不要设置新生代大小（-Xmn）
调优 建议：老年代占用率至少大于新生代活跃数据的1.5倍，新生代空间大小至少为堆大小的10%.
主要触发事件：
新生代用完会触发Minor GC，时间通常很快；
老年代（tenure&#43;perm）用完会触发Full GC,时间通常较长。
原始是更频繁的Minor GC和更少的Full GC。
Heap Size = Young Gen &#43; Old Gen &#43; Meta space
主要参数  -Xms Heap初始大小 -Xmx Heap最大值 -Xmn 新生代Heap大小（推荐不设置，使用则该值不能太大）  XMX和XMS设置一样大,减轻伸缩堆带来的压力　JVM占用内存会超过Xmx大致1/3, 因此Xmx的值不应超过总内存的60%~70%.　-X 是设置JVM参数的新命令，不带-X 的是为了兼容之前版本.
打印默认参数
java -XX:&#43;PrintFlagsFinal -version
Thread Stack Size Java 8 64bit 默认1024k. 每个线程启动时JVM为该线程创建一个新的Java Stack,在discrete frames存放线程状态,执行两类操作push和pop frames.
使用递归算法或使用第三方框架会增加该大小．
如果应用创建很多线程，在申请更多线程栈内存会报StackOverFlowError错误.
可以用设置最大线程栈内存: -Xss256k 或　-XX:ThreadStackSize=256
也可以压缩操作符和类指针:
-XX:&#43;UseCompressedClassPointers
-XX:&#43;UseCompressedOops
原则:
 一般没必要设置该值，除非64bit　JVM的物理内存较小产生OutOfMemory错误 设置为较小的值可以有更大的Heap size 一般来说，64bit　JVM使用256k足够用  OOM问题 针对Tomcat
# 检索gc日志 grep &amp;#39;java.lang.OutOfMemoryError: GC overhead limit exceeded&amp;#39; catalina.2016-10-25.log # 记录heap dump，setenv.sh XX:&#43;HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/tomcat/logs/ GC日志 参数设置 一些gc日志参数，经常使用的:
-verbosegc
-Xloggc:/var/log/gc.log
设置更详细日志
-XX:&#43;PrintGC
-XX:&#43;PrintGCDetails
显示时间
-XX:&#43;PrintGCTimeStamps
-XX:&#43;PrintGCDateStamps
日志分析 Allocation Failure：运行GC（一般是新生代回收即minor GC）的原因，意味着新生代已没有空间.
一共存在8种OutOfMemoryErrors , GC日志可以记录5种:
 Java heap space GC overhead limit exceeded Requested array size exceeded VM limit Permgen space Metaspace  名称缩写  JRE: Java Runtime Environment JDK: Java Development Kit JVM： Java Virtual Machine GC: Garbage Collection JMX: Java Management Extentions JPA: Java Persistence API  工具 GC日志分析  jstat: 命令行工具 Visual GC GCViewer 在线gc日志分析  Heap Dump分析  JHAT &amp;gt; jhat heap-dump.hprof Eclipse Memory Analyzer (MAT) IBM HeapAnalyzer:貌似已停更  获取heap dump  jmap -dump : 运行时获得(会停止java进程) JConsole使用 HotSpotDiagnosticMXBean 使用JVM参数 -XX:&#43;HeapDumpOnOutOfMemoryError 使用hprof命令: java -agentlib:hprof=help  获取ThreadDump  jstack -l  &amp;gt;&amp;gt; threadinfo.log kill -3  jcmd &amp;lt;pid&amp;gt; Thread.print &amp;gt; &amp;lt;file-path&amp;gt;  参考资源 官方文档：
 Getting Started with the G1 Garbage Collector HotSpot Virtual Machine Garbage Collection Tuning Guide Java Virtual Machine Troubleshooting  其他：
 GC Handbook ： GC手册 JVM Anatomy Park ：深入讲解JVM How to Tune Java Garbage Collection </content>
    </entry>
    
     <entry>
        <title>全链路压测笔记续</title>
        <url>/blog/more-load-test-note/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>performance</tag>
        </tags>
        <content type="html"> 看完美团的分享觉得不过瘾，继续学习其他大厂的分享。
不用猜，第一个搞出这套系统的一定是阿里，因为他的双11需求最迫切。

阿里分享 2013年为了双11提前预演而诞生,该服务已提供在阿里云PTS铂金版。
 系统稳定性保障核武器——全链路压测 双11核武器——全链路压测详解  可用性及单机压测问题 系统可用性问题 经常由下面一些不确定性因素引起：
 系统容量 业务性能 基础设施瓶颈 中间件瓶颈 系统直接的依赖影响  传统线上单机与单系统压测的四种方式  模拟调用者压测生产环境：读请求&#43;写请求（需要特定处理） 流量录制和回放：快速率回放对单机压测  从流量分配的角度，将流量集中到某台机器（这两种方式要求访问流量不能太小）：
 请求流量转发 改变负载均衡的权重  单系统压测的问题  在做单个系统的容量规划时，所有的依赖环节能力是无限的，进而使得我们获取的单机能力值是偏乐观的； 采用单系统规划时，无法保证所有系统均一步到位，大多数精力都集中核心少数核心系统； 部分问题只有在真正大流量下才会暴露，比如网络带宽等等。  全链路压测组成 单链路指一个业务线。
全链路压测是一个模拟线上环境的完整闭环，由5大核心要素组成：
 压测环境：对应用户真实的线上环境，具备数据与流量隔离能力的生产环境； 原则：能够用中间件解决的问题，绝不对业务系统进行改造，系统所需做的是升级中间件，这一原则极大提高了工作效率。 压测基础数据：构造满足高峰场景的核心基础相关数据，影子库里构造相同量级的数据； 真实线上数据筛选脱敏。 压测流量（模型、数据）：成百上千的接口组合，到复杂的接口之间的参数传递，复杂的条件判断来构造精准的全局流量模型，和真实业务情况保持一致；
&amp;gt; 压测引擎的三层结构：  协议支持 请求发送：CGroup资源隔离，异步Reactor模型发送请求，链路间线程池隔离 集群协作： Master，Slave长连接； Cristian算法同步网络延迟，Slave动作一致；  流量发起：模拟全国各地真实的用户请求访问，探测站点能力； 问题定位：多维度的监控和报表，服务端可通过其他生态产品协助定位。  翻译构造能力的体现：便捷的构造全局业务场景和流量数据的能力。
原子因素：链路（被压测的最小单位） 指令： 思考时间、集合点、条件跳转、cookie存取、全局准备、并发用户限制等
原子因素-&amp;gt;串行链路-&amp;gt;场景
超限后的流量控制  丢弃请求 对下游降级 黑白名单 请求排队  流量平台数据量  T级别的压测请求数据 每秒1600W&#43;次请求压测能力 维持1亿&#43;的无线长连接和登陆用户 秒级的智能数据调度和引擎调度能力  京东分享 ForgeBot， 2016年开发
京东全链路压测军演系统(ForceBot)架构解密
最早基于开源的NGrinder，能胜任单业务压测。Controller功能耦合重，支持的Agent数量有限。 之后开发了ForgeBot。
主要功能模块  Controller：任务分配 Task Service：负载任务下发，支持横向扩展。提供任务交互和注册服务。（gRPC:HTTP2&#43;protobuf3） Agent：注册心跳，拉取任务、更新任务状态、 执行和停止worker process（采用Docker容器部署） Monitor Service:接受并转发压测数据给JMQ DataFlow:对压测数据做流式计算(输出TPS,TP999,TP99,TP90,TP50,MAX,MIN)，将计算结果存到DB(ES)  在管理端创建测试场景，Controller扫描发现场景，寻找空闲Agent资源。
任务分配时，Controller计算每个间隔的执行时间点和递增的虚拟用户数，由Agent动态加压减压。
在多个组件使用了gRPC框架通讯
分读压测和写压测
一些解决问题的思路 问题：如何模拟在某一个瞬间压力达到峰值？
解决方案：通过集合点功能实现，提前开启峰值所需足够数量的线程，通过计算确定各个时间点上不需要执行任务的线程数量，通过条件锁让这些线程阻塞。当压力需要急剧变化时，我们从这些阻塞的线程中唤醒足够数量的线程，使更多的线程在短时间进入对目标服务压测的任务。
问题：为了计算整体的 TPS，需要每个Agent把每次调用的性能数据上报，会产生大量的数据，如果进行有效的传输？
解决方案：对每秒的性能数据进行了必要的合并，组提交到监控服务
饿了么分享 饿了么全链路压测平台的实现与原理
业务模型的梳理  是否关键路径 业务的调用关系 业务的提供的接口列表 接口类型(http、thrift、soa等) 读接口还是写接口？ 各接口之间的比例关系  数据模型的构建 写请求 压测方法：
 用户、商户、菜品等在数量上与线上等比例缩放； 对压测流量进行特殊标记； 根据压测标记对支付，短信等环节进行mock； 根据压测标记进行数据清理；
读请求 压测方法：拉取线上日志，根据真实接口比例关系进行回放
  无日志服务 压测方法：
 构建压测数据使缓存命中率为0%时，服务接口性能，数据库性能； 缓存命中率为100%时，服务接口性能； 缓存命中率达到业务预估值时，服务接口性能；  压测工具 定制JMeter
压测指标监控和收集  应用层面 服务器资源 基础服务：中间件和数据库  要点：
 响应时间不要用平均响应时间，关注95线； 吞吐量和响应时间挂钩 吞吐量和成功率挂钩  具体实现 SpringBoot&#43;AngularJS.
测试期间产生的冷数据(用例数据、结果数据)持久化至MongoDB，热数据(实时数据)持久化至InfluxDB并定期清理。
分布式测试：重新实现JMeter的分布式调度
测试状态流转：各种流程形成闭环，要考虑各种异常。
主要流程：配置 -&amp;gt; 触发 -&amp;gt; 运行 -&amp;gt; 结果收集 -&amp;gt; 清理。
整个状态流转的实现，采用异步Job机制实现了类似状态机的概念，状态属性持久化到数据库中，便于恢复。
安全保障 由于是在线上真实环境，需要避免测试引起的服务不可用和事故。
 权限管理：用户权限分级管理，不能随意触发他人的测试用例，同时高峰期和禁止发布期，不允许执行任何测试。 停止功能：这是面向用户的手动停止功能，用户可以随时点击运行状态下的测试用例上的停止按钮，后台会直接kill掉所有运行该测试用例的测试机上的JMeter进程。 熔断功能：系统会根据实时信息中的错误率进行判断，当一定时间内的实时错误率达到或超过某个阈值时，该次测试将被自动熔断，无需用户干预。 兜底脚本：最极端的情况，当整个系统不可用，而此时需要停止测试时，我们提供了一份外部脚本直接进行停止。 </content>
    </entry>
    
     <entry>
        <title>美团全链路压测Quake学习笔记</title>
        <url>/blog/meituan-load-test-note/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>testing</tag><tag>performance</tag>
        </tags>
        <content type="html"> 今天读了美团技术团队新发布的全链路压测平台Quake在美团中的实践，做个笔记。
先说下总的读后感:
压力测试/性能测试有多种方式，从下面的几个发展阶段可以看出越来越追求真实高峰访问的模拟。
现在大公司普遍的分布式架构，云计算的应用，容器的使用也可以提供更有力的资源调度。但全链路压测最重要的工作在于需要架构，开发团队的支持和适配工作。
没有全链路的监控及相关工具支撑，没有架构的调整（压测标识）和数据库的配合（影子表），这个全链路压测就是个听起来更美的名字（你也知道技术圈喜欢造新词）。
印象中APM/Application Performance Management 前几年就挺火的，现在各大厂又都在提全链路了。

 文章笔记摘要
 背景 要解决的问题  验证峰值流量下服务的稳定性和伸缩性 验证新上线功能的稳定性 进行降级、报警等故障演练 对线上服务进行更准确的容量评估  压力测试方式的几个阶段  对线上的单机或集群发起服务调用 将线上流量进行录制，然后在单台机器上进行回放 通过修改权重的方式进行引流压测 全链路压测  全链路压测介绍 基于线上真实环境和实际业务场景，通过模拟海量的用户请求，对整个系统进行压力测试。
主要特征：
 真实流量 线上环境 实时监控和过载保护  核心功能 数据构造 回放业务高峰期产生的流量
 HTTP： Nginx Access Log分析 RPC：对部分机器录制  通过以上两种方式生成压测词表（词表分片处理，方便后续批量加载）
压测隔离 添加压测标识，各服务和中间件依据标识来进行压测服务的分组和影子表方案的实施。
在请求头添加特殊标识，但需要保证线程间和跨服务间透传。
链路诊断功能方便定位问题。
服务隔离 通常选择深夜低峰压测，同时隔离正常流量和测试流量。 隔离策略：基于IP，机器数，百分比
数据隔离 影子表（阿里）：使用线上同一个数据库，包括共享数据库中的内存资源，只在写入数据时写进另一个影子表。 KV的处理类似，MQ则选择生产端或消费端忽略消息。
调度中心 资源计算预估  压测期望到达的QPS 压测请求的平均响应时间和请求/响应体大小 压测的词表大小、分片数 压测类型  事件注入机制 根据系统的实际情况对压力进行相应调整。
 调整QPS 触发熔断 开启事故注入 开启代码级性能分析  代码设计：观察者模式（会触发的事件）和责任链模式（执行事件）
熔断保护机制 客户端熔断： 根据业务自定义的熔断阈值，实时分析监控数据，当达到熔断阈值时，任务调度器会向压测引擎发送降低QPS或者直接中断压测的指令，防止系统被压挂。
</content>
    </entry>
    
     <entry>
        <title>再学游泳</title>
        <url>/play/swimming/</url>
        <categories>
          <category>play</category>
        </categories>
        <tags>
          <tag>health</tag>
        </tags>
        <content type="html"> 最近再次开始学游泳，距离初次学蛙泳已经过去了10多年。当时还在大学蹭宿舍，因为一直很喜欢向往大海，便让老同学教我蛙泳。 期间由于基础不行，某次在深水区溺水给我留下了阴影，之后参与便不积极，直到搬家远离了游泳馆，便不再接触该运动了。 这段时间有短短续续的一年多，现在想来最后可能也就40～50分，主要是基础动作不对，连续换气困难，对深水不自在。
这次的契机是8月初公司组织去南戴河，去之前复习了游泳，结果到海里一旦脚够不着底就很慌不敢游，也呛了好几口海水。回来后从知乎开始学习，跟着“网红”教练梦觉（易鑫海）又到B站，几乎看了所有视频，受益良多。
现在水性（和水的亲和感）好多了，学会了基本的潜泳，前滚翻，仰泳腿，也学会了踩水,可以再次游到深水区了。
蛙泳练的差不多了，现在已改学自由泳,自由泳腿刚有感觉。
能继续参与的另一个原因是之前找到运动方式要么时间空间受限，要么热情不够。而自从上个月开始游泳，每次都有小的进步，这种感觉还是很爽的。
也欢迎大家关注讲解细致幽默系统的易教练，视频里的错误动作，我这个新手80%都犯过。
 B站：https://space.bilibili.com/7283282/#/index 知乎：怎样快速有效地学习游泳？  也该感谢这个内容创业火热的年代，让优质的教学内容有好的生长空间，让自学更容易了。
</content>
    </entry>
    
     <entry>
        <title>Ubuntu日常</title>
        <url>/blog/ubuntu/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html">  很早就接触使用Ubuntu，也是自己最钟爱的Linux系统。 给Ubuntu留一篇记录日常使用。
Ubuntu 18.04安装中文输入法 sogou拼音由于不支持最新的18.04，所以安装系统自带的中文输入法。 PS. Sublime Text 3不支持中文输入也很不爽。
安装中文语言 [Settings] - [Region &amp;amp; Language],点击“Manage Insalled Languages”,点击“Install/Remove Language”,勾选“Chinese(simplified)”并点击“Apply”.
或者直接使用命令行：
sudo apt install language-pack-zh-hans language-pack-gnome-zh-hans thunderbird-locale-zh-hans firefox-locale-zh-hans kde-l10n-zhcn fonts-arphic-ukai libreoffice-l10n-zh-cn kde-config-fcitx hunspell-en-za hyphen-en-ca mythes-en-au gnome-user-docs-zh-hans fonts-arphic-uming thunderbird-locale-zh-cn libreoffice-l10n-en-za kde-l10n-engb hyphen-en-gb libreoffice-l10n-en-gb ibus-table-wubi ibus-libpinyin libreoffice-help-zh-cn thunderbird-locale-en-gb fonts-noto-cjk-extra hunspell-en-au hunspell-en-gb hunspell-en-ca libreoffice-help-en-gb  添加智能中文输入法 注： 可能需要先Logout下。
之后在[Settings] - [Region &amp;amp; Language]的“Input Sources”选择 [Chinese]-[Chinese(Intelligent Pinyin)]并添加。
Ubuntu/Linux下常用软件  图像编辑： GIMP （[编辑]-[首选项]-[界面]下设置中文） 编辑器： sublimetext3/vscode FTP： FileZilla  </content>
    </entry>
    
     <entry>
        <title>MySQL性能优化</title>
        <url>/blog/mysql-tuning/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>database</tag><tag>mysql</tag>
        </tags>
        <content type="html"> 关于MySQL性能问题查找及优化的点滴. 常用参数 # /etc/my.cnf [mysqld] max_connections=1000 # 最大连接数 innodb_buffer_pool_size=4G # 缓存池大小,建议&amp;lt; 80% 总内存  # 时间超过2秒的SQL记录在慢查询日志 long_query_time=2 # 用以下面响应时间分布的收集 query_response_time_stats = on innodb_buffer_pool_size 推荐大小 计算RIBPS(Recommended InnoDB Buffer Pool Size)基于所有InnoDB数据大小和额外60%索引大小.
SELECT CEILING(Total_InnoDB_Bytes*1.6/POWER(1024,3)) RIBPS FROM (SELECT SUM(data_length&#43;index_length) Total_InnoDB_Bytes FROM information_schema.tables WHERE engine=&amp;#39;InnoDB&amp;#39;) A; 实际占用大小为:
SELECT (PagesData*PageSize)/POWER(1024,3) DataGB FROM (SELECT variable_value PagesData FROM information_schema.global_status WHERE variable_name=&amp;#39;Innodb_buffer_pool_pages_data&amp;#39;) A,(SELECT variable_value PageSize FROM information_schema.global_status WHERE variable_name=&amp;#39;Innodb_page_size&amp;#39;) B; 利用多核CPU # 无限并发 innodb_thread_concurrency = 0 # 下面两个值最大设置为64 innodb_read_io_threads innodb_write_io_threads 检查当前慢查询并运行EXPLAIN mysql&amp;gt; SHOW FULL PROCESSLIST; # 找到上面经常出现的SQL语句 EXPLAIN SQL-Statement  状态sending data意味着正在等待从磁盘或内存读取数据并发送出去,即 reading and filtering data.
 PMM的MySQL Query Response Time仪表盘 PMM(Percona Monitoring and Management)的开源监控工具还是很好用的.
安装PMM服务端 建议使用docker的方式
# 获取镜像 docker pull percona/pmm-server:latest # 创建容器 docker create \  -v /opt/prometheus/data \  -v /opt/consul-data \  -v /var/lib/mysql \  -v /var/lib/grafana \  --name pmm-data \  percona/pmm-server:latest /bin/true # 运行 docker run -d \  -p 80:80 \  --volumes-from pmm-data \  --name pmm-server \  --restart always \  percona/pmm-server:latest 配置客户端 (在运行MySQL的主机) yum install -y pmm-client # Ubuntu 先获取 # wget https://www.percona.com/downloads/pmm/1.13.0/binary/debian/xenial/x86_64/pmm-client_1.13.0-1.xenial_amd64.deb sudo pmm-admin config --server 192.168.100.1 # 可选项 —server-user admin —server-password admin  sudo pmm-admin add mysql —user root —password password # 查看当前状态 sudo pmm-admin list pmm-admin使用  pmm-admin ping pmm-admin config pmm-admin info pmm-admin stop —all pmm-admin uninstall  设置以记录Response Time分布 安装必要的插件:
mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME &amp;#39;query_response_time.so&amp;#39;; mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME SONAME &amp;#39;query_response_time.so&amp;#39;; mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME_READ SONAME &amp;#39;query_response_time.so&amp;#39;; mysql&amp;gt; INSTALL PLUGIN QUERY_RESPONSE_TIME_WRITE SONAME &amp;#39;query_response_time.so&amp;#39;; # 检查当前安装插件状态 mysql&amp;gt; SHOW PLUGINS; 开启数据收集:
SET GLOBAL query_response_time_stats = &amp;#39;ON&amp;#39;; # 检查是否生效 show variables like &amp;#39;%query_response_time%&amp;#39;; 资源  EXPLAIN执行计划讲解 PMM Server官方文档 </content>
    </entry>
    
     <entry>
        <title>Java应用的数据库迁移工具Flyway</title>
        <url>/blog/java-db-migrate/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>database</tag>
        </tags>
        <content type="html"> 最近折腾部署一年前的一个应用,发现一些由于一些细节已经忘记,常常可能多花费几个小时去重新解决问题的过程. 而有的过程之前写过KB,关键字一搜索就出来能省不少时间.
所以对于健忘的自己,还是多些记录,也不介意技术含量这个概念了.
印象中flyway应该是Java生态中很成熟的一个解决方案了,简略的记下使用过程.

安装 wget https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/5.1.4/flyway-commandline-5.1.4-linux-x64.tar.gz tar xzf flyway-commandline-5.1.4-linux-x64.tar.gz # 可选 cp mysql-connector-java-5.1.41.jar /opt/flyway-5.1.4/drivers/ 配置 主要在conf/flyway.conf文件
# 必须项 flyway.url=jdbc:mysql://&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;database&amp;gt; flyway.user=test flyway.password=test # 升级数据库脚本位置 flyway.locations=filesystem:/opt/db/migration/ # 可选 # 用于非空数据库首次使用 flyway.baselineOnMigrate=true 使用 # 清空数据 ./flyway clean # 升级/迁移数据 ./flyway migrate 资源  Flyway官网 </content>
    </entry>
    
     <entry>
        <title>Go并发编程笔记</title>
        <url>/blog/go-concurrency/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 最近尝试用Go重写以前Python的一个工具,感觉一直工作于Hard模式,可是又不想轻易的放弃Golang的实践,因为遇到一些问题最终变成从入门到放弃.
还好一周周坚持了下来,虽然遇到一个问题可能会解决多半天甚至一天多时间,还是有所学的.
今天整理下关于并发编程,也就是Go核心亮点goroutine使用中可能遇到的问题.

敲重点 运行是一定打开 -race 命令行参数 该标记会打印产生读写冲突/数据竞争的错误及stacktrace, 避免到生产环境才发现问题.
绝对是提早排查的利器, 也算Go的优势之一 :)
其他应用: 该参数也可以加在test,build,run等命令, 由于生成带检测的build会消耗更多内存和CPU,建议生产环境不要部署或只部署其中一台节点.
并发Map 默认的map是不支持并发读写的, 如果违法了后果很严重,主程序直接异常退出,通常会看到如下的错误:
 fatal error: concurrent map writes
 解决方式有三个:
 仍使用原生map,用sync.RWMutex加锁 使用 1.9 引入的 sync.Map, 适用于读远大于写的情景(方法少了些) 使用 第三方库concurrent-map （sharding方式,更适合以内存数据库方式使用）  // 加锁的示例, 修改自SO的一个例子 // 锁可以被任意读或唯一的写协程所持有 var m = map[string]int{&amp;#34;a&amp;#34;: 1} var lock = sync.RWMutex{} func read() { lock.RLock() _ = m[&amp;#34;a&amp;#34;] lock.RUnlock() } func write() { lock.Lock() m[&amp;#34;b&amp;#34;] = 2 lock.Unlock() }</content>
    </entry>
    
     <entry>
        <title>开源消息队列实现</title>
        <url>/blog/mq/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>middleware</tag><tag>message</tag>
        </tags>
        <content type="html"> 经常会遇到系统中使用Message Queue/消息队列的情况, 与此类似的模型还有 pubsub/发布订阅模式(publisher/subscriber).
这两种模型的实现也被看做 消息中间件/MOM(Message-Oriented Middleware),因为这种结构解耦了发送端和接收端,简化了架构.
另外常提的一个概念是Messaging Broker, 更多的用于消息验证,转换,路由.

现在有很多流行的开源实现, 对于消息有常用的三种标准:
 AMQP: Advanced Message Queuing Protocol STOMP: Streaming Text Oriented Messaging Protocol MQTT/ MQ Telemetry Transport: 轻量级协议,IoT标准  其他
 XMPP/Extensible Messaging and Presence Protocol: 基于XML的通讯协议  前两个基于HTTP, 后一个基于TCP/IP.
 下面是一些实现的概要描述, 这些实现的比较不全在同一纬度, 只是看那个更适合你的应用场景,语言绑定等.
开源实现    名称 语言 星数 描述     ActiveMQ Java 1.1 k Apache基金旗下, 支持JMS   RabbitMQ Erlang 4.3k 貌似MQ系列的首选,成熟且性能高   ZeroMQ C&#43;&#43; 4.4k    Celery Python 10k 异步任务队列,常用于耗时操作的异步执行   Redis C 30.3k 最流行的内存KV数据库/缓存   Kafka Java/Scala 9k 早期LinkedIn开源产品,后归于Apache基金. 常用于日志处理分析   NATS Go 4.4k CNCF孵化项目   NSQ Go 12k 项目近期发布不活跃    注: 只接触过Celery,Redis和Kafka, MQ系列没有使用经验不做过多介绍.
示例 TBC&amp;hellip;
</content>
    </entry>
    
     <entry>
        <title>网络基础</title>
        <url>/blog/network/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>network</tag>
        </tags>
        <content type="html"> 好记性不如烂笔头, 网络基础知识备忘.

OSI 7层模型 OSI/开放式系统互联通讯参考
 7: 应用层: HTTP,FTP,Telnet, SSH, SMTP, POP3 6: 表达层 5: 会话层 4: 传输层: TCP 3: 网络层: IP 2: 数据链路层: 以太网,WiFi,GPRS 1: 物理层 : 数据帧传输,包括网卡,集线器,主机适配器等  注: OSI参考模型不是一个标准,也没有提供实现方法,而且概念性框架.
TCP/IP协议集 互联网基础协议, 可以被认为是简化版OSI模型
 应用层: HTTP, DNS 传输层: TCP, UDP 网络互连层(internet): IP  基于IP的高层协议  ICMP: IP发送诊断信息 IGMP: 管理多播数据   网络接口层(link): 以太网等  每个应用层协议一般会使用到两个传输层协议之一:
 面向连接的TCP传输控制协议 无连接的包传输的UDP用户数据报文协议  常用协议归类
 运行于TCP协议上的协议: HTTP/HTTPS/FTP/POP3/SMTP/TELNET/SSH 运行于UDP协议上的协议: BOOTP/NTP/DHCP 运行于TCP和UDP的协议: DNS/ECHO 其他协议: SNMP(简单网络管理协议)/ARP(地址解析协议)  DNS/域名系统  域名和IP地址互相映射的分布式数据库. 使用TCP和UDP的53端口. 每级域名长度限制63,域名总长度不超过253字符.  记录类型  主机记录/A记录: 将特定的主机名映射到对应主机的IP地址上 别名记录/CNAME记录: 将某个别名指向到A记录 IPv6主机记录/AAAA记录: 与A记录对应, 映射到IPv6地址 服务位置记录/SRV记录: 定义提供特定服务的服务器位置,如hostname,端口等  实现 全球有13组,504个根域名服务器, 为层次结构.
常用软件实现:
 BIND/Berkeley Internet Name Domain CoreDNS: Kubernetes默认的DNS Server  WHOIS/域名数据库查询
新的规定,域名机构不能返回注册者隐私信息.
NAT/网络地址转换 IP数据包通过路由器/防火墙时重写来源/目的IP的技术.
重写源/目的IP和端口.
解决的问题:
 局域网环境只有一个公网IP 负载均衡: 重定向到随机服务器 失效终极: 转换到备用服务器,提高可靠性 透明代理: 重定向到指定HTTP代理以缓存数据和过滤请求  HTTP/HTTP2 协议
客户端(用户)和服务器端(网站)请求和应答标准.
请求方法 GET/HEAD/POST/PUT/DELETE/TRACE/OPTIONS/CONNECT/PATCH
HTTP服务器至少应该实现GET和HEAD方法.
版本  HTTP/1.1: 1999年制定. 默认保持连接(Keep-Alive) HTTP/2: 2015年发布, 基于SPDY(Google主导的替代HTTP的项目,已被HTTP2取代). 主要为性能改进, 主流浏览器只支持加密通讯(即h2).  状态码 HTTP响应的第一行都是状态行, 状态代码是3位数字:
 1xx消息——请求已被服务器接收，继续处理 2xx成功——请求已成功被服务器接收、理解、并接受 3xx重定向——需要后续操作才能完成这一请求 4xx请求错误——请求含有词法错误或者无法被执行 5xx服务器错误——服务器在处理某个正确请求时发生错误  例子 # 请求信息: # 1. 请求行:指定方法、资源路径、协议版本 # 2. 请求头(Host是必须项) GET / HTTP/1.1 Host: www.google.com # 服务器应答 HTTP/1.1 200 OK Content-Length: 3059 Server: GWS/2.0 Date: Sat, 11 Jan 2003 02:44:04 GMT Content-Type: text/html Cache-control: private Set-Cookie: PREF=ID=73d4aef52e57bae9:TM=1042253044:LM=1042253044:S=SMCc_HRPCQiqy X9j; expires=Sun, 17-Jan-2038 19:14:07 GMT; path=/; domain=.google.com Connection: keep-alive IP/因特网协议 子网指具有相同的前半部分地址的一组ip地址.
子网掩码/subnet mask 目的: 用来指明一个IP地址的哪些位标识的是主机所在的网络地址以及哪些位标识的是主机地址的位掩码.
可以表示为同地址一样的形式,也可以使用更简短的CIDR/无类别域间路由表示法.
比如 192.0.2.96/28表示的是一个前28位被用作网络号的IP地址（和255.255.255.240的意思一样）
IPv4子网 IPv4地址分3个部分: 网络部分,子网部分和主机部分.
共有3类IP地址,分别指定各部分占多少位.
   类别 起始位 开始 结束 点分十进制掩码 CIDR     A 0 0.0.0.0 127.0.0.0 255.0.0.0 /8   B 10 128.0.0.0 191.255.0.0 255.255.0.0 /16   C 110 192.0.0.0 223.255.255.0 255.255.255.0 /24    Docker网络 Docker 网络实质上是操纵Network Namespace, 网桥, 虚拟网卡及iptables实现的.
OVS (Open vSwitch): 开源虚拟交换机
ip netns 管理Network Namespace ip link 管理layer2网络 ip addr 管理layer3网络 sudo apt install bridge-utils brctl show # 内核IP路由表 route -n 软件定义网络 flannel: 虚拟网络,给每台主机划分一个子网用于容器运行时
</content>
    </entry>
    
     <entry>
        <title>Kubernetes和云原生计算</title>
        <url>/blog/cloud-native/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>cloud</tag>
        </tags>
        <content type="html"> 最早注意到云原生这个概念是某次看文章说Kubernetes是作为CNCF(云原生计算基金会)的主要项目来开发的,该基金会属于Linux基金会旗下,还包括被熟知的prometheus,istio等开源项目, 似乎可以理解为Kubernetes生态系统.
至此Kubernetes把微服务,十二要素,服务网格/Service Mesh等串联了起来, 符合这些概念的应用架构就是云原生应用.

云原生计算 提到云计算,现在主流的分类及代表是:
 IaaS/基础设施:AWS,OpenStack PaaS/平台: Heroku, Cloud Foundry SaaS/软件,应用:  从云计算的角度看, 云原生计算可被看做是最新发展阶段.云原生/Cloud Native的代表技术:
 容器 服务网格 微服务 不可变基础设施 声明式API  相比传统应用架构, 云原生具备的优势是:
 敏捷 可靠 高弹性 易扩展 故障隔离保护 不中断业务持续更新  技术圈的造词运动没有停止过, 下面顺便学习下这两个新词:
 Serverless/无服务器技术: 也不算新概念,这里并不是真的不需要后端服务器,而是后端服务以服务的形式提供,或被称为Backend-as-a-Service/BaaS,通常简化移动端开发部署的成本,前几年最成功的代表Parse被Facebook收购后很快关闭服务,BaaS也随之不被提及. 这两年随着Amazon Lambda服务的火热, ServerLess又被提起,同时造了个新词:FaaS/Function-as-a-Service, 这可能是云服务平台乐于推广的,不过现在看来,应用场景似乎比较受限.  扩展阅读  CNCF官网 云原生概览 云原生详解 云原生语言:Pulumi </content>
    </entry>
    
     <entry>
        <title>私有Docker仓库Harbor</title>
        <url>/blog/harbor/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>docker</tag><tag>ops</tag>
        </tags>
        <content type="html">  提到私有容器仓库,VMWare出品的开源Harbor算是首选.
安装和配置照官方文档来很简单,今天在尝试push镜像时遇到了如下错误: &amp;ldquo;Get https://yourdomain.com/v2/: Service Unavailable&amp;rdquo;, 检查之下发现是没有配置https引起.
 配置https 虽然可以给docker常驻进程添加&amp;ndash;insecure-registry 这个参数而改用默认的http协议(需要重启docker), 但该参数会使本机所有的注册服务都不再安全, 极力不推荐这么做.
配置https的步骤其实不复杂,记录如下:
先使用mkcert生成证书和密钥, 该工具见上篇证书一文 注: mkcert的方式对docker/k8s会产生问题, 改用官方证书生成方式
# 创建CA证书 openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt # 生成CSR openssl req -newkey rsa:4096 -nodes -sha256 -keyout yourdomain.com.key -out yourdomain.com.csr # 生成域名证书 penssl x509 -req -days 365 -in yourdomain.com.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out yourdomain.com.crt # 复制证书到服务器 ssh yourdomain.com &amp;#34;mkdir -p /data/cert&amp;#34; scp yourdomain.com*.pem yourdomain.com:/data/cert vi ~/harbor/harbor.cfg 编辑如下内容:
hostname = yourdomain.com ui_url_protocol = https ssl_cert = /data/cert/yourdomain.com.crt ssl_cert_key = /data/cert/yourdomain.com.key 之后重启harbor服务:
./prepare docker-compose down docker-compose up -d 配置docker客户端进程https 解决错误:&amp;ldquo;Error response from daemon: Get v1/_ping: x509: certificate signed by unknown authority&amp;rdquo;
cd /etc/docker/certs.d/yourdomain.com # 复制上一节生成的ca.crt到此  # 产生客户端证书 openssl genrsa -out client.key 4096 openssl req -new -x509 -text -key client.key -out client.cert 最终目录结构如下: tree /etc/docker/certs.d/yourdomain.com
. ├── ca.crt ├── client.cert └── client.key Ubuntu可能需要更新系统证书:
cp youdomain.com.crt /usr/local/share/ca-certificates/ update-ca-certificates 为kubernetes节点设置验证 # 在其中一台节点登录私有仓库 docker login reg.server # 会更新$HOME/.docker/config.json  # 复制到其他节点 nodes=$(kubectl get nodes -o jsonpath=&amp;#39;{range.items[*].metadata}{.name} {end}&amp;#39;) for n in $nodes; do scp ~/.docker/config.json root@$n:/root/.docker/config.json; done 备注 Web UI 默认用户名/密码: admin/Harbor12345
推送本地镜像到该仓库 docker login yourdomain.com docker tag myimg:mytag yourdomain.com/pt/myimg:mytag docker push yourdomain.com/myproject/myimg:mytag Docker Notary Harbor可以和Notary结合, Notary是一个内容数字签名服务,保证分发的内容/镜像可信.
资源  官网 安装配置向导 https配置向导 k8s镜像文档  </content>
    </entry>
    
     <entry>
        <title>证书那些事</title>
        <url>/blog/cert/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>crypto</tag><tag>networking</tag>
        </tags>
        <content type="html"> 断断续续接触过加密通讯的一些场景, 随着近两年安全的普及,建站使用https也成为标配.
这篇文章试图汇总下证书这块的知识提纲.

基本概念 认证和鉴权 经常容易混淆的两个概念.
 Authentication: 验证你是你所说的人,即通讯中某端的身份识别机制. 通常用于访问控制 Authorization: 验证你被许可你正在试图做的事. 用于用户识别访问权限  客户端证书 通常用户客户端/用户身份识别.
Client Certificate Authentication 用于相互的认证机制.
服务端证书 通常用于加解密内容.
区分客户端/服务端证书可以通过查看&amp;rdquo;Enhanced Key Usage&amp;rdquo;字段.
证书应用 通常用于认证/隐私/加密/数字签名.
常见数字证书类型  Certificate Signing Request (.csr) Base64编码的X.509证书 (.cer/.crt) (用于导出) DER编码的二进制X.509证书(.cer/.der/.crt) 加密消息语法标准 (PKCS#7) 证书 (.p7b/.p7r/.spc) 个人信息交换格式 (PKCS#12) 证书 (.pfx/.p12)/ Java Keystore (JKS) Privacy-enhanced Electronic Mail (.pem) (Base64编码改进版,OpenSSL所使用)  PKCS#12 证书用于客户端, 是唯一可以被导出证书和私钥的文件格式.
.pem格式可以在一个文件包含下面一种/全部的信息:
 Issued Public Certificate (Client/Server) Intermediate CA Certificate Root CA certificate Private Key(.key) (Linux or Java) Certificate Revocation List (.crl extension) (CRL Distribution Points) Certificate Trust List (.stl)  # 转换pem格式到crt格式 openssl x509 -outform der -in ca.pem -out ca.crt SSL单向认证和SSL双向认证  SSL单向认证只要求站点部署了ssl证书就行，任何用户都可以去访问(IP被限制除外等)，只是服务端提供了身份认证。一般Web应用都是采用SSL单向认证的 双向认证则是需要服务端与客户端提供身份认证，只能是服务端允许的客户能去访问，安全性相对于要高一些。  通配符证书/Wild Card Certificates 在host包含*来匹配多个子域名, 但*只可以匹配一级子域名.
SAN/Subject Alternative Name也可以包含通配符主机名.
证书体系 CA含权威的第三方公开证书认证机构和内部认证机构(Enterprise CA).
Root CA/根证书机构 权威的根证书机构, 与中间证书机构的区别:
 Issued to 和Issued by是同一机构. Certification Path位于顶级  本身是自签证书.
Intermediate CA/中间证书机构 作为PKI体系的一部分,使证书结构可扩展. Root CA 把任务代理给Intermediate CA.
自签证书 顾名思义, Issued to 和Issued by 是同一机构/人. 通常用户非生产环境.
浏览器会显示警告为不可信任, 因为不被公共的根证书机构认可.
证书实战 mkcert 最简单的生成证书方式, 可用于开发测试环境
mkcert -install mkcert example.com &amp;#39;*.example.org&amp;#39; 127.0.0.1 openssl使用 # Ubuntu生成自签名服务端证书和私钥 openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /home/xulz/certs/server.key -out /home/xulz/certs/server.crt # 生成证书和密钥到一个文件 openssl req -x509 -nodes -days 365 -new -keyout /home/xulz/certs/mail.pem -out /home/xulz/certs/mail.pem #key和cert分开创建 openssl genrsa 2048 -out key.pem openssl req -x509 -nodes -days 365 -new -key key.pem -out cert.pem# 其他命令示例 # 产生私钥 openssl genrsa -aes256 4096 -out key.pem # 产生不被密码保护的密钥 openssl genrsa 4096 -out key.pem # 使用新版genpkey命令 openssl genpkey -algorithm RSA -out key.pem -aes-256-cbc -pkeyopt rsa_keygen_bits:4096 # 改用更强算法加密 openssl pkcs12 -in weak.p12 -nodes -out decrypted.pem openssl pkcs12 -export -in decrypted.pem -keypbe AES-128-CBC -certpbe AES-128-CBC -out strong.p12 openssl req命令行参数
 -new new request. -out arg output file -nodes don&amp;rsquo;t encrypt the output key -x509 output a x509 structure instead of a cert. req. -days number of days a certificate generated by -x509 is valid for. -keyout arg file to send the key to -key file use the private key contained in file   openssl genpkey [-out filename] [-outform PEM|DER] [-pass arg] [-cipher] [-engine id] [-paramfile file] [-algorithm alg] [-pkeyopt opt:value] [-genparam] [-text]
openssl genrsa [-out filename] [-passout arg] [-des] [-des3] [-idea] [-f4] [-3] [-rand file(s)] [-engine id] [numbits]
 keytool Linux/Mac中OpenSSL的证书和密钥管理工具
# 产生密钥对 keytool -genkeypair -alias test123 -keystore test123.pfx -storepass test123 -validity 365 - keyalg RSA -keysize 2048 -storetype pkcs12 Misc 工具  testssl.sh: 强大友好的SSL证书测试命令行工具 certbot mkcert Windows证书管理: certmgr.msc  名词缩写    缩写 全名 注释     CA Certificate Authority    SSL Secure Socket Layer client和server加密通讯协议   TLS Transport Layer Security SSL继承者,应用层协议   PKCS Public Key Cryptography Standard    DER Distinguished Encoding Rules     扩展阅读  Unleashed Java加密 </content>
    </entry>
    
     <entry>
        <title>python流行库/框架汇总</title>
        <url>/blog/python-lib/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> 作为一个Python粉,一直在各种场合使用这个语言,最近也在试图从Python2彻底切换到Python3.
如果说缺点的话,也只有对它的性能有所抱怨(GIL),不能使用多核CPU.
这篇主要记录使用过和部分mark过的库/框架,其他检索的话可以使用awesome-python.

注: 具体类别以个人喜好排序
开发类 必备  Requests :用的最久和最多的库  Web开发  Flask :轻量级微框架 Django :全栈框架 Pyramid :想用却没太多实战  Flask相关  Flask-SQLAlchemy  REST服务  Eve: 基于Flask的灵活RESTful服务 Django REST framework Falcon: 高性能微服务框架  数据库  peewee : 轻量级ORM SQLAlchemy : 标配ORM  Driver/驱动  PyMySQL : 纯python实现的MySQL客户端 psycopg2: 最常用PostgreSQL客户端 asyncpg: 支持asyncio的PostgreSQL客户端 cx_Oracle: Oracle客户端  I/O 多线程  Curio : 协程库,aysncio的其他版本  功能增强  schedule: 类似cron的任务安排 ElastAlert : Elasticsearch提醒 Celery : 异步消息/任务队列 rq: 精简版任务队列,基于Redis  图像处理  Pillow  加密  cryptography  网络抓取  Scrapy/Portia web前端 pyspider  语言规范  YAPF : 格式化及规范 常用设计模式  客户端  Click: 命令行工具 PyInstaller : 安装打包 Kivy: 跨平台/手机产品原型设计  运维相关 生产部署  Gunicorn : WSGI HTTP Server  自动化/运维  Fabric : 轻量部署 Ansible Boto 3: AWS运维  监控  psutil:进程和系统监控 psdash: 基于psutil和flask的web端  测试 测试库/框架  pytest : 基础测试框架 Faker : 假数据生成 易出错输入字符集 PyAutoGUI: GUI自动化,操作鼠标/键盘  性能测试  Locust  数据科学 数据处理  pandas openpyxl : Excel操作 q: 在csv上运行SQL  可视化  Matplotlib : 最早接触的绘图库 Bokeh : 交互式可视化  工具  HTTPie : 增强易用版curl httpbin/官方站 : 请求/响应服务,学习HTTP协议
 cookiecutter:项目开发模板
  扩展阅读  awesome-python </content>
    </entry>
    
     <entry>
        <title>Fabric自动化部署</title>
        <url>/blog/fabric/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>automation</tag><tag>python</tag>
        </tags>
        <content type="html"> Fabric比较轻量级,平时在部署多个服务器时经常用到.
今年作者发布了不向后兼容的Fabric2, 由于原有的脚本改动太多,暂时还没有迁移.
[2018.12更新]
Fabric2现在看来是个错误选择, Fabric v1不支持Python3,而Fabric2仍存在大量bug和未实现功能,从实用的角度看v2基本不可用.
在主流已经使用Python3的情况下,这意味着Fabric毫无迁移必要.
算了不折腾了,直接上Ansible吧.

Fabric2 # 如果要同时安装两个版本,建议使用下面方式安装新版本 pip install fabric2 TODO
Fabric v1 因为默认会安装新版v2,需要指定具体的版本号
pip install Fabric==1.14.1 Q: 如果遇到错误: CTR mode needs counter parameter, not IV
A: 需要升级paramiko库 &amp;gt; sudo pip install -U paramiko
fab命令行  -u User : 以该用户远程登录 -R ROLES : 以该角色执行任务 -l : 列出可执行任务 -P : 切换为并行执行 -H : 用,分割的远程主机列表 -f PATH : 加载python模块  # 执行参数化任务 fab mytask:arg1,arg2 fabfile.py的写法 常用接口 from fabric.api import * run(&amp;#39;pwd&amp;#39;) # 忽略错误 with settings(warn_only=True): sudo(&amp;#39;cat /etc/passwd&amp;#39;) 文件操作 from fabric.operations import put,get from fabric.contrib import files put(&amp;#39;/home/xulz/test1.txt&amp;#39;, &amp;#39;/home/ubuntu/tmp/&amp;#39;) get(&amp;#39;/home/ubuntu/remote.txt&amp;#39;,&amp;#39;/home/xulz/tmp/&amp;#39;) files.append(&amp;#34;/home/xulz/test.txt&amp;#34;, &amp;#34;new line&amp;#34;) 灵活调用 from fabric.api import execute from fabric.api import env env.user = &amp;#39;xulz&amp;#39; env.roledefs = { &amp;#39;db&amp;#39;: { &amp;#39;hosts&amp;#39;: [&amp;#39;192.168.1.1&amp;#39;] } } @roles(&amp;#39;db&amp;#39;) def my_func(arg1,arg2) pass def my_task(): execute(my_func,arg1,arg2) 其他 from fabric.colors import red, green 资源  官网 </content>
    </entry>
    
     <entry>
        <title>Vim必知必会</title>
        <url>/blog/vim/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>tools</tag><tag>linux</tag>
        </tags>
        <content type="html"> VI/VIM作为Nix环境的常用编辑器,有一些常用命令/用法.
由于平时用VSCode/SublimeText比较多,以至于切换到vi经常需要查阅,特记录与此.

命令行用法 # 以只读方式打开 vi -R filename # 从某行打开 vi &#43;linenumber file.py #修改当前路径 gvim -c &amp;#34;cd ~/workspace&amp;#34; 导航  切换Tab: Ngt (N是页码) 跳转到某行 ：NG或Ngg或:N (N代表行数)  常用快捷键    快捷键 说明     zz 移动当前行到屏幕中间   zt 移动当前行到屏幕顶部   zb 移动当前行到屏幕底部   Ctrl-y 上移屏幕一行, 只   Ctrl-e 下移屏幕一行   Ctrl-u 向上移动光标屏幕1/2页面   Ctrl-d 向上移动光标屏幕1/2页面   Ctrl-b 向前翻页,光标移到最后一行   Ctrl-f 向后翻页,光标移到第一行   Ctrl&#43;C 或 Ctrl&#43;[ Esc     &amp;lsquo;zt&amp;rsquo;, &amp;lsquo;zz&amp;rsquo; 和 &amp;lsquo;zb&amp;rsquo; 会保持当前光标位置, 但移动视野使其在屏幕的&amp;rsquo;t&amp;rsquo;op, &amp;lsquo;z&amp;rsquo; center, 或 &amp;lsquo;b&amp;rsquo;ottom 位置.
&amp;lsquo;H&amp;rsquo;ighest, &amp;rsquo;M&amp;rsquo;iddle, &amp;lsquo;L&amp;rsquo;ower 屏幕行
 设置命令 # 执行命令 !! 等同于 :.! 或Ctrl-z &#43; fg #显示行号/自动缩进/忽略大小写/显示结束行和tab标识/显示换行符 :set number/ai/ic/list/wm # 关闭显示 set nu! :set nonumber #高亮搜索,关闭:noh;实时显示匹配 :set hlsearch incsearch 简写 set hls is # 忽略大小写 :set ignorecase smartcase # 用sudo保存只读文件(经常用到的一个命令) :w !sudo tee % # 设置终端为vi 模式 :set -o vi #切换工作路径 :cd ~/workspace # 将当前编辑文件第 # 行至第 # 行的內容保存到文件FILENAME :#,#w FILENAME # 读取 FILENAME文件 并将其插入到当前文件的光标位置后面 :r FILENAME # 重复上一次变更 . (period) 编辑内容 # 复制和粘贴 &amp;#34;ayy (内容存放在寄存器 &amp;#34;) / &amp;#34;ap 查找 搜索光标处单词 * *(向前) 或#(向后) * q/ 或/Ctrl-f (== find) * /之后用上下方向键
替换  :[address]s/search-string/replacement-string[/g]
  address 为一个行号或者是用逗号隔开的两个行号。句点 (.) 代表当前行。可以使用标记或者搜索字符串表示行号。 %代表当前文件 search-string 可以是正则表达式或简单的字符串 g 表示进行全局替换 ( 针对一行可能执行多次替换 )  # 几个例子 # 替换当前文件所有并确认，global :%s/old/new/gc # 列出所有行 :g/old/p :g/old/s//new/gp # 匹配整个单词 :s/\&amp;lt;bar\&amp;gt;/baz 批量替换 :
:args *.[ch] # 替换所有*.c和*.h文件 :argdo %s/&amp;lt;my_foo&amp;gt;/My_Foo/ge | update # e 忽略没有找到的错误  # update 写入修改 定制 设置字体  Linux: set guifont=DejaVu Sans Mono 10 Windows :set guifont=DejaVu Sans Mono:h10  Troubleshooting Q: 终端显示颜色失败 A: export TERM=xterm-256color
Q： Ubuntu下中文菜单不能显示 A： $sudo cp /usr/share/vim/vim72/lang/{menu_zh_cn.utf-8.vim,menu_zh_cn.utf8.vim}
Q：使用Taglist(Ctag)报错  A： apt-get install exuberant-ctags 或在WIndows把ctags.exe放到vim根目录
扩展学习 工具扩展  spf13-vim Maximum For Mac  学习资源  How I Boosted My Vim Cheat Sheet 入门图解 </content>
    </entry>
    
     <entry>
        <title>Ansible Checklist</title>
        <url>/blog/ansible/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>automation</tag><tag>ops</tag>
        </tags>
        <content type="html"> 最早接触Ansible是在15年,后来断断续续用过几次,因为更倾向于所写即所得的Fabric,后者也更轻量级.
每次拾起来都要查文档,记录下常见用法.

基础 ansible命令行用法 ansible  [options]
 -m ping : 使用模块 -a/&amp;ndash;args &amp;ldquo;&amp;hellip;&amp;rdquo;: 模块参数 -u xulz : 切换远程连接用户 -b/&amp;ndash;become : 等同于之前的sudo  # 复制本地文件到远程 ansible all -m copy -a &amp;#39;src=./README.md dest=/tmp&amp;#39; ansible-console 交互式shell
# 列出hosts list # 切换分组 cd groupA cd db* 配置 配置选项 # ansible-config命令查看当前配置 ansible-config view 以下列顺序查找:
 ANSIBLE_CONFIG 环境变量 当前路径的ansible.cfg 文件 ~/.ansible.cfg 系统配置 /etc/ansible/ansible.cfg (默认)  Ansible Configuration Settings
服务器信息配置  /etc/ansible/hosts (类似ini格式:以;作为注释,[header]作为分组) inventory文件  注: 可以使用正则匹配指定主机
Working with Inventory
Playbook ansible-palybook playbook.yml # 运行adhoc命令 ansible boston -i production -m command -a &amp;#39;/sbin/reboot&amp;#39; ### 用法 * -i/--inventory : 指定参考文件 ### 减少执行时间  * -l/--limit : 限定子集 * --tags/--skip-tags : 标签 * gather_facts: False ### 最佳实践 * 命名任务 * 涉及状态 * 以角色分组 ### ansible-galaxy用法  ```bash ansible-galaxy init -p playbooks/roles web 日志及调试 # 打印详细信息到控制台 ansible-playbook -vvv playbook.yaml # 查看一些信息 --list-hosts --list-tasks 配置日志文件
[defaults] log_path=/path/to/logfile 其他工具 ansible-vault 加密secret
ansible-doc 插件文档
Rollback https://github.com/ansistrano/rollback
</content>
    </entry>
    
     <entry>
        <title>Docker Command</title>
        <url>/blog/docker-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>docker</tag><tag>ops</tag>
        </tags>
        <content type="html"> 实际使用中，docker的命令还是很多的，这里单列出来方便查询。

常用命令 # 停止所有运行的containers docker stop $(docker ps -q) # 删除所有容器 docker rm $(docker ps -a -q) # 显示所有exited的容器ID docker ps -a -q -f status=exited # 显示标准输出日志 docker logs --follow &amp;lt;container&amp;gt; # 复制文件 docker cp foo.txt &amp;lt;container&amp;gt;:/ docker cp &amp;lt;container&amp;gt;:/foo.txt / docker run docker run 选项详解
# --rm 容器关闭时自动删除容器, 通常用于运行一次性命令 # -d, —detach 在后台运行(detached模式)并打印容器ID, 如果不指定,容器运行日志会打印到终端 # -p &amp;lt;hostPort&amp;gt;:&amp;lt;containerPort&amp;gt; 建立宿主机到容器的端口映射  # -v &amp;lt;hostDirectory/volume&amp;gt;:&amp;lt;containerDirectory&amp;gt; 建立宿主机到容器的文件目录映射, 如果不指定,则不能持久化保存变更  上面的docker volume如果不存在会自动创建, 也可以手动创建: docker volume create my-container-data
 # 指定网络 docker run --net mynet123 --ip 172.18.0.22 -it ubuntu bash 从Host传递环境变量到Container 方式1: 使用-e 参数
export LOCUST_MODE=&amp;#34;master&amp;#34;;printenv |grep LOADS_MODE; docker run -e LOCUST_MODE ... 方式2: 使用 &amp;ndash;env-file参数
# 指定环境变量文件 docker run --env-file=runtime_env 排查/调试 # 查看容器日志, 包含已Exited docker logs -f &amp;lt;container id/name&amp;gt; # 或者直接登录容器 docker run xxx -ti bash # inspect 查看状态/LogPath docker inspect xxx docker network docker port &amp;lt;CONTAINER&amp;gt; docker network ls # 创建新的bridge 网络  docker network create net-demo docker network create --subnet=172.18.0.0/16 mynet123 docker volume/数据卷  docker volume ls  docker system  docker system prune : 删除不用的数据  -a, &amp;ndash;all : 删除所有不用镜像而不仅仅悬挂的 -f, &amp;ndash;force &amp;ndash;volumes : 不用的卷也删除 &amp;ndash;filter &amp;ldquo;key=value&amp;rdquo;  docker system info : 系统信息 docker system df : 磁盘占用  docker system prune -a # This will remove: # - all stopped containers # - all networks not used by at least one container # - all images without at least one container associated to them # - all build cache 制作镜像 Dockerfile 例子
# 基础镜像 FROM python:3-onbuild # 对外暴露端口 EXPOSE 5000 # 执行命令 CMD: [&amp;#34;python&amp;#34;,&amp;#34;.app.py&amp;#34;]   # 其他 # 运行命令 RUN apt -yqq update  # 把应用添加到容器卷 ADD flask-app /opt/flask-app # 设置工作目录 WORKDIR /opt/flask-app docker build  -t &amp;lt;版本标签&amp;gt; PATH/URL/. : 通常使用的最后的.代表当前路径  # 构建及运行示例 docker build -t my-app . docker run -it --rm --name my-running-app my-app # 强制构建/不使用缓存 docker build --no-cache -t my-app -f Dockerfile . RUN/ENTRYPOINT/CMD的区别  RUN: 构建新镜像层 ENTRYPOINT: 总是需要执行命令时使用,使容器可执行 CMD: 需要提供默认命令,参数可以被覆盖  两种形式:shell和exec
 shell形式   : 会调用/bin/sh -c 并执行shell处理 exce形式  [&amp;ldquo;executable&amp;rdquo;,&amp;ldquo;param1&amp;rdquo;]  直接调用executable,例如 /bin/bash写作 ENTRYPOINT [&amp;ldquo;/bin/bash&amp;rdquo;,&amp;ldquo;-c&amp;rdquo;,&amp;ldquo;echo Hello, $name&amp;rdquo;] 更多用于 CMD和 ENTRYPOINT   传递参数 # 通常组合为 ENTRYPOINT [&amp;#34;/bin/bash&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;param1&amp;#34;] CMD [&amp;#34;param2&amp;#34;,&amp;#34;param3&amp;#34;] 调试 # 对于直接EXITED的容器,可修改入口为 ENTRYPOINT [&amp;#34;/bin/bash&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;sleep 1800&amp;#34;] # 容器启动后,再登录容器shell查看日志 镜像导出/导入 保存镜像 # 格式: docker save -o &amp;lt;path for generated tar file&amp;gt; &amp;lt;image name&amp;gt; # 压缩 docker save &amp;lt;docker image name&amp;gt; | gzip &amp;gt; &amp;lt;docker image name&amp;gt;.tar.gz 导入镜像 docker load &amp;lt; my-image.tar.gz # 注: 对于gzip, bzip2, xz的压缩文件,导入时会自动解压 docker-compose 定义及运行多个容器应用,Python写的一个工具
PS. 原来docker-compose最初也是收购来的
# 停止服务 docker-compose stop # 停止并删除container及数据卷 docker-compose down -v # 创建,启动并在后台运行container docker-compose up -d docker-compose.yml version:services:&amp;lt;service_name&amp;gt;:image:command:ports:volumes: 技巧  所有命令的Container ID可以仅使用前2/4位  扩展阅读  Docker RUN vs CMD vs ENTRYPOINT 如何在已启动的容器开启新端口映射 </content>
    </entry>
    
     <entry>
        <title>Docker最佳实践</title>
        <url>/blog/docker-best-practice/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>docker</tag>
        </tags>
        <content type="html">  这里主要针对制作Docker镜像，汇总常见的正确使用方式：
制作镜像 使用继承镜像 如果要制作包含Tomcat和Java运行环境的镜像， 建议先基于CentOS制作Java镜像，接着基于它做Tomcat镜像。
centos7-java8 &amp;gt; centos7-java8-tomcat8
在一个容器最好只运行一个进程 制作合适层数的镜像 避免只包含一层，也避免太多层。常用的方式例如：
 基于操作系统的定制基础镜像 新用户创建准备 安装运行时 配置 应用层  定义.dockerignore 使用WORKDIR 注意顺序，依照构建过程（不变的在前） 缩减镜像尺寸 镜像的选择：
Ubuntu &amp;gt; openjdk:8-alpine &amp;gt; tomcat:8.5-alpine
常用清除命令
# Alpine  apk add --no-cache curl # CentOS  yum clean all # Ubuntu  rm -rf /var/lib/apt/lists/* 使用Health Check HEALTHCHECK CMD curl --fail http://localhost || exit 1 --interval=10s --timeout=10s --start-period=30s # 检查状态  docker ps response Java应用性能优化 JVM 应该指定 -Xmx
默认使用宿主机的25%或1G(取较小值)
使用docker资源限制  &amp;ndash;memory &amp;ndash;memory-reservation &amp;ndash;cpus  如果CPU被限制，需要同时设置 -XX:ParallelGCThreads
日志处理 不建议写到容器的RW层，应该发送到数据卷（NAS/SAN）或使用 Docker Log Drivers.
问题诊断 JVM命令：
GC Stats: jstat &amp;ndash;gcutil
Heap Dump/直方图: jmap
Docker命令： docker stats
ctop
一些镜像资源  Tomcat Dockfile Postgres Dockfile JBoss Dockfile  参考  SlideShare Java Docker Pipeline Dockerfile Good Practices  </content>
    </entry>
    
     <entry>
        <title>在Windows10运行增强版Ubuntu,支持复制粘贴和本地磁盘映射</title>
        <url>/blog/hyperv-ubuntu-enhanced-mode/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>hyper-v</tag><tag>ubuntu</tag><tag>windows10</tag>
        </tags>
        <content type="html">  使用Win10自带的Hyper-V运行Ubuntu虚拟机确实资源使用很小，Ubuntu虚拟机开个全屏，用起来和双系统没有区别。
前提 由于这是最新版Windows 10发布版才支持的特性（增强Linux支持），需要确保Windows已升级至1803. 升级使用官方的Windows10易升就可以。
同时Hyper-V需要专业版和企业版才支持（家庭版不行）。
主要步骤 1.下载Ubuntu 18.04（或16.04）镜像
2.在Hyper-V创建新虚拟机，可以选择&amp;rdquo;Generation 2/2代。 创建完成之后，在虚拟机[设置]-[硬件]-[安全],把&amp;rdquo;Enable Secure Boot&amp;rdquo;前的勾选去掉。
3.虚拟机安装完成之后，进入Ubuntu系统，在终端执行下列命令：
sudo apt-get update sudo apt install git git clone https://github.com/jterry75/xrdp-init.git ~/xrdp-init cd ~/xrdp-init/ubuntu/18.04/ vi install.sh # 把以下两行注释掉并保存，如下 #rmmod vmw_vsock_vmci_transport #rmmod vsock  # 运行 sudo chmod &#43;x install.sh sudo ./install.sh sudo reboot # 重启后，进入该目录再次运行 sudo ./install.sh # 之后关闭Ubuntu 4.以管理员打开powershell，运行
Set-VM -VMName Ubuntu -EnhancedSessionTransportType HvSocket 5.进入Ubuntu虚拟机，以默认的Xorg方式登录系统。
如果登录失败，进入[Hyper-V Settings]-[User]-[Enhanced Session Mode]设置项，把&amp;rdquo;Use enhanced session mode&amp;rdquo;前的勾选去掉，重新登录Ubuntu并检查日志/var/log/xrdp.log最后的错误。如果是因为私钥读失败，可执行
# 这里修改为你的用户名  sudo chown xulz /etc/xrdp/key.pem 参考  Windows 10: A guide how to run Ubuntu 18.04 in Enhanced Mode in Hyper-V   </content>
    </entry>
    
     <entry>
        <title>Kubernetes控制命令kubectl汇总</title>
        <url>/blog/k8s-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html">  kubectl 作为Kubernetes集群管理的命令行工具,经常用到的几个子命令包括:
 kubectl get &amp;ndash; list resources kubectl describe &amp;ndash; show detailed information about a resource kubectl logs &amp;ndash; print the logs from a container in a pod kubectl exec &amp;ndash; execute a command on a container in a pod  按类型分 集群状态 kubectl cluster-info get 获取信息 kubectl get nodes kubectl get deployments # -o yaml 输出yaml配置格式 kubectl -n kube-system get deployment coredns -o yaml kubectl get pods # 显示更详细的信息 kubectl get pods -o wide # 显示所有命名空间的 kubectl get pods --all-namespaces # 指定命名空间 -n # -w 监控变化 kubectl get pod -n kube-system kubectl get componentstatuses # 等价于 kubectl get cs delete 删除资源 kubectl delete pod &amp;lt;pod-name&amp;gt; describe 详细信息 kubectl describe pod &amp;lt;pod-id&amp;gt; # 描述系统命名空间Pod, 经常用于查找问题 kubectl describe pod calico-node-j2ggr --namespace=kube-system logs 获取容器日志 POD_NAME=$(kubectl get pods -l run=nginx -o jsonpath=&amp;#34;{.items[0].metadata.name}&amp;#34;) kubectl logs $POD_NAME exec 在容器执行命令 kubectl exec -ti -- $POD_NAME &amp;lt;command&amp;gt;kubectl exec -ti k8s-demo -- /bin/bash # 查看环境变量 # printenv 配置/部署 # 部署Deployment kubectl create -f deployment.yaml # 编辑Deployment kubectl edit deployment/nginx-deployment # 基于配置文件创建pod kubectl create -f &amp;lt;config.yaml&amp;gt; # 创建其他资源 kubectl create secret generic kubernetes-bootcamp --from-literal=&amp;#34;mykey=mydata&amp;#34; 在非Master机器使用kubectl scp root@&amp;lt;master ip&amp;gt;:/etc/kubernetes/admin.conf . kubectl --kubeconfig ./admin.conf get nodes 按使用场景 部署容器镜像 ## 部署 kubectl run &amp;lt;deployment name&amp;gt; —image=&amp;lt;full url&amp;gt; —port=8080 # 例如 kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080 kubectl run busybox --image=busybox # 检查 kubectl get deployments # 使用标签过滤 kubectl get pods -l run=busybox 升级及回滚 ## 升级 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 kubectl rollout status deployment/nginx-deployment kubectl rollout undo &amp;lt;deployment&amp;gt; [--to-revision=2] # 手动强制更新容器镜像 # 注: 仅适用于ReplicationController kubectl rolling-update k8s-demo --image=k8s-demo:latest --image-pull-policy Always 暴露服务 # 使API Server监听本地的8001端口 kubectl proxy # 使用NodePort服务方式暴露部署 kubectl expose deployment nginx --port 80 --type NodePort # 标签标记 kubectl label # 检查 kubectl get services 自动扩容 kubectl scale deployment nginx-deployment --replicas=5 # 自动扩容/Horizontal Pod Autoscaler kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80</content>
    </entry>
    
     <entry>
        <title>电音欣赏</title>
        <url>/play/electronic-muisc/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          <tag>music</tag>
        </tags>
        <content type="html"> 去年下半年玩王者荣耀(年前已出坑)的收获之一就是接触了电音,当时找一些攻略视频看,背景音乐都很带劲,于是通过网易云音乐的歌单发现了电音的广阔天地.
从个人爱好说,超喜欢铁托,那首BOOM就很魔性. 其他DJ有Deorro(Five Hours必听),Timmy Trumpet,Zedd.
欢迎收听我的歌单: http://music.163.com/#/playlist?id=969925767
</content>
    </entry>
    
     <entry>
        <title>Kubernetes部署篇:Kubespray方式自动化</title>
        <url>/blog/k8s-deploy/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html">  众所周知Kubernetes集群的部署比较繁琐复杂,这里列出常见的几种部署方式及过程.
官方现在提供2种主要的部署方式:
 Kubespray : 基于Ansible的集群自动化部署,支持的平台更广泛,部署更灵活 Kubernetes Operations (kops): 生产环境集群自动化部署工具, 目前只支持AWS, GCE云环境.  Kubernetes部署/运行结构 Control Plane 包括三部分组件:
 apiServer controllerManager scheduler  kube-controller-manager实例:
管理controller状态的守护进程,包括replication controller, endpoints controller, namespace controller, serviceaccounts controller.
组件安装顺序  Docker etcd kubelet and kube-proxy network_plugin (such as Calico or Weave) kube-apiserver, kube-scheduler, and kube-controller-manager Add-ons (such as KubeDNS)  高可用 Control Plane和ETCD至少需要3个节点,才可提供HA.
添加 &amp;ndash;experimental-control-plane 选项组成control plane集群.
Kubespray部署实战 说明 由于国内网络访问docker.com及镜像, kubernates, gcr.io等相关镜像极不稳定,替换了相关安装源.
这里使用的是我的Kubespray(已更新至2018.12最新版v2.8.0) fork版本
部署节点前提 cp inventory/sample inventory/mycluster 根据自己的节点信息修改inventory/mycluster/hosts.ini
我的例子
moon1 ansible_ssh_host=10.20.30.101  moon2 ansible_ssh_host=10.20.30.102  moon3 ansible_ssh_host=10.20.30.103 moon4 ansible_ssh_host=10.20.30.104  moon5 ansible_ssh_host=10.20.30.105  moon6 ansible_ssh_host=10.20.30.106  [kube-master] moon1 moon2 [etcd] moon1 moon2 moon3 [kube-node] moon2 moon3 moon4 moon5 moon6 [k8s-cluster:children] kube-master kube-node 国内镜像及加速的常见步骤 已包含于Ansible运行脚本.
docker 阿里云镜像 # step 1: 安装必要的一些系统工具  sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common # step 2: 安装GPG证书  curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # Step 3: 写入软件源信息  sudo add-apt-repository &amp;#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable&amp;#34; # Step 4: 更新并安装 Docker-CE  sudo apt-get -y update # 查找Docker-CE的版本: apt-cache madison docker-ce  # 安装指定版本的Docker-CE  sudo apt-get -y install docker-ce=17.03.2~ce-0~ubuntu-xenial docker镜像 阿里云加速 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&amp;#39;EOF&amp;#39; { &amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://nz4awhki.mirror.aliyuncs.com&amp;#34;] } EOF # 重启以生效  sudo service docker restart kubernetes镜像 cat &amp;lt;&amp;lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main EOF gcr.io和quay.io镜像 将相关镜像URL里
 gcr.io部分替换为gcr.mirrors.ustc.edu.cn quay.io部分替换为quay.mirrors.ustc.edu.cn  注1: 国内网络的问题也可以通过手动下载相关镜像并重新tag的方式解决. 注2: gcr.io的镜像列表见 官方网站
运行Ansible Playbook命令 首次运行,建议:
 开启详情日志: -v
 如果非root,切换sudo用户: -u xulz -b
 建议先运行其中一台节点: &amp;ndash;limit moon1
  ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini cluster.yml --limit moon1 # 如果某步骤出错,建议修复后先重试错误,在以上命令后添加 --limit @/Users/xulz/k8s/kubespray/cluster.retry 删除节点 ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini remove-node.yml --limit moon11 添加节点 ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini scale.yml 升级节点 ansible-playbook -u xulz -b -i inventory/mycluster/hosts.ini upgrade-cluster.yml 问题排查 如果ansible运行失败,根据最后的控制台错误做相应的修正并重试. 日志的存放位置为节点主机的: /var/log/containers/
 注: 如果以&amp;ndash;check的Dry Run方式运行,会造成运行错误(因为脚本依赖于某些步骤的实际运行结果为环境变量),所以不要使用这种模式.
 运行kubectl xxx命令报错: The connection to the server localhost:8080 was refused - did you specify the right host or port? 解决方式: 添加 KUBECONFIG 环境变量
vi ~/.bashrc export KUBECONFIG=/etc/kubernetes/admin.conf 在准备阶段报错: &amp;ldquo;assertion&amp;rdquo;: &amp;ldquo;ansible_swaptotal_mb == 0” 解决方式: 需要关闭swap
sudo swapoff -a 运行kubectl 命令报错: Unable to connect to the server: x509: certificate is valid for &amp;hellip;, not &amp;hellip; 解决方式: 参考Invalid x509 certificate for kubernetes master
如果升级cluster出错,建议逐个命令调试. sudo kubeadm upgrade plan # 参考下面的扩展阅读部分  登录Kubernetes Dashboard ### 创建管理员账号  kubectl create -f admin-role.yaml # 找到admin-token开头的token名字  kubectl -n kube-system get secret # 获取相应的token  kubectl -n kube-system get secret admin-token-tmh9v -o jsonpath={.data.token}|base64 -d # 也可以直接运行 kubectl -n kube-system describe secret admin-token-tmh9v 获取token  # 访问网址: https://&amp;lt;first_master&amp;gt;:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login  # 选择以token方式登录, 输入上一步获取的token  # 登录成功  admin-role.yaml的具体内容见这里
 关于Dashboard的说明 Dashborad支持token和kubeconfig两种认证登录方式，而kubeconfig的方式也需要token字段。
默认命名空间有: default, kube-public, kube-system
扩展阅读  Kubernetes The Hard Way: 例子基于GCP(Google Cloud Platform) kubespray官网 Kubernetes - Upgrading Cluster  </content>
    </entry>
    
     <entry>
        <title>Kubernetes部署篇:本地开发测试环境搭建</title>
        <url>/blog/k8s-local/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html"> 本文侧重于入门Kubernetes时的本地开发测试环境搭建,及minikube的使用.
尤其在国内使用时需要开启网络代理,否则会因为访问Google的一些服务失败而造成各种运行失败的问题.

Mac单节点体验 先安装相应的几个工具:
 下载Minikube: minikube-darwin-amd64 kuberctl   后续命令:
chmod &#43;x minikube-darwin-amd64 mv minikube-darwin-amd64 /usr/local/bin/minikube brew install kubectl 验证环境正确:
注: 进行前需梯子,否则第一步下载localkube可能失败,产生如下错误 Error creating localkube asset from url: Error opening file asset: open /Users/xulz/.minikube/cache/localkube/localkube-v1.8.0: no such file or directory 进而导致之后Pod的状态一直是ContainerCreating# 确保本机已安装VirtualBox  minikube start kubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 --port=8080 # 检查Pod是否已运行, 需要从ContainerCreating更新为Running  kubectl get pod # 如果一直是ContainerCreating, 检查错误原因  kubectl describe pods # 页面应该可访问  curl $(minikube service hello-minikube --url) # 查看Dashboard  minikube dashboard # 不用时清除  kubectl delete deployment hello-minikube minikube stop Ubuntu多节点 使用工具conjure-up搭建本地测试/开发环境, 本身基于juju部署工具.
官方支持2种部署模式:
 kubernetes-core : (Staging环境) 1个Master节点&#43;1个Worker节点
 canonical-kubernetes: (生产环境) 2 masters, 3 workers, 3 etc nodes 及API Load Balance
# 本地安装使用kubectl sudo snap install kubectl --classic # 准备阶段 sudo snap install conjure-up --classic sudo snap install lxd newgrp lxd sudo usermod -a -G lxd xulz /snap/bin/lxd init # 需要重启机器 sudo reboot # 禁用IPv6, conjure-up基于的juju暂时不支持 lxc network set lxdbr0 ipv6.address none  使用图像界面安装
conjure-up kubernetes # 对于Docker的虚拟网络插件,这里选择默认的Flannel  # 安装过程需开启梯子, gcr.io 不可访问  Kubernetes常用网络插件: flannel, calico, weave
这里的网络也称作SDN(软件定义网络), 通常基于CNI: Container Network Interface/容器网络接口
 juju常用命令 在查看运行环境及问题排查时常会用到的命令.
juju controllers # Models 有2个是因为包含内置的管理模块default  # 查看当前的 Controller, Model, User  juju whoami # 显示当前应用状态  juju status # 远程登录到master  # 日志存放在 /var/log/juju/  juju ssh kubernetes-master/0 # 获取当前controller名称  juju switch # 卸载停止controller  juju destroy-controller &amp;lt;上一步得到的名字&amp;gt; --destroy-all-models # 单独卸载 model  juju destroy-model &amp;lt;model_name&amp;gt; 资源  Running Kubernetes Locally via Minikube LXD入门介绍 k8s国内镜像介绍 gcr.io/google-containers Hub镜像   注: gcr(Google Container Registry)的URL结构是gcr.io/{PROJECT_ID}/{image}:tag,在国内不可访问，请使用以上镜像．
</content>
    </entry>
    
     <entry>
        <title>Web测试及工具</title>
        <url>/blog/webtest/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 整理下测试相关的东西在这里。
说到Web网页自动化测试，事实上的唯一标准就是基于WebDriver/Selenium的实现了。
 说明: WebDriver 等同于Selenium2
 WebDriver 介绍 WebDriver 是一个跨浏览器的网站自动化测试API，主要包含以下几方面
 Browser Control： navigation, snapshotting, window control, override geolocation User input simulation： mouse, keyborad, file uploads, altert handling Web stuff： find/query elements, evaluate JavaScript, manipulate cookies

  页面对象模型 页面对象模型是挺早就有的一个概念，现在也是实现的一个通用标准/最佳实践.
他的思想是应该暴露你要交互的服务而不是具体实现，即你的测试方法不应该包含最底层的WebDriver API。
如果某些复杂UI的层次结构只是用来组织UI，应该与page对象分离开。断言也应该与页面对象分离。
同时“页面”对象并不意味着为每个页面建立一个这样的对象，比如页面有重要意义的元素可以独立为一个page对象。
Martin Flower最早提出的Page Object英文版/中文版
页面对象的例子  Page(object)  init(self, testsetup) get_url(self, url) is_the_current_page get_url_current_page is_element_present(self, *locator) is_element_visible(self, *locator) return_to_previous_page  Base(Page) Regions  一些流行语言的工具和框架实现 Selenium Server  Docker images for Selenium Grid Server
# start the hub java -jar selenium-server-standalone-2.47.0.jar -role hub -port 4444 # start the node java -jar selenium-server-standalone-2.47.0.jar -role node -hub http://localhost:4444/grid/register # 其他 java -jar selenium-server-standalone-{version}.jar -Dwebdriver.chrome.driver=/path/to/chromedriver # Chrome Only chromedriver --port=4444 --url-base=wd/hub  Python实现  Selenium with Python:Python使用文档 splinter PageObject库 RobotFramework库  Java实现 基本组成：
 UI层: selenide Report框架: allure 断言框架: assertj-core/assertj-db 基础测试框架: TestNG/JUnit  相关网站/文档：
 Selenide/示例 结合TestNG JDK:java.awt.Robot Atlassian Selenium: 供学习 Dagger:网易开源，不再维护，同样基于TestNG,供参考  Node.JS/JavaScript实现  UI Recorder:阿里的录制回放工具 Intern :全功能自动化测试工具 Karma:浏览器测试执行工具, 因AngularJS而生 WebdriverIO :Node.js库,结合BDD框架使用 Nightwatch.js :Node.JS 实现的UI测试框架 Testnium:GroupOn的Node集成测试库  响应式布局测试  Galen  Jenkins集成 SeleniumPlugin
浏览器辅助工具 Chrome
 CSS Selector Helper for Chrome Selenium Page Object Generator  Firefox
 Firebug Firefinder : Finds HTML elements matching chosen CSS selector(s) or XPath expression xpathchecker : An interactive editor for XPath expressions &amp;ndash; Firefox Extension WebDriver Element Locator 2.0  示例 元素定位 CSS Selector
 .class #id element [operator: , &amp;gt; &#43; ~ ] element [id] :checked  参考文档CSS Selector/测试页/关于Selectors
关于等待 # Waiting for an element to appear driver.wait(until.elementLocated(by.id(&amp;#39;elementappearschild&amp;#39;)), 10000, &amp;#39;Could not locate the child element within the time specified&amp;#39;); # Waiting for an element to disappear //Method1: driver.wait(until.elementIsNotVisible(element),10000); //Method2 [better]: driver.wait(function() { return driver.isElementPresent(by.id(&amp;#39;elementdisappears&amp;#39;)).then(function(present) { return !present; }); }, 10000, &amp;#39;The element was still present when it should have disappeared.&amp;#39;); # Waiting for an element’s text to change to a value driver.wait(until.elementTextContains(element, &amp;#39;new&amp;#39;),10000); 扩展阅读  官方文档 Architecture of Selenium Webdriver Selenium Guidebook </content>
    </entry>
    
     <entry>
        <title>接口测试及工具</title>
        <url>/blog/apitest/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html">  接口（API）测试随着REST的流行有个越来越多的应用，而基于测试金字塔理论，偏底层的接口测试是投入产出最高的。
接口测试基本操作：
 生成符合协议格式的请求数据 向指定接口发送数据并接受响应 验证响应码并解析响应内容，确保符合预期数据  接口测试的用例分以下两类：
 单接口用例： 主要测试不同参数数据组合得到的响应符合期望值 多接口业务用例 ： 更偏向业务的实际应用场景，尽量提高覆盖  通常情况下，接口测试自动化实现会基于单元测试框架作为测试脚本的运行驱动, 为减少数据依赖通常会引入Mock数据. 最终部署形式通常与CI系统(Jenkins)整合.
以下为接口测试的相关工具/框架:
基础库 Java的生态相对成熟丰富, 牵涉到几个常用库:
 rest-assured： 更友好的DSL测试语法 Hamcrest ： 灵活的匹配表达式(matchers),新版JUnit已内置;支持多语言 WireMock: HTTP服务Mock工具  流行工具 Diffy ： Twitter开源的回归测试工具, 通过代理的形式比较响应内容,验证新代码是否引入缺陷
扩展阅读 相关链接  rest-assured Hamcrest WireMock Diffy：Scala开发  其他 有些项目已不再维护，供学习参考。
 WeTest:微博开源的基于JUnit4的轻量级接口自动化测试框架 zato-apitest： python实现，略显繁琐  </content>
    </entry>
    
     <entry>
        <title>用Makefile简化重复的多个命令</title>
        <url>/blog/makefile/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html">  经常会通过编译安装一些Linux包,最熟悉的就是make test, make install 这类命令了,以为make只适用于编译安装.
实际上发现Makefile/makefile在简化一些常用命令(多行命令或长命令)时也非常方便.
# Makefile install: @go get github.com/revel/cmd/revel @dep ensure server: revel run github.com/xulz/webapp Makefile规则 &amp;lt;目标&amp;gt;:&amp;lt;执行的前提条件,即有文件更新才执行&amp;gt;
(tab) 具体的命令
 默认执行第一个目标. 在命令前添加@ 表示不打印正在执行的命令  Makefile的一些语法 # 定义变量, 使用 $(LDIR) 引用 LDIR =../lib 自动化变量:
 $&amp;lt; 表示所有的依赖目标集
 $@ 表示目标集
  调试 带参数 -n或&amp;ndash;just-print, 只显示命令而不执行.
扩展阅读  跟我一起写Makefile/另一个整理版本 如何调试MAKEFILE变量  </content>
    </entry>
    
     <entry>
        <title>用Jupyter/iPython Notebook做笔记</title>
        <url>/blog/jupyter-ipython-notebook/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html">  ipython作为一个必备的学习/调试环境, notebook可以看做其增强版, 支持Markdown格式说明, 很适合用笔记或者演示/培训用途,基本是机器学习的标配.
安装及运行 python3 -m pip install jupyter notebook jupyter notebook # 新版的iPython要求Python 3.3以上,因此建议在python3环境使用 如果要在Python2.7运行,安装IPython5.7分支.
pip install ipython ipython 如果在本地没有运行环境,又想打开一个包含笔记的GitHub仓库, 可以使用binder在云端打开.
多用户版本  jupyterhub  扩展阅读  官网 用Jupyter做slides/ppt Python学习课程  </content>
    </entry>
    
     <entry>
        <title>你的网站账号密码安全吗</title>
        <url>/blog/check-your-password/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>security</tag>
        </tags>
        <content type="html"> 今天看了Django开发者的一篇文章,关于web安全的子项目, 其中提到了一个用于检测用户密码是否安全的API.
不同于普通的密码强度检测,它的检测原理基于最近这些年大型的互联网公司数据库泄漏事件,比如CSDN,天涯,HiAPK安卓网,网易等.
对普通用户,提供两个主要的网页查询功能:
 你邮件账户的密码是否已泄漏[1] 你正在使用的密码是否存在于泄漏数据库及被其他用户泄漏的次数[2]   通过API用Python检测的例子 import hashlib password = &amp;#39;swordfish&amp;#39; digest = hashlib.sha1(password.encode(&amp;#39;utf-8&amp;#39;)).hexdigest().upper() print(digest) # 4F57181DCAADE980555F2CE6755CA425F00658BE 然后访问 https://api.pwnedpasswords.com/range/4F571  (URL最后的参数是以上哈希摘要的前5位)
在响应内容中搜索以上哈希摘要的剩余字符 81DCAADE980555F2CE6755CA425F00658BE
如果检索到,则冒号:后面的数字就是被泄漏的次数, 如果成百上千了,一定要修改你的密码.
密码基本原则  密码分级: 根据是否涉及支付和隐私,最起码分成强密码和弱密码两类,强密码定期更新(每年). 如果是一次性注册网站, 使用固定的弱密码. 不要使用其他人也常用的弱密码或容易猜到的内容. 强密码定义: 8位及以上,包含大小写字母,数字和符号   注: 其实很早之前使用过2次这个网站,记录下让更多人知道.
</content>
    </entry>
    
     <entry>
        <title>回到WordPress</title>
        <url>/play/blog-wordpress/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 最近几年博客经历 3年前改用Evernote做笔记,因为很少写博客的原因停掉了国外共享主机的wordpress,之前的内容也迁移到了Blogger平台(国内不可访问,仅作为备份).
后来为了学习git和markdown,也时常在GitHub上写笔记.
久闻Go大名已久,在听了播客内核恐慌某期讲静态博客后,尝试了高性能的Hugo.
去年总收到阿里云的广告促销,也想有一个移动版调试系统,就购买了云主机,把域名也迁到了国内.
在上面部署了静态博客, 由于Hugo/Lektor缺乏好用的主题,最后使用了已有所了解的Hexo. 也就有了前两篇搭建博客的记录文章.
WordPress 又回到WordPress,其实是为了让写博客这件事变得简单. 不管静态博客还是新生代Ghost,最终用下来的感觉是表面看似简洁的新博客使用起来并不简单.
例如静态博客, 需要git版本管理,每次修改需要commit/push, Hexo需要generate/deploy(虽然这一步在Github Pages可以hook自动化),有时候还需要clean,而生成静态页面/rsync并不像Hugo那么智能高效.
由于云主机几乎没有资源占用率,实际上新版WordPress有很大改进,在插件优化之后,安装前后资源占用几乎没有变化.
之前WordPress使用时间比较长,对插件/主题比较熟悉,只记录下关键步骤.

在Ubuntu16上安装可参考DO上的这篇文章.
# 安装php7环境  sudo apt-get install php-fpm php-mysql sudo apt-get install php7.0-mysql php7.0-curl php7.0-gd php7.0-mbstring php7.0-mcrypt php7.0-xml php7.0-xmlrpc sudo systemctl restart php7.0-fpm # Nginx更新用户  vi /etc/nginx/nginx.conf user www-data; # 默认nginx  # 调试用,查看当前php用户组  ps aux | grep php # 文件夹权限  sudo chown -R xulz:www-data /var/www/html sudo find /var/www/html -type d -exec chmod g&#43;s {} \; sudo chmod g&#43;w /var/www/html/wp-content sudo chmod -R g&#43;w /var/www/html/wp-content/themes sudo chmod -R g&#43;w /var/www/html/wp-content/plugins</content>
    </entry>
    
     <entry>
        <title>Linux Bash笔记</title>
        <url>/blog/linux-bash/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 这里主要记录Linux系统的默认shell Bash用法.

快捷键 当前命令编辑 Ctrl &#43; A : 光标移到开头
Ctrl &#43; E : 光标移到结尾
Ctrl &#43; U : 删除整行
Ctrl &#43; W : 删除前一个单词
历史命令 Ctrl &#43; R : 历史命令查找
^old^new : 替换上一个命令字符串
sudo !! : sudo执行上一个命令
Alt &#43; . : 打印上一个命令的最后参数
!$ : 特殊变量,代表上一个命令的最后参数
目录切换 cd &amp;ndash; : 切换到上一个工作目录
cd ~ : 切换到Home目录
Bash特定用法 环境变量 # Linux vi ~/.bash_profile export PATH=&amp;#34;/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin&amp;#34; # Mac vi /etc/paths shebang #!/bin/bash # 脚本执行时告诉shell用哪个程序解释脚本 重定向/管道 2&amp;gt;&amp;amp;1 # 1 代表 stdout, 2 代表 stderr. # 2&amp;gt;1 可以看做重定向 stderr 到 stdout.实际上被解释为 &amp;#34;重定向 stderr 到文件名为 1的文件&amp;#34;. # &amp;amp; 指出接下来是一个文件描述符而不是一个文件 制作包含二进制数据的安装脚本 参考1/2
Bash 脚本 # 调试 set -x # 出错后退出 set -e 常用变量 # 显示当前日期 $(date &#43;%Y-%m-%d) subshell 使用(在子命令范围有效), 如临时切换目录等.
循环 while [$port -lt 1024] do port = &amp;#39;expr $port &#43; 1&amp;#39;; done 多分支选择 case &amp;#34;$1&amp;#34; in start) ./start.sh ;; stop) ./stop.sh ;; *) echo &amp;#34;Usage: $0 {start|stop}&amp;#34; exit 1 ;; esac HereDoc 也许你没听过这个名字,但一定见过这个用法.
它会把开头的单词做标记,提取中间的内容作为标准输入stdin.
# 格式 &amp;lt;&amp;lt;[-]END_TEXT here-document END_TEXT # 示例1 cat &amp;lt;&amp;lt;EOF My home directory is $HOME EOF # 说明: 默认会解释内容中的变量符号 # 如果要保持原样,开头要加上引号&amp;#39;EOF&amp;#39; # 如果要去掉格式中的tab符号,前面加-EOF # 示例2,利用定向符 cat &amp;lt;&amp;lt;EOF &amp;gt; file My home dir is $HOME EOF # 精简格式 fmt -t -w 20 &amp;lt;&amp;lt;&amp;lt; &amp;#39;Wrap this silly sentence.&amp;#39; Troubleshooting tab 不能自动补全?  sudo dpkg-reconfigure dash 选择no (原因: 默认创建的新用户使用的dash)
 sh脚本异常：/bin/sh^M:bad interpreter: No such file or directory  :set ff=unix
 资源  interactive Shell Programming tutorial Bash新手指南 Bash Guide Advanced Bash-Scripting Guide </content>
    </entry>
    
     <entry>
        <title>Linux文件查找/内容搜索命令</title>
        <url>/blog/linux-search/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Linux的文件检索或者日志文件关键字搜索应该是很常用的工作场景, 这里汇总常见的命令用法.

find # 只查找特定文件 find . -type f -name &amp;#39;*.py&amp;#39; # 只查找特定文件 find . -type f -name &amp;#39;*.py&amp;#39; # 在所有目录查找特定文件名 find / -type f -name httpd.conf # 忽略大小写 find . -iname # 忽略目录 find / -xdev -type f -size &#43;100M find / -size &#43;100M -not -path &amp;#39;/proc/*&amp;#39; 查找大文件 find . -type f -size &#43;100M -exec ls -lh {} \; | awk &amp;#39;{ print $8 &amp;#34;: &amp;#34; $5 }&amp;#39; # 支持文件名含空格 find $1 -type f -exec stat --format &amp;#39;%Y :%y %n&amp;#39; {} \; | sort -nr | cut -d: -f2- | head # 执行更快 find $1 -type f | xargs stat --format &amp;#39;%Y :%y %n&amp;#39; | sort -nr | cut -d: -f2- | head # 最常用  统计代码行数 find . -name ‘.py’ | xargs wc -l (find ./ -name &amp;#39;.py&amp;#39; -print0 | xargs -0 cat)|wc -l # 注: -print0 | xargs -0 == -X 规避特殊字符 grep/egrep  grep [OPTIONS] PATTERN [FILE&amp;hellip;] grep [OPTIONS] &amp;ldquo;text string to search” directory-path
 -w # 匹配单词 -i # 忽略大小写 -color -R, -r #recursively, 递归的查找子文件夹 -n # 显示行号 -a, --text # 把二进制文件当作text处理 --exclude: --exclude=*.o --include: --include=*.{c,h} # 只检索匹配的文件 --exclude-dir: --exclude-dir={dir1,dir2,*.dst} --include-dir: -o # 只显示匹配行 -l # 只显示匹配文件名 | # 匹配多个 显示上下文 -B num # 显示匹配前多少行 -A num # 显示匹配后多少行 # 示例 grep -B 3 -A 2 foo README.txt # 如果显示相同行的上下文,可使用 -C num # 或者 -n 查找某时间区间 grep &amp;#34;31/Mar/2002:19:3[1-5]&amp;#34; logfile egrep &amp;#39;^[^ ]&#43; (0[89]|1[0-9]|2[012]):&amp;#39; # awk的方式 awk -v from=&amp;#34;12:52:33&amp;#34; -v to &amp;#34;12:59:33&amp;#34; &amp;#39;$1&amp;gt;=from &amp;amp;&amp;amp; $1&amp;lt;=to&amp;#39; foo.log awk &amp;#39;$0 &amp;gt;= &amp;#34;13/05/13 07:50&amp;#34; &amp;amp;&amp;amp; $0 &amp;lt;= &amp;#34;13/05/23 01:58&amp;#34;&amp;#39; # sed的方式 sed -rne &amp;#39;/&amp;lt;timestamp&amp;gt;/,/&amp;lt;timestamp&amp;gt;/ p&amp;#39; &amp;lt;file&amp;gt; # 示例 sed -n &amp;#39;/Feb 23 13:55/,/Feb 23 14:00/p&amp;#39; /var/log/mail.log sed -n &amp;#39;/Feb 21 23:08:19/,/Feb 21 23:08:23/p&amp;#39; daemon.log awk/sed awk &amp;#39;NR&amp;gt;=10&amp;amp;&amp;amp;NR&amp;lt;=20&amp;#39; in.log &amp;gt; out.log sed -n &amp;#39;100,1000 p&amp;#39; in.log &amp;gt; out.log sed  sed -i &amp;rsquo;s/foo/bar/gI&amp;rsquo; hello.txt
  -i 直接替换原文 -i.bak 同时保存备份 s 替换 / 分割符，也常用&#43;代替 g 全局替换而不是第一项 I 不区分大小写  sort/uniq/cut/tr sort  -n 以数字而非字母排序 -h 更可读的方式显示 -r 倒序排列 -k 5 第五列 -t, &amp;ndash;field-separator=SEP # 指定分隔符 -s, &amp;ndash;stable # 稳定排序,用于多列排序  uniq  -u 只显示唯一行 -d 只显示重复行 -c 显示重复次数  cut  -d&amp;rsquo;:&amp;rsquo; 以冒号为分隔符,默认分隔符为tab -f1-4 选取1~4列  tr 转换/替换/删除字符 tr -d &amp;#39;input-characters&amp;#39; # 删除字符 tr -s &amp;#39;\n&amp;#39; # 把重复字符压缩为一个,s代表squeeze tr &amp;#34;[:lower:]&amp;#34; &amp;#34;[:upper:]&amp;#34; &amp;lt; filename # 转换大小写 tr -cd &amp;#34;[:print:]&amp;#34; &amp;lt; filename # 取消非打印字符, c代表complement 扩展 xargs  xargs [options] [command] 构造参数列表然后执行. 将标准输入或管道转换为命令行的参数,如果省略command则默认使用echo. 通常用作替代find的-exec参数,因为xargs如果出错不会停止执行.
 常用选项:
 -0 ,&amp;ndash;null 以空字符为结束符, 和find -print0结合使用 -I_ 以_为替换字符 -L max-lines 最多个非空行执行一次 -I replace-str 替换字符串,以换行符为分割符  -exec 系统包查找 yum # 查找包含某命令的包 yum provides mpstat # 查询安装包名 rpm -qpi ***.rpm  资源  SED单行脚本快速参考 </content>
    </entry>
    
     <entry>
        <title>pytest测试框架</title>
        <url>/blog/pytest/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>testing</tag>
        </tags>
        <content type="html"> 单元测试最初流行是从JUnit,而他的发明者Kent Beck大神的经典名作&amp;lt;测试驱动开发&amp;gt;这本小书却引领了TDD的风潮,产生了xUnit各个语言系列.
初次接触pytest,感觉不像个xUnit,因为既看不到对TestCase的继承,也找不到Setup/Teardown这些建立/销毁函数.当然这些基本功能肯定是支持的.
pytest虽然作为一个Python单元测试框架的扩展版, 但是它丰富的功能和灵活的特性也很适合做功能测试, 其中的精华就是fixtures.

py.test 用法 pytest提供丰富的命令行参数.
pytest -h # 其他用法 -q, --quiet -s --capture=no --cache-show --cache-clear 下面以测试过程为序,展开各过程主要用法.
配置 pytest配置文件: pytest.ini|tox.ini|setup.cfg
收集 pytest.mark  注: 只作用于tests,对fixture无效
 命令行测试用例选择: -k EXPRESSION : 按正则选取 -m MARKEXPR : 示例 &amp;#34;not (slow or long)” --ignore=path 忽略部分测试集 运行 基本用法:
 pytest test_mod.py::TestClass::test_method
 命令行辅助选项:
--lf, --last-failed rerun only the tests that failed at the last run (or all if none failed) # 退出条件: -x, --exitfirst 出错后退出 --maxfail=num 失败N次后退出 报告 # 需要先安装pytest-html插件 py.test --html=report.html # 命令行选项: --durations=N # 显示最慢的执行 (N=0 for all) fixture fixtures通常存放在根目录的conftest.py或子文件夹的conftest.py(可用来覆盖并重新定义).
fixture的用法 @pytest.fixture()
主要参数:
 scope: session/module/class
 params: 参数化,会执行多次
 autouse=True
  tear down函数体定义:
 代码块为yield之后的所有语句
 或者使用request.addfinalizer(fin)的方式 (好处:及时发生异常也会执行)
  命令行辅助项 --fixtures 显示可用的fixture --setup-only only setup fixtures, do not execute tests. --setup-show show setup of fixtures while executing tests. --setup-plan show what fixtures and tests would be executed but don&amp;#39;t execute anything. 功能介绍 Fixtures 装饰器标记函数为fixture, 总体上fixtures提供:
 单元测试框架的基本功能
 依赖注入: 一些共有函数值/帮助函数/Mock等
 测试数据参数化
 灵活性由不同的作用范围和目录级conftest.py等提供
  monkeypatch Monkeypatching/mocking modules and environments.
 monkeypatch.setattr()
 monkeypatch.delattr()
  扩展资源 流行插件  pytest-variables : 通过json文件定义共享变量 pytest-html : HTML测试报告 pytest-selenium  文档  conftest的用法 配置文件 API接口和内置方法 </content>
    </entry>
    
     <entry>
        <title>Linux系统命令</title>
        <url>/blog/linux-system-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Linux系統命令, 完成一些常見任務.

常用命令使用帮助 用示例方式的简化版man手册, tldr
sudo npm install -g tldr 用户管理 # 添加用户 sudo useradd -m xulz sudo passwd xulz sudo权限 # 创建sudo组用户 useradd -aG sudo xulz # 添加到sudo gpasswd -a xulz sudo # Ubuntu gpasswd -a xulz wheel # CentOS # sudo免密码输入 echo &amp;#34;xulz ALL=(ALL) NOPASSWD:ALL&amp;#34; | sudo tee /etc/sudoers.d/nopass  更改UID(user)和GID(group) usermod -u 2001 xulz groupmod -g 2001 xulz # 注: 以上命令仅修改home目录,其他目录需手动执行 文件管理 # 创建HOME目录 mkhomedir_helper xulz # 输出全路径 readlink -f myfile # 创建软链接 # f 代表重写原链接 # T 代表把链接当做普通文件 ln -sfT path/to/file path/to/symlink 文件内容浏览 less head tail tail -f &amp;lt;file_name&amp;gt; 权限 chown chmod 删除除某文件外的所有文件 # 如果要删除文件夹,更新为 -type d -r find . ! -name &amp;#39;file.txt&amp;#39; -type f -exec rm -f {} &#43; # 或者 # enable extglob shopt -s extglob rm -rf -- !(file.txt) mc 目录浏览和文件管理 # 类似 total command Server必备 同步系统时间 # CentOS yum install ntp systemctl enable ntpd.service # CentOS 7.x # chkconfig ntpd on # CentOS 6.x ntpdate pool.ntp.org # Ubuntu apt install ntp service ntp restart 进程管理 nohup 不挂断地运行命令。
运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。
在注销后使用 nohup 命令运行后台中的程序。
要运行后台中的 nohup 命令，添加 &amp;amp; （ 表示“and”的符号）到命令的尾部。
网络 常用命令 ifconfig #ipconfig # for Windows ip a 增强工具  mtr: 网络调试工具 iperf3: 网络吞吐测试  修改hostname hostname # 查看当前值 # 只应用于内部网络IP映射 vi /ect/hosts vi /etc/sysconfig/network NETWORKING=yes HOSTNAME=newHostName # 重启服务以生效 /etc/init.d/network restart 系统 # 时间戳转换 date -d@1234567890 # 显示unix时间戳 date &#43;%s # 关机 shutdown -h now 文件完整性校验 md5sum file sha256sum file 增强命令 open # git tig # HTTP Client httpie # 彩显文本 lolcat # 浏览器 w3m lynx 复制/粘贴 # 复制/粘贴 apt install xclip # 类似Mac的pbcopy/pbpaste alias pbcopy=&amp;#39;xclip -selection clipboard&amp;#39; alias pbpaste=&amp;#39;xclip -selection clipboard -o&amp;#39;</content>
    </entry>
    
     <entry>
        <title>Linux调优</title>
        <url>/blog/linux-tuning/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> Linux作为服务器针对使用场景, 有许多需要调优的地方, 本文记录常用优化项.

性能基本调优 通常涉及到/etc/sysctl.conf和/etc/security/limits.conf配置文件的修改.
也可使用命令修改,使用sysctl -p 立即生效.
内核参数设置 sysctl命令可以用来实时的读取/修改内核参数
# 显示所有可用内核参数  sysctl -a # 加载/etc/sysctl.conf的参数  sysctl -p 提高文件描述符限制 soft limit类似于warning, hard limit是真实的最大值限制.
默认的1024偏小, 有两种方式修改:
临时设置 # 查看当前值  ulimit -n # 临时增加  ulimit -n 65535 # 单个进程的限制为soft limit  # hard limit应小于当前系统打开的文件描述符  # 相应增加nr_open  echo 2000000 &amp;gt; /proc/sys/fs/nr_open # 系统级限制, 上限为nr_open  echo 1000000 &amp;gt; /proc/sys/fs/file-max SystemD服务设置 在CentOS7使用SystemD启动的服务不同于CentOS6, 对/etc/security/limits.conf的设置不会生效.
需要修改/etc/systemd/system.conf或/etc/systemd/system.conf.d/tomcat.conf.
# 对应下面几项 DefaultLimitCORE=infinity DefaultLimitNOFILE=102400 DefaultLimitNPROC=102400 常用的命令:
# 查看当前进程的限制 cat /proc/$(pgrep java)/limits # 查看当前进程句柄数 lsof -p $(pgrep java)|wc -l ## 或者使用 ls /proc/$(pgrep java)/fd|wc -l 永久设置 修改 /etc/security/limits.conf,重启以生效.
* soft nofile 65535 * hard nofile 65535 root soft nofile 65535 root hard nofile 65535 # 系统级内核句柄限制 fs.file-max = 1000000 查看当前描述符情况 # 列出打开/占用的文件描述符  cat /proc/sys/fs/file-nr # 三个值分别代表 占用/未使用/最大可用值  # 注: lsof只会列出进程占用  lsof | wc -l # 要得到线程占用,需要使用  ps -eLf # 查看某进程限制  cat /proc/[Process ID]/limits 增加可用端口数 默认28000, net.ipv4.ip_local_port_range
如果Nginx作代理,需要增加端口范围,否则会出现错误: Cannot assign requested address .
IPv4端口可用数:端口号是16位无符号整数,即65535
# 实时生效  echo 12000 64000 &amp;gt; /proc/sys/net/ipv4/ip_local_port_range # 永久生效  sysctl -w net.ipv4.ip_local_port_range=&amp;#34;12000 64000&amp;#34; 可选:最大线程数 一般不需要设置
# 默认31299 echo 100000 &amp;gt; /proc/sys/kernel/threads-max 查看当前线程数:
 top, then hit H to view threads top -H htop  网络调优 通用网络参数 /etc/sysctl.conf # 系统网络设置 # 生效值取系统和下面TCP设置值的最大值 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 TCP/IP调优 Backlog Queue 最大连接数队列. 可选, 查看kernel日志决定是否需要调整
net.core.somaxconn net.core.netdev_max_backlog = 300000 网络缓冲区大小 # TCP读取缓冲区 # 格式: 最小值/默认值/最大值 字节数 # cat /proc/sys/net/ipv4/tcp_rmem net.ipv4.tcp_rmem = 4096 87380 16777216 # 发送缓冲区 net.ipv4.tcp_wmem = 4096 65536 16777216 # TCP内存, 对应 low/pressure/high 页大小(4K) net.ipv4.tcp_mem = 786432 2097152 3145728 UDP调优 默认比较受限
#改成8M sysctl -w net.core.rmem_max=8388608 主要参数 Receive-Side Scaling (RSS) also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs.
cat /sys/class/net/eth1/queues/&amp;lt;rx-0&amp;gt;/ ethtool --show-rxfh-indir eth1 CLOSE_WAIT 和 TIME_WAIT 解释 TCP是全双工的,任何一端可以是source或destination.
Due to the way TCP/IP works, connections can not be closed immediately. Packets may arrive out of order or be retransmitted after the connection has been closed.
CLOSE_WAIT indicates that the remote endpoint (other side of the connection) has closed the connection.
TIME_WAIT indicates that local endpoint (this side) has closed the connection. The connection is being kept around so that any delayed packets can be matched to the connection and handled appropriately.
The connections will be removed when they time out within four minutes.
tcp_tw_reuse和tcp_tw_recycle 不用开启 net.ipv4.tcp_tw_recycle, 最新内核4.12已结去掉该参数.
连接有incoming和outgoing之分，tcp_tw_reuse仅仅对outgoing有效.
设计协议时,尽量不用让客户端先关闭连接,应该让服务端控制.
TCP/UDP参数  Socket receive buffer size: Socket send and receive sizes are dynamically adjusted, so they rarely need to be manually edited. rmem_default : A kernel parameter that controls the default size of receive buffers used by sockets.  调优常用指标  Ping 100以下 网络延迟50ms以下 Dns解析尽量快 尽量少丢包 反向代理优化  调优辅助工具 perf-tools 开源的性能分析工具,基于perf和ftrace.
  Linux Performance Observability Tools   SystemTap  SystemTap官方网站 CentOS有用的脚本  扩展阅读  Linux性能资源大全 RedHat官方系统调优指南 TCP的那些事儿 : TCP协议特点汇总 Linux TCP/IP 协议栈调 tcp_tw_reuse和tcp_tw_recycle调整对于过多TIME_WAIT的调研 centos7-systemd-conf-limits </content>
    </entry>
    
     <entry>
        <title>Nginx调优</title>
        <url>/blog/nginx-tuning/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> Nginx在部署服务时经常被用到, 大多时候是作为代理使用. 如果用户量比较大就涉及到一些调优, 本文做一些分类记录.

以下部分主要基于两个主要配置文件:nginx.conf和conf.d/default.conf展开.
Worker Processes # 默认为1, 应更新为一个CPU核心一个worker # 查看CPU核数 $grep ^processor /proc/cpuinfo | wc -l worker_processes auto; # 文件句柄数,默认跟随系统设置 worker_rlimit_nofile 100000; # 事件驱动部分 events { # 每个worker允许的连接数, 默认512 worker_connections 65536; use epoll; multi_accept on; } HTTP和TCP优化 http{ sendfile on; tcp_nopush on; tcp_nodelay on; } 文件访问优化 # 访问日志使用缓冲或关闭 # 如果日志文件路径包含变量，需要打开open_log_file_cache以提高性能 access_log buffer=size flush=time # 多使用缓存和压缩 # 但是图片不应该开启压缩 Keepalive Connections  client保活 upstream保活
http { # 以下两项为client保活配置 # 默认100, 一个keep-alive服务的最大请求数,超出后关闭连接 keepalive_requests 102400; keepalive_timeout 65;
# 以下为upstream保活配置 keepalive 10240; # 默认和上游间60秒超时 proxy_read_timeout 120; # 以下必须设置, 默认响应后会关闭连接 proxy_http_version 1.1; proxy_set_header Connection &amp;#34;&amp;#34;; }
  限制IP连接和并发  limit_req_zone: 限制单位时间内的请求数，即速率限制,采用的漏桶算法 &amp;ldquo;leaky bucket&amp;rdquo; limit_req_conn: 限制同一时间连接数，即并发限制  扩展阅读  官方优化指南 linode优化 性能优化文章 </content>
    </entry>
    
     <entry>
        <title>分布式系统的那些论文及开源实现</title>
        <url>/blog/distributed-paper/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 近几年总能看到大数据,云计算这些buzz word/时髦词, 可是说来惭愧,对近10来年历史上那些著名论文及主要内容却知道的很少.
之前零散的看到分布式系统的一些文章,接下来总结下主要内容,也打算读几本书系统的学习下.
今天先看看这些经典论文及衍生的开源系统.
按时间顺序/影响力最大的应该就是谷歌的老三篇了,即 GFS &#43; MapReduce &#43; BigTable.

论文列表  2003 Google File System/GFS 2004 Google MapReduce: Simplified Data Processing on Large Clusters 2006 Google The Bigtable &amp;ndash; A Distributed Storage System for Structured Data 2007 Amazon Dynamo 2010 Yahoo S4: distributed stream computing platform 2012 Google Spanner:Google&amp;rsquo;s Globally-Distributed Database 2012 Google F1 &amp;ndash; The Fault-Tolerant Distributed RDBMS Supporting Google&amp;rsquo;s Ad Business  对应的开源产品  GFS &#43; MapReduce &#43; BitTable : 对应Hadoop的HDFS和HBase S4(Simple Scalable Streaming System): Twitter开源的实时流计算Storm/继承者Heron Dynamo: Facebook开源的Cassandra, 之后出现了高性能C&#43;&#43;版本ScyllaDB (兼容Cassandra协议,KVM作者开发) SSTable &#43; LSM Tree(BigTable背后技术) : Google开源实现LevelDB和Facebook的分支RocksDB NoSQL(Not only SQL): 基于BigTable的实现, 主要有HBase/MongoDB/Cassandra NewSQL: 基于Spanner/F1的实现, 主要有 TiDB/CockroachDB   特点: Cassandra强调AP ，Hbase强调CP, Spanner 支持分布式事务
 其他概念  LSM: Log-Structured Merge SSTable: Sorted Strings Table paxos/raft : 一致性算法 HTAP: Hybrid transactional/analytical processing WAL: Write Ahead Logging MVCC(Multi-Version Concurrency Control): 多版本并发控制  资源 一些中文翻译和相关网页
 厦大中文版本 OpenOpen中文版本 </content>
    </entry>
    
     <entry>
        <title>NodeJS及前端开发</title>
        <url>/blog/nodejs-and-frontend/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 因为最近使用的两个博客系统都是基于NodeJS开发的,也顺便谈谈我理解的JavaScript及前端开发.
NodeJS的是伴随Chrome的V8 Engine而出现,由于JS群众基础及高性能而快速发展,本质是它使用类似Nginx的事件循环模型可以处理极高的并发请求.异步IO及基于NodeJS的第三方库都提供的异步版本,使得较简单的编程模型带来极高的性能, JavaScipt这一应用于前端开发的古老语言焕发出新的生机.
早期前端开发的JavaScript由于要处理浏览器版本兼容且语言本身问题,充斥着丑陋的代码. 伴随着JQuery及第三方框架/库的流行,JavaScript也变得优美起来.
前端开发三剑客: HTML &#43; CSS &#43; JavaScript这些年随着新标准的发展也比我最初接触时强大易用多了, 一切事物还真得以发展的眼光看待,技术领域尤其容不得偏见.

因为偶尔会忘记,下面记些简单的笔记:
NodeJS Node是一个JS应用的平台,而不是框架. 尤其适用于数据密集型实时服务和大并发量/小数据块的长连接场景.
 匿名函数调用也被称为回调(a.k.a callback) steams是随时间进行的数据分发  Node版本 稳定版本: 6.x /最新版本: 9.x
使用n管理多版本 npm install -g n n stable # n lts 使用nvm管理多版本 curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bash nvm install node nvm use node 卸载 # Ubuntu sudo rm -rf /usr/local/lib/node_modules sudo rm -rf ~/.npm # Mac brew uninstall --force node 包管理npm # 安装 curl -0 -L https://npmjs.com/install.sh | sudo sh 选项说明:
 -g: 代表全局  使用淘宝镜像 npm在国内的使用环境很糟,经常安装第三方包超时,强烈建议换成国内镜像.
# https://npm.taobao.org/ # 相关工具镜像 https://npm.taobao.org/mirrors npm install -g cnpm --registry=https://registry.npm.taobao.org # 使用别名 cnpm echo &amp;#39;\n#alias for cnpm\nalias cnpm=&amp;#34;npm --registry=https://registry.npm.taobao.org \ --cache=$HOME/.npm/.cache/cnpm \ --disturl=https://npm.taobao.org/dist \ --userconfig=$HOME/.cnpmrc&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.zshrc &amp;amp;&amp;amp; source ~/.zshrc 依赖管理 Yarn Facebook出品替代npm的新工具
# https://yarnpkg.com/lang/en/docs/install/ # Mac brew install yarn # 会自动安装Node brew install yarn --without-node # 使用node版本管理工具安装 资源  Mac使用指南 How To Install Node.js on Ubuntu 16.04  前端工具集 包管理 Bower
构建工具  注: 前面出现的较新
 自动化构建工具
Gulp vs. Grunt
把依赖全部提取到一个文件
webpack vs. browserify
桌面开发Electron 最早知道基于HTML&#43;CSS&#43;JavaScript的桌面开发是看到豌豆荚团队的访谈,知道了基于Chromium的CEF框架.
之后不断演进出优秀的Electron,该框架极大的简化了跨平台开发的成本,你很难想象VSCode,Slack等工具是基于Electron和Web开发技术做出来的.
JavaScript Babel JavaScript转换器,把高版本(ES标准)转换为浏览器兼容版本
JS语言增强  TypeScript CoffeeScript  资源  MDN学习资源  CSS CSS扩展语言  Less Stylus Saas  响应式设计 资源  @media 控制不同尺寸设备的显示 CSS3 模板 MDN学习资源  链接  百度的轮子 Babel : Facebook出品 Grunt </content>
    </entry>
    
     <entry>
        <title>静态博客Hexo</title>
        <url>/play/blog-hexo/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 可能过于追求完美,使用Ghost博客两个多月,感觉功能还是过于简单,许多常用的功能用户早就提了Issue,官方却认为不是核心.
比如常用的文章目录,归档页,搜索功能等. 文章目录折腾下来已经可用了,搜索折腾了一半,实在没时间调试放弃了.见新博客这篇记录文章.
本来用这么个博客系统是为了不折腾,索性迁移到了之前熟知的Hexo&#43;NexT(国人最好用主题),该主题常用的扩展都提供,没想到的功能也支持,很👍.

安装及配置 npm install hexo-cli -g hexo init blog cd blog npm install hexo server ## 产生静态文件，默认存放于 public  hexo generate # 部署,我使用rsync的方式  hexo deploy 常用功能 主要参考./theme/next/_config.yml相应注释按步骤操作。
 RSS 调整主题scheme以获取不同的展示效果 增加搜索功能 使用rsync部署  // package.json { &amp;#34;name&amp;#34;: &amp;#34;hexo-site&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;0.0.0&amp;#34;, &amp;#34;private&amp;#34;: true, &amp;#34;hexo&amp;#34;: { &amp;#34;version&amp;#34;: &amp;#34;3.5.0&amp;#34; }, &amp;#34;dependencies&amp;#34;: { &amp;#34;hexo&amp;#34;: &amp;#34;^3.2.0&amp;#34;, &amp;#34;hexo-algolia&amp;#34;: &amp;#34;^1.2.4&amp;#34;, &amp;#34;hexo-deployer-rsync&amp;#34;: &amp;#34;^0.1.3&amp;#34;, &amp;#34;hexo-generator-archive&amp;#34;: &amp;#34;^0.1.4&amp;#34;, &amp;#34;hexo-generator-category&amp;#34;: &amp;#34;^0.1.3&amp;#34;, &amp;#34;hexo-generator-feed&amp;#34;: &amp;#34;^1.2.2&amp;#34;, &amp;#34;hexo-generator-index&amp;#34;: &amp;#34;^0.2.0&amp;#34;, &amp;#34;hexo-generator-tag&amp;#34;: &amp;#34;^0.2.0&amp;#34;, &amp;#34;hexo-migrator-ghost&amp;#34;: &amp;#34;^0.1.0&amp;#34;, &amp;#34;hexo-renderer-ejs&amp;#34;: &amp;#34;^0.3.0&amp;#34;, &amp;#34;hexo-renderer-marked&amp;#34;: &amp;#34;^0.3.0&amp;#34;, &amp;#34;hexo-renderer-stylus&amp;#34;: &amp;#34;^0.3.1&amp;#34;, &amp;#34;hexo-server&amp;#34;: &amp;#34;^0.2.0&amp;#34; } } 一些增强功能的展示 大部分功能只需要在配置中修改，非常易用。
{% note success %}
Success 说明文本
{% endnote %}
{% note info %}
info 说明文本
{% endnote %}
{% cq %} 人的一切痛苦,本质上都是对自己无能的愤怒.
** 王小波 **
{% endcq %}
{% fi /images/publication-cover.png, 测试, 好图 %}
链接  Hexo NexT主题文档 </content>
    </entry>
    
     <entry>
        <title>Linux调试命令/工具</title>
        <url>/blog/linux-debug-command/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html"> Linux的强大之一是丰富的命令系统,尤其在调试服务端应用时.
记录在这里方便查阅.

资源统计 yum install sysstat mpstat -P ALL 1 pidstat 1 top -p &amp;lt;pid ## 内存,IO相关  free -m vmstat 1 iostat -xz 1 top/htop 名称解释
 RSS: Resident Set Size VmRSS: 进程除了swap外使用的物理内存大小 VmSwap: swap大小  watch # 每隔2秒更新一次内存变化 watch free -h sar sar是System Activity Reporter（系统活动情况报告）的缩写
sar -n DEV 1 sar -n TCP,ETCP 1 vmstat vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可实时动态监视操作系统的虚拟内存、进程、CPU活动。
 cs: 代表 context switches in: 代表 interrupts  iostat 使用-x参数我们可以获得更多统计信息
 rrqm/s：每秒这个设备相关的读取请求有多少被Merge了(当系统调用需要读取数据的 时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge);wrqm/s：每秒这个 设备相关的写入请求有多少被Merge了。
 rsec/s：每秒读取的扇区数;wsec/： 每秒写入的扇区数。r/s：The number of read requests that were issued to the device per second;w/s：The number of write requests that were issued to the device per second; await：每一个IO请求的处理的平均时间(单位是微秒)。这里可以理解为IO的响应时 间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。 %util：在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该 设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8&amp;frasl;1 = 80%，所以该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了(当然如果是多磁盘，即使%util是100%，因 为磁盘的并发能力，所以磁盘使用未必就到了瓶颈)。  命令参数
iostat [-c|-d] [-k] [-t] [间隔描述] [检测次数]
参 数：
-c : 仅显示cpu的状态 -d : 仅显示存储设备的状态，不可以和-c一起使用 -k : 默认显示的是读入读出的block信息，用-k可以改成KB大小来显示 -t : 显示日期 -p device | ALL : device为某个设备或者某个分区，如果使用ALL，就表示要显示所有分区和设备的信息 CPU 占用情况包括四块内容 %user：显示user level (applications)时，CPU的占用情况。 %nice：显示user level在 nice priority 时，CPU 的占用情况。 %sys: 显示 system level (kernel)时，CPU 的占用情况。 %idle: 显示CPU 空闲时间所占比例。 磁盘使用报告分成以下几个部分： Device: 块设备的名字 tps: 该设备每秒 I/O 传输的次数。多个 I/O 请求可以组合为一个，每个 I/O 请求传输的字节数不同，因此可以将多个 I/O 请求合并为一个。 Blk\_read/s, Blk\_wrtn/s: 表示从该设备每秒读写的数据块数量。块的大小可以不同，如1024, 2048 或 4048 字节，这取决于 partition 的大小。 Blk\_read, Blk\_wrtn: 指示自从系统启动之后数据块读/写的合计数。也可以查看这几个文件/proc/stat，/proc/partitions，/proc/diskstats的内容。 mpstat mpstat是MultiProcessor Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。
# 每隔2秒显示一次 mpstat 2 mpstat -P ALL mpstat -P 0 3 3 # 对第一块CPU，每隔3秒监控一次，重复3次。 关键字段解释： LOC :Local interrupt Timer
CPU CPU 编号,all 那行是所有CPU的平均统计值。 %user 在监控的时间间隔内，用户级进程（运用程序）占用的CPU时间百分比。 %nice 在监控的时间间隔内，nice值为负的用户级进程所占用的CPU时间百分比。 %sys 在监控的时间间隔内，系统及进程（内核）占用的CPU使用率。该时间包括了系统处理软、硬中断所花的时间。 %iowait 在监控的时间间隔内，等待硬盘I/O的时间，CPU的闲置时间百分比。 %irq 在监控的时间间隔内,CPU服务硬中断的所占的时间百分比。 %soft 在监控的时间间隔内，CPU服务软中断的所占的时间百分比。 %idle 在监控的时间间隔内，CPU闲置时间所占用的时间百分比，不包括等待磁盘IO请求的时间。 其中最重要的字段是%idle,%iowait。如果%idle 说明CPU的负载不高。如果%iowait，说明存在I/O竞争。 也可以使用输出重定向保存mpstat对CPU的监控数据，用作CPU历史使用率分析。 si 软中断太高: cat /proc/interrupts uptime dmesg 内核日志  dmesg | tail
 文件/进程类 ps # 查看用户线程数 ps -fLu xulz # 根据pid找到process ps -p &amp;lt;pid -o comm= # 运行队列 ps -eo stat,pid,user,command | egrep &amp;#34;^STAT|^D|^R&amp;#34; # D : Uninterruptible sleep (usually IO) # R : Running or runnable (on run queue) 进程检索/管理 # 显示进程树  pstree -p pgrep kill/pkill用法:
# 默认用SIGTERM (terminate)信号终止进程 kill &amp;lt;porcess_id # 列出可用(不带SIG前缀的)信号名 kill -l # 立即终止进程 kill -9|KILL &amp;lt;process_id # 根据进程名称(而不是id) pkill &amp;lt;process_name pkill -f &amp;#34;command_name&amp;#34; lsof 列出文件打开情况
# 查看某进程打开连接 lsof -i -a -p `pidof firefox` # 或者 ss -nap | grep $(pidof firefox) # 查看端口占用 lsof -i :portNumber lsof -i :22 taskset set or retrieve a process&amp;rsquo;s CPU affinity
# 显示当前进程的 affinity taskset -c -p 1162 # 设置进程的affinity taskset -c 0,1 -p 1162 taskset -c 1  proc Process information pseudo-filesystem
man proc /proc/&amp;lt;pid/status /proc/&amp;lt;pid/statm #Memory valgrind 查内存泄漏
网络类 # 显示所有打开连接 ss -l # 或者 netstat -tlpn netstat -anp # 或者 lsof -i # 更精确的方式显示打开的网络端口 nmap -sT -O localhost # 如果遇到未知服务打开端口: cat /etc/services | grep 834 网络连接监控ss socket stats
ss -s ss -lp | grep 8080 netstat 常用选项:
 -a/&amp;ndash;all: 显示监听和非监听连接 -n: 显示IP  # 显示所有TCP  netstat -nat #Windows  netstat -aon | more # 显示建立的TCP连接  netstat -np | grep ESTABLISHED | wc -l netstat -nat | grep &amp;#39;ESTABLISHED&amp;#39; netstat -s |grep &amp;#39;connections established&amp;#39;  cURL 命令行文件传输工具.
常用选项:
-d, --data 使用类型 application/x-www-form-urlencoded做POST -F, --form &amp;lt;name=content -x, --proxy 代理设置 -X, --request &amp;lt;command&amp;lt;/command 指定类型 -I, --head 只显示响应头，在响应体较大时很有用# 在内网查看外网IP curl ifconfig.me wget 域名解析 nslookup www.google.com dig xulizhao.com dnstracer dig &#43;trace xulizhao.com # 查找域名服务器 less /etc/resolv.conf nmcli device show &amp;lt;interfacename| grep IP4.DNS Windows从IP得到hostname: ping -a 10.10.10.10
修改DNS ## Ubuntu vi /etc/network/interfaces dns-nameservers 8.8.8.8 # 重启服务 /etc/init.d/networking restart ## CentOS vi /etc/resolv.conf nameserver 8.8.8.8 网络调试traceroute/mtr mtr可以看做traceroute的加强版 显示数据包在IP网络经过的路由器的IP地址,一直达到默认或用参数指定的追踪限制（maximum_hops）才结束追踪. [Windows] tracert 响应格式: Hop RTT1 RTT2 RTT3 Domain Name [IP Address] 每个hop发送三个包, * 代表丢包 使用ICMP协议 (同ping); RTT: round trip time ; 延时突然增加并持续的增加通常意味着问题; 网络数据统计iftop r 代表receive
# 某网口带宽占用 iftop -i eth1 # 子网数据流 iftop -F 192.168.1.0/24 网络模拟tc/netem 模拟网络延迟,丢包,重复,乱序等
软件调试类  strace/dtruss: 系统调用跟踪工具 ltrace：查询库调用  辅助类  pv : 管道进度监控  # 相当于cat # 监控某进程文件 pv -d &amp;lt;pid&amp;gt; # 管道命名 pv -cN gzip 扩展阅读  如何用curl做API接口测试 Linux 工具快速教程 ss命令详解 traceroute解释1/2 </content>
    </entry>
    
     <entry>
        <title>Redis</title>
        <url>/blog/redis/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 最流行的内存数据库,Redis可以理解为Remote Dictionary Service.

基本配置 # 默认端口 6379 # 配置文件 /etc/redis/redis.conf bind 0.0.0.0 # 运行远程访问,开发环境 redis-cli # 常用命令 ping # 检查连通性 -h &amp;lt;host&amp;gt; -p &amp;lt;port&amp;gt; shutdown flushall 清数据库 INFO SLAVEOF NO ONE / hostname port CONFIG SET protected-mode no 集群/高可用 Redis Cluster 提供自动分片(sharding)和部分高可用
可用性：只要集群中大多数master可达、且失效的master至少有一个slave可达时，集群都可以继续提供服务
# 两种安装方式 # Ruby脚本方式 yum install ruby -y yum install rubygems gem install redis # 自带脚本 cd utils/create-cluster/ # 编辑create-cluster文件,更新35行 HOSTS=&amp;#34;$HOSTS &amp;lt;YOUR_SERVER_IP&amp;gt;:$PORT&amp;#34; ./create-cluster start ./create-cluster create # 停止/卸载 ./create-cluster stop ./create-cluster clean ## 密码认证 config set masterauth p@ssw0rd config set requirepass p@ssw0rd config rewrite # 带参数 --masterauth p@ssw0rd --requirepass p@ssw0rd Redis Sentinel 提供高可用及以下功能:
 Monitoring
 通知
 自动故障转移Failover (Master -&amp;gt; Slave)
 配置提供者(为客户端提供唯一入口)
  优化 # 编辑/etc/sysctl.conf net.core.somaxconn=65535 # 或及时生效 sysctl -w net.core.somaxconn=65535 管理工具  RedisDesktopManager: GUI工具,提供Windows安装包 redsmin: 云端管理界面  资源  codis: 豌豆荚开源集群 </content>
    </entry>
    
     <entry>
        <title>MySQL</title>
        <url>/blog/mysql/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag><tag>mysql</tag><tag>database</tag>
        </tags>
        <content type="html"> 最流行的开源关系型数据库,常用的MySQL版本为社区版或Percona版.

安装及配置 # 安全化安装  sudo apt install mysql-server sudo mysql_secure_installation # 设置root密码, Percona  /usr/bin/mysqladmin -u root password &amp;#39;new-password&amp;#39; # 配置文件  /etc/mysql/my.cnf # CentOS  /etc/sysconfig/mysql # Ubuntu  /etc/default/mysql 授权登录  GRANT ALL PRIVILEGES ON dbname.* TO &amp;lsquo;USERNAME&amp;rsquo;@&amp;lsquo;IP&amp;rsquo; IDENTIFIED BY &amp;lsquo;PASSWORD&amp;rsquo;;
  grant与on之间是各种权限，例如:insert,select,update等 on之后是数据库名和表名,第一个_表示所有的数据库，第二个_表示所有的表 ＠后可以跟域名或IP地址(%代表所有地址)，identified by后面的是登录用的密码，可以省略，即缺省密码或者叫空密码  常用命令 CREATE USER &amp;#39;newuser&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;password&amp;#39;; select current_user(); -- 授予权限需要以 root@localhost 登录 -- 创建数据库并授权 CREATE DATABASE wordpress DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci; GRANT ALL ON wordpress.* TO &amp;#39;wordpressuser&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;password&amp;#39;; FLUSH PRIVILEGES; -- 创建相同结构 CREATE TABLE new_table LIKE old_table; -- 同时复制数据 INSERT INTO new_table SELECT * FROM old_table; -- 显示所有索引 SHOW INDEX FROM yourtable; -- 字符集 CREATE DATABASE IF NOT EXISTS `gitlabhq_production` DEFAULT CHARACTER SET `utf8` COLLATE `utf8_unicode_ci`; show variables like &amp;#34;character_set_database&amp;#34;; show variables like &amp;#34;collation_database&amp;#34;; 导出/导入数据 # 备份数据  mysqldump -d -uroot -p mydb &amp;gt;mydb_schema.sql --no-create-info, -t # 只包含数据  --skip-triggers --no-data, -d # 导入数据  mysql -h host -u username -p password --default_character_set utf8 database &amp;lt; file.sql # Load-data高速导入数据  load data local infile /root/out.txt into table table1 fields terminated by &amp;#39;,’ (field1,field2) 重置丢失的root密码 sudo mysqld_safe --skip-grant-tables &amp;amp; mysql -u root use mysql; update user set password=PASSWORD(&amp;#34;newpass&amp;#34;) where User=&amp;#39;root&amp;#39;; flush privileges; mysql-python的使用  mysql-python 需要的mysql_config 包含在 libmysqlclient-dev 或 libmysqld-dev sudo apt-get install mysql-server mysql-client libmysqlclient-dev
 性能 慢查询 -- 配置 show variables like &amp;#39;%slow_query%&amp;#39;; SET GLOBAL log_output = &amp;#39;FILE,TABLE&amp;#39;; select * from mysql.slow_log; -- 或者 mysql&amp;gt; SET GLOBAL slow_query_log = &amp;#39;ON&amp;#39;; mysql&amp;gt; SET GLOBAL slow_query_log_file = &amp;#39;/var/log/mysql/localhost-slow.log&amp;#39;; mysql&amp;gt; SET GLOBAL log_queries_not_using_indexes = &amp;#39;ON&amp;#39;; mysql&amp;gt; SET SESSION long_query_time = 1; -- 配置文件: long_query_time = 1 mysql&amp;gt; SET SESSION min_examined_row_limit = 100; 工具  自带工具: mysqldumpslow -t 5 -s at /var/log/mysql/localhost-slow.log 第三方：pt-query-digest  其他命令 select @@global.max_connections; show variables like ‘max_connections’; SELECT * FROM information_schema.STATISTICS WHERE TABLE_SCHEMA = DATABASE() 集群及高可用 Percona XtraDB Cluster 推荐至少3节点,每个节点包含全部数据的复制.主要作为读操作的扩展方案,写操作不会成倍scale.实现基于单实例并加入了写复制(同步). 限制:复制只支持InnoDB存储引擎, 系统表复制只支持DDL.写吞吐量由最差的节点决定.不支持Lock查询 用Connector/J实现负载均衡 Failover协议是“Multi-Host”链接模式中最基础的协议，“load balancing”、“replication”、“farbic”协议都基于Failover协议。 中间件 实现透明访问分布式数据库集群中的各个分库分表
 ProxySQL : High-performance MySQL proxy kingshard  一些工具  vitess: 工具集,youtube在用 orchestrator: MySQL replication topology management and HA mysql_utils:Pinterest MySQL Management Tools  资源  MySQL Yum Repository Percona Server for MySQL </content>
    </entry>
    
     <entry>
        <title>PostgreSQL</title>
        <url>/blog/postgresql/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html"> PostgreSQL是2017年流行度上升最快的数据库.
 吐槽:官方的管理工具pgAdmin真难用啊, 命令也没有MySQL易记.

 配置  端口: 5432 默认用户: postgres 配置默认目录: /var/lib/pgsql/   pg_hba.conf控制认证方式
 默认认证方式: ident,以当前登录的系统用户为数据库用户名连接 密码认证: md5 无密码: trust 使用Linux系统账号: peer(仅限于本地连接)  Ubuntu配置 配置文件位置： /etc/postgresql/10/main/pg_hba.conf
常用命令 # 连接服务器  psql -h hostname database user # 创建数据库  sudo -u postgres createuser xulz -s sudo -u postgres createdb mydb &amp;gt; createuser -E --encrypted (store password) -s --superuser -P --pwprompt &amp;gt; createdb &amp;gt; dropdb -W -U postgres -h localhost your_db_name PSQL:
-- 连接  sudo -u postgres psql -- 创建用户  CREATE USER xulz WITH PASSWORD &amp;#39;password&amp;#39;; -- 更改密码  ALTER USER &amp;#34;user_name&amp;#34; WITH PASSWORD &amp;#39;new_password&amp;#39;; -- 修改postgres密码  alter user postgres password &amp;#39;postgres&amp;#39;; #或者　\password postgres -- 用户授权  grant all privileges on database db1 to user1; -- 重命名数据库  ALTER DATABASE people RENAME TO &amp;#34;customers&amp;#34;; PSQL Command:
\dt list tables \du list users \password user_name \dn list schemas \l list database \? \c[onnect] {[DBNAME|- USER|- HOST|- PORT|-] | conninfo} #Connection 关闭所有session连接 SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = &amp;#39;dbname&amp;#39; AND pid &amp;lt;&amp;gt; pg_backend_pid(); -- 避免关闭当前连接 REVOKE CONNECT ON DATABASE dbname FROM PUBLIC, username; -- Revoke CONNECT权限以避免创建新连接 备份和还原 这里主要指逻辑备份（而不是物理备份）。
pg_dump的几个主要选项：
-U, --username=NAME connect as specified database user -F, --format=c|t|p output file format (custom, tar, plain text) -f, --file=FILENAME output file name SQL格式文件备份 ## 备份 pg_dump dbname -f db_bak.sql # 或者 pg_dump -Fp dbname &amp;gt; db_bak.sql ## psql命令还原 psql -U username -f db_bak.sql dbname # 或者直接在psql终端还原 postgres=# \i db_bak.sql 自定义格式和tar格式备份 pg_dump -Fc dbname -f filename # 还原 pg_restore -Fc -d dbname filename # tar格式与此类似，-Ft 注： pg_dumpall 用于集群级别备份，使用psql命令还原。
从数据库删除所有表 -- —clean 清除数据库 pg_dump -U postgres -h localhost -p 5432 --clean --file=sandbox.sql sandbox pg_dumpall -U postgres -h localhost -p 5432 --clean --globals-only --file=globals.sql psql -W -U postgres -h localhost your_db_name &amp;lt; backup.sql drop schema public cascade; create schema public; 方式二：
DO $$ DECLARE r RECORD; BEGIN -- 注意替换current_schema为要删除的schema FOR r IN (SELECT tablename FROM pg_tables WHERE schemaname = current_schema()) LOOP EXECUTE &amp;#39;DROP TABLE IF EXISTS &amp;#39; || quote_ident(r.tablename) || &amp;#39; CASCADE&amp;#39;; END LOOP; END $$ 性能 关注几个方面:
 索引使用 IO尽量使用缓存: cache hit ratio = blks_hit /(blks_hit&#43;blks_read) 并发连接 避免死锁 长时间查询  主要参数调优 参考 官方wiki 或Performance Tuning PostgreSQL
## postgres.conf # 通常设置为几百连接 max_connections = &amp;lt;num&amp;gt; # 1/4 ~ 1/3内存 shared_buffers = &amp;lt;num&amp;gt; Explain  Explain SQL STATEMENT  cost 建议控制在300 以内 重点关注缺少索引的大表  EXPLAIN ANALYZE 检查规划器预估值的准确性  Startup Cost Max Time Rows   监控性能数据  内部使用 pg_stats 监控用途
 数据库: pg_stat_database 表: pg_stat_all_tables tup : rows 查询 : pg_stat_statements 需要先enable plugin  编辑postgres.conf
shared_preload_libraries = &amp;#39;pg_stat_statements&amp;#39; pg_stat_statements.track = all  表监控
SELECT sum(idx_scan)/(sum(idx_scan) &#43; sum(seq_scan)) as idx_scan_ratio FROM pg_stat_all_tables WHERE schemaname=‘public&amp;#39;; SELECT relname,idx_scan::float/(idx_scan&#43;seq_scan&#43;1) as idx_scan_ratio FROM pg_stat_all_tables WHERE schemaname=&amp;#39;public&amp;#39; ORDER BY idx_scan_ratio ASC; Troubleshooting  死锁问题检查  SELECT * FROM pg_stat_activity WHERE datname = &amp;#39;deadlock database ID’; -- 找到waiting字段, procpid找到对应的列值 SELECT pg_cancel_backend (&amp;#39;死锁的procpid值&amp;#39;);  在Mac下使用pip安装psycopg2时报错:&amp;ldquo;pg_config executable not found&amp;rdquo;  解决: export PATH=$PATH:/Applications/Postgres.app/Contents/Versions/9.6/bin
与MySQL比较  更完整的事务支持 更快的列添加 更好的多核CPU支持  资源  查看表/对象大小 What PostgreSQL Tells You About Its Performance pgAdmin How To Install and Use PostgreSQL on Ubuntu 18.04 </content>
    </entry>
    
     <entry>
        <title>Linux防火墙</title>
        <url>/blog/linux-firewall/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> CentOS作为一个开发环境用还是有些繁琐了,今天因为忘了iptables防火墙默认开启,还浪费了些时间找原因.

更郁闷的是用lokkit这个工具新开通一个端口,几分钟之后之前的防火墙设置全没了.
Docker啊,赶紧给团队统一起来吧,折腾环境太无聊了.
防火墙概要 iptables  iptables是存放防火墙规则的数据库
 # 检查当前状态  iptables -nvL # 或者 service iptables status  # 关闭防火墙,在非生产环境  service iptables save service iptables stop chkconfig iptables off # 开启防火墙  service iptables start chkconfig iptables on lokkit CentOS简化命令行工具
# 允许某端口 lokkit -p 3389:tcp ufw Ubuntu简化工具: Uncomplicated Firewall
sudo ufw allow ssh/tcp sudo ufw allow 3389/tcp # 常用命令  sudo ufw logging on sudo ufw enable/disable sudo ufw status 其他工具  fail2ban: python工具,根据正则匹配日志错误并触发iptables动作  GUI工具
 Gufw FirewallBuilder: 强大而复杂  iptables详解 iptables使用表结构管理防火墙规则, 底层实际上调用Linux内核的netfilter框架.
几种表类型:
 Filter: 防火墙过滤 NAT: 地址转换 Mangle: 改变数据包IP头信息或增加标记 Raw: 用于连接追踪,保持连接会话关系/状态 Security: SELinux相关  常用命令 # 列出所有规则 -S # 删除所有规则 -F --flush # 清除计数 -Z --zero -L --list -A # 添加一条规则 -I #在指定位置插入一条规则,默认chain的第一条  # 显示行号 --line-numbers -m --match -p --protocol -i --in-interface 常用规则 # 允许本地连接 iptables -A INPUT -i lo -j ACCEPT # 开启常用服务端口 iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT # 或者 iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT # 允许在server发起建立的outgoing连接上返回数据. iptables -I INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT# 其他 # 查询对外IP w # 之后可以限定来源IP iptables -A INPUT -p tcp -s YOUR_IP_ADDRESS -m tcp --dport 22 -j ACCEPT # 允许所有outgoing iptables -P OUTPUT ACCEPT # 拒绝其他incoming iptables -P INPUT DROP # 多个端口 iptables -A INPUT -p tcp -m multiport --dport 80,443 -j ACCEPT 规则的保存/备份/恢复 注: 用命令配置重启后会失去作用,需要先保存并重启防火墙服务
#保存规则 # Ubuntu apt-get install iptables-persistent netfilter-persistent save # CentOS service iptables save # 默认保存到 /etc/sysconfig/iptables # 等价于 iptables-save | sudo tee /etc/sysconfig/iptables  # CentOS7有可能会开启firewalld, 检查firewalld 运行状态 firewall-cmd --state# 导出规则 iptables-save &amp;gt; iptables-export #恢复规则 iptables-restore &amp;lt; ~/iptables-export 规则使用说明 Chain是一组规则的集合,默认内置有几个Chain,包含INPUT,FORWARD,OUTPUT.
每个Chain有一个默认的policy, ACCEPT/DROP/REJECT
用户可以自定义新的Chain(必须通过jump到达),比如Docker启动容器时会默认创建几个.
Chain可以理解为有顺序的一系列规则,由上到下挨个匹配,没有匹配则使用默认策略.
规则构成:
 INPUT: 系统接收的数据包,打开/关闭(进口/incoming)端口/地址 OUTPUT: 系统发出的数据包,打开/关闭(出口/outgoing)端口/地址 FORWARD:通常用于路由转发,如LAN到互联网  包/packet 匹配规则:
 每个包以第一条规则开始 继续处理包直到匹配到一条规则 如果找到匹配,控制跳转到指定目标  目标/target : 指规则匹配时采取的行动.
 ACCEPT : 允许 REJECT : 丢掉包,通知错误消息给远程主机(connection refused) DROP : 丢掉包,不发错误通知  较少用到的:
 RETURN : 通常用于自定义Chain NOTRACK: 不做连接追踪  连接追踪 iptables也可以track connection/state(new,established,related).
可用状态:
 NEW ESTABLISHED RELATED: 与被标记为RELATED的连接关联,如FTP,ICMP INVALID UNTRACKED SNAT/DNAT: 原/目的地址已被转换  资源/参考  Set Up a Basic Iptables Firewall Deep Dive into Iptables Using FirewallD on CentOS 7 </content>
    </entry>
    
     <entry>
        <title>Tomcat</title>
        <url>/blog/tomcat/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>java</tag><tag>ops</tag>
        </tags>
        <content type="html"> Tomcat是最常用的Java部署容器，在我最初接触Java时就是主流，特点就是稳定.
与之类似还有个Jetty，用的不多就不涉及了.

安装 Ubuntu 安装:
apt install tomcat8 tomcat8-admin tomcat8-docs tomcat8-examples # 常用路径 /etc/tomcat8/server.xml /etc/default/tomcat8 /var/lib/tomcat8/webapps/ROOT/index.html  服務：
# /etc/systemd/system/tomcat.service  [Unit] Description=Apache Tomcat Web Application Container After=network.target [Service] Type=forking Environment=JAVA_HOME=/usr/java/default Environment=CATALINA_PID=/opt/tomcat/temp/tomcat.pid Environment=CATALINA_HOME=/opt/tomcat Environment=CATALINA_BASE=/opt/tomcat Environment=&amp;#39;CATALINA_OPTS=-Xms512M -Xmx1024M -server -XX:&#43;UseParallelGC&amp;#39; Environment=&amp;#39;JAVA_OPTS=-Djava.awt.headless=true -Djava.security.egd=file:/dev/./urandom&amp;#39; ExecStart=/opt/tomcat/bin/startup.sh ExecStop=/opt/tomcat/bin/shutdown.sh User=tomcat Group=tomcat UMask=0007 RestartSec=10 Restart=always [Install] WantedBy=multi-user.target CentOS 安装:
groupadd tomcat useradd -s /bin/false -g tomcat -d /opt/tomcat tomcat cd /opt/ wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.28/bin/apache-tomcat-8.5.28.tar.gz sudo tar xvf apache-tomcat-8*tar.gz -C /opt/tomcat --strip-components=1 chown -hR tomcat:tomcat tomcat 服务：
# vi /etc/systemd/system/tomcat.service  # Systemd unit file for tomcat [Unit] Description=Apache Tomcat Web Application Container After=syslog.target network.target [Service] Type=forking Environment=JAVA_HOME=/usr/java/default Environment=CATALINA_PID=/opt/tomcat/temp/tomcat.pid Environment=CATALINA_HOME=/opt/tomcat Environment=CATALINA_BASE=/opt/tomcat Environment=&amp;#39;CATALINA_OPTS=-Xms512M -Xmx2048M -server&amp;#39; ExecStart=/opt/tomcat/bin/startup.sh ExecStop=/bin/kill -15 $MAINPID #User=tomcat #Group=tomcat #UMask=0007 RestartSec=10 Restart=always [Install] WantedBy=multi-user.target 服务管理：
# 加载服务 systemctl daemon-reload # 启动 systemctl start tomcat # 开机启动 systemctl enable tomcat 配置 常用配置 以最常用的HTTP Connector为例, 最关键的几个参数是：
 maxThreads ： 能同时处理的请求数, 默认200有些偏小。 acceptCount ： 请求队列最大值,处理不过来就放到这个队列,队列满之后会拒绝请求. 默认100有些偏小. maxConnections ： 服务器接受并处理的最大连接数,超出后新连接会被阻塞.对于BIO连接器默认=maxThreads, NIO连接器默认10000.   Connector的实现主要是BIO,NIO,NIO2 其中BIO是大多数版本的默认实现，但是在最新版Tomcat8.5，已经不再支持BIO
 开启HTTPS 关于SSL/TLS,建议使用Nginx反向代理配置而不使用Tomcat.
Tomcat开启TLS后,性能会有所下降(CPU占用更高).官方推荐使用APR,而不使用BIO或NIO(使用Java内置的安全组件JSSE)。
 APR(Apache Portable Runtime)是Tomcat的Native Library，实现网络连接和随机数生成器.主要特点:
* 支持Keep-Alive请求的非阻塞I/O * 使用OpenSSL 版本的TLS/SSL
 关于参数调优 建议使用setenv.sh的方式调整参数，比如记录GC日志
JAVA_OPTS=&amp;#34; -Xmx6g -XX:&#43;PrintGC -XX:&#43;PrintGCDetails -XX:&#43;PrintHeapAtGC -Xloggc:/usr/local/tomcat/logs/gc.log -XX:&#43;HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/tomcat/logs/ &amp;#34; 开启远程监控JMX CATALINA_OPTS=&amp;#34; -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=1616 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=10.120.1.99 &amp;#34; 开启目录列表 default servlet 负责处理静态资源和目录列表
&amp;lt;init-param&amp;gt; &amp;lt;param-name&amp;gt;listings&amp;lt;/param-name&amp;gt; &amp;lt;param-value&amp;gt;true&amp;lt;/param-value&amp;gt; &amp;lt;/init-param&amp;gt; 压缩日志 # vi /etc/logrotate.d/tomcat /usr/local/tomcat/logs/catalina.out { copytruncate daily rotate 5 dateext compress missingok size 1024M } 调试：
 logrotate -d -f /etc/logrotate.d/tomcat
 -d = 开启调试模式 -f = 强制循环日志   其他 # 查看运行时参数  ps aux | grep catalina # 或者  jinfo # 调试debug  set -x # 使用pid  CATALINA_PID=&amp;#34;$CATALINA_BASE/bin/catalina.pid&amp;#34;  AJP( Apache JServ Protocol)的特点是作为Web Server(Apache)和Servlet Container(Tomcat/JBoss)之间的反向代理, 使用二进制协议传输,没有解析开销.
 资源链接  Tocmat7 HTTP Connector Choosing Tomcat Connectors @2014 PPT Jetty How to rotate the Tomcat catalina log file </content>
    </entry>
    
     <entry>
        <title>网络分析工具</title>
        <url>/blog/network-tools/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 这里的网络分析工具可以归为两大类:
 网络代理: 用的最多的是 Fiddler
 分析工具: 比较熟悉的是Wireshark
  
代理类 Fiddler 以Android客户端抓包为例,主要步骤为:
 [Tools]-[Options], 检查Connections和HTTPS选项,开启代理模式
 安卓浏览器访问 :8888, 下载并安装根证书
 设置安卓WIFI代理为以上地址和端口
  Charles (付费) Burp Suite 默认端口8080
mitmproxy Python写的开源调试工具, 解析/修改/重放/保存
抓包分析 Wireshark 需要区分两种过滤语言
Capture Filter: Berkley Packet Filter  示例: host xulizhao.com and port 443
 Display Filter 常用过滤器
# 地址/端口 ip.addr == 10.0.0.1 ip.src == ip.src_host == tcp.port==4000 tcp.port == 8080 and ip.addr==127.0.0.1 # HTTP http http.request # 显示所有GET请求 # 其他 # 显示所有 TCP resets tcp.flags.reset==1 # 显示所有retransmissions tcp.analysis.retransmission tcp.analysis.lost_segment tcp.analysis.ack_lost_segment # 显示包含关键字 traffic 的包 tcp contains traffic frame contains ... 知识点  Wireshark的时间戳存在偏差,非标准时间 每个包在Info存在唯一标识 DUP ACK/TCP Retransmission 是正常的 协议  802.11即以太网,在frames Internet Protocol/IP: 包含在每个以太frame,在packets Transmission Control Protocol/TCP: 包在每个IP packet,在segments Transport Layer Security/TLS: 通过TCP字节流,在records/messages Hypertext Transfer Protocol/HTTP: 在加密的TLS连接中携带,一般不可见  名词解释  TCP Spurious Retransmission: 发送方重传了接收方已确认的数据, 通常因为发送方认为该数据包丢失而重发. TCP post number reused: 可能意味网络存在重复包.   编辑/合并文件 editcap -c 10000 in.pcap out.pcap editcap -A &amp;#34;2017-05-11 12:00:00&amp;#34; -B &amp;#34;2017-05-11 13:00:00&amp;#34; in.pcap out.pcap mergecap out.pcap in1.pcap in2.pcap tcpdump  sudo tcpdump -n -s 4096 -w l.log port 80
 常用选项:
 -n: 不做地址和端口的数字/名称转换
 -i: 捕获的网卡名
 -w: 把原始包写到文件, 而不是解析并打印(默认行为). 可以用-r选项再次打印
  tcpflow 轻量级网络包分析
Android全局抓包分析(HTTP/HTTPS&#43;TCP) 最近遇到的问题是，App也使用了TCP协议，如果使用Fiddler这类HTTP代理工具会造成应用使用问题。
所以要同时抓取HTTP/HTTPS和TCP数据，安卓自带的WiFi代理便局限了。
抓包方案有2个：
Android机已ROOTED 手机端安装tcpdump，因为安卓本身就是基于*Nix的嘛，在电脑用Wireshark抓包。
其实就是一条命令：
adb exec-out &amp;#34;tcpdump -i any -U -w - 2&amp;gt;/dev/null&amp;#34; | wireshark -k -S -i - 电脑建立WiFi热点 由于是公司的手机，不能随便ROOT。思路是通过电脑的无线网络建立一个代理WiFi热点。
在Windows7/10都可以，如果是台式机，需要自备无线网卡。
# 确定 Hosted network supported/支持的承载网络为 Yes/是 netsh wlan show drivers # 建立虚拟WiFi netsh wlan set hostednetwork mode=allow ssid=testWiFi key=password # 设置网络连接共享: 右键点击正在使用的以太网络连接，[属性]-[共享]标签-勾选 [Internet共享连接]并从下拉列表选择刚创建的网络。 # Windows10位置：[Windows Settings]-[Network&amp;amp;Internet]-[Change Adapter Options] #开启无线AP netsh wlan start hostednetwork 资源 链接  Fiddler mitmproxy tcpflow  扩展阅读  fiddler安卓配置图文教程 fiddler各图标的意思 TLS的Wireshark例子 tcpdump命令详解 Android抓包方法(三) Android 抓包实践总结 </content>
    </entry>
    
     <entry>
        <title>聊聊监控系统</title>
        <url>/blog/monitoring/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 2017很快就要过去了,也顺便整理下散落在印象笔记的一些片段.
监控系统本来是运维的一个重要组成,因为工作需要也接触了一些开源的监控系统, 下面简要的聊聊我所知道的.

接触监控系统历史 开始接触监控系统是在之前公司时通过运维的Nagios访问一些数据,这个古老的系统之前有很高的占有率, 能很好的提供系统级检测和告警, 感觉界面易用性差些.后来偶然看到Cacti这个网络监控的界面,感觉清爽了许多.
第一个用起来的Munin也是同样基于RRDTool的,当时起码能满足系统和Java应用的性能监控需求.
之后了解到新浪在用Zabbix这个大而全的方案,而且提供了不少扩展. 我对这个复杂的系统有些抵触,并没有使用.
因为最熟悉Python, 也有试用过Graphite,感觉部署和配置都稍显复杂.
近两年随着大数据和时序数据库的火热, 在2016年中开始使用 InfluxDB和Grafana这对组合, 总体功能强大而灵活.
在国内,小米开源的Open-Falcon也有较多应用,我的项目太小暂时用不到:)
总的来说,最近几年的趋势是监控系统用Go开发,一般由专门的时序数据库存储数据.
监控系统组成 监控系统一般由两部分构成:
 度量数据收集和可视化 收集尽可能多的性能和状态数据 图形化做有意义的展示 如果发现可疑问题,可以关联其他图表找到原因 错误检测 按需告警, 触发条件越宽松则告警应该越少 避免误报  从监控的层次划分的话,一般包含三层监控:
 基础层: 主机的CPU,内存,网络及IO等 中间层: 应用运行的中间件层,Nginx,Tomcat,MySQL,Redis 应用层: 服务端及客户端性能数据,如API访问次数和响应时间等  现代的监控越来越关注应用层和其他层数据的整合能力,具有快速找到系统瓶颈,方便扩容或代码优化.
InfluxData提供的开源方案 开源的几个产品简称TICK. 相对于付费的企业版/云版少了集群和高可用等支持.
我主要使用的Telegraf和InfluxDB, 后两者感觉易用性太差.
展示这部分使用Grafana替代,它自带基本的告警.
 Telegraf : 性能数据的收集,插件支持丰富 InfluxDB: 核心的时序数据库,负责存储 Chronograf : 前端图形化展示 Kapacitor: 流数据处理,异常检测并触发报警  Telegraf备忘 # 安装 sudo dpkg -i telegraf_*_amd64.deb # Ubuntu sudo yum localinstall telegraf-*.rpm # CentOS # 常用插件 procstat/ netstat/ jolokia/ postgres/ statsd # 测试配置 telegraf -config /etc/telegraf/telegraf.conf -input-filter processes -test # 启动服务 sudo service telegraf start InfluxDB备忘 几个概念:
 measurement : 概念上对应SQL表,主索引是时间戳 tags : 对应表列,有索引 fields : 对应表列,无索引  # 查看日志  sudo journalctl -u influxdb.service # 命令行工具  influx ## 性能提高  # 走UDP协议  # insert走批量接口  # 如果内存够大,增加 LRU大小 InfluxQL 类SQL查询
SHOW MEASUREMENTS LIST SERIES # 查询 select * from mem where host=&amp;#39;moon&amp;#39; select \* from /.\*/ order by time desc limit 3 SHOW TAG VALUES FROM &amp;#34;mem&amp;#34; WITH KEY = &amp;#34;host&amp;#34; # 删除 drop measurement mem delete from com\_load\_avg_one where time &amp;lt; now() -1h # 时间查询, 格式now() 或者2016-11-01 HH:MM:SS  # 注: 操作符和时间之间需要 空格; 时间串需要使用 单引号 &amp;#34;; 如果不指定时间,默认为 00:00:00  # 正则匹配, 支持 measurements 和 tags  /.\*abc.\* / # 包含字符串  /^abc/ # 以指定字符串为开头  /[ab]/ #包含 a 或 b  # WHERE子语句, =~ 匹配, !~ 不匹配   Grafana # 启动服务  systemctl start grafana-server # 默认地址 http://127.0.0.1:3000/  # 默认用户名/密码:admin/admin  # 配置文件 /etc/grafana/grafana.ini Java应用的监控  Tomcat大部分通过插件形式监控 Jolokia: Remote JMX with JSON over HTTP Servo : Netflix的一个Java库,JMX的方式 jmxtrans: 也是通过JMX的方式  其他方案  StatsD: 这已经成为事实上的通用协议,聚合功能很强大. 作为插件配合telegraf工作 bosun : StackExchnage出品,侧重于告警 Cabot NetData: 轻量级极简监控 monit: 轻量级监控  资源链接  Grafana/一些数据库Dashboards InfluxDB Prometheus : SoundCloud开源的Graphite的替代品/ Prometheus与其他系统比较 Open-Falcon Graphite Sensu Zabbix RRDtool / Cacti / Munin Nagios 大家族  Nagios / 扩展 nagios-herald 客户端AgentNSClient&#43;&#43; 分支/继任Icinga 2  </content>
    </entry>
    
     <entry>
        <title>微服务</title>
        <url>/blog/microservices/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>cloud</tag><tag>architecture</tag>
        </tags>
        <content type="html"> 微服务是最近两年流行起来的一种架构设计方法,可以很好的和Docker,Kubernetes结合起来.

从最早的&amp;rdquo;单体应用&amp;rdquo;到&amp;rdquo;SOA(面向服务的架构)&amp;ldquo;再到&amp;rdquo;微服务架构&amp;rdquo;,这些新东西都是大公司搞出来的最佳实践.
软件界的真理是没有银弹,所以如果要上微服务,你就得在部署,测试和监控等其他地方做的更好(自动化),否则系统的复杂度伴随分布式系统反而上升了,得不偿失.
 不得不说ThoughtWorks搞敏捷,微服务这些新概念真的很六,但是中小公司得沉住气,晚点上车
 下面记录之前的一些整理.
什么是微服务 这里必须提到大神Martin Flower早在2014年的这篇文章.大致为:
 服务组件化  组件: 可以独立更换和升级的单元 服务件HTTP通讯  按业务组织团队  全栈的要求  做产品的态度(而非项目)  持续关注并提升  智能终端和哑管道: 粗粒度通讯(非RPC)  HTTP Rest 轻量级消息 强调性能用二进制  去中心化治理  技术选型独立  去中心话数据管理/存储  每个服务管理自己的数据库 数据一致性保证  服务件&amp;rsquo;无事务&amp;rsquo;调用 保证最终一致性   基础设施(运维)自动化  持续交付  自动化测试 自动化部署   容错设计  快速检测故障并自动恢复  监控和日志  服务状态,断路由状态,吞吐量,延迟    演进式设计  单体monolith 到 (部分)微服务   微服务网络 Service Mesh
十二要素应用宣言  这个宣言是Heroku发布的构建SaaS(软件即服务)应用的方法论.
虽然和微服务不直接相关,也适合作为参考
 使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目；
 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性；
 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源；
 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发；
 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展；
   这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。
 基准代码:一份基准代码,多份部署 依赖:显式声明依赖关系 配置: 推荐将应用的配置存储于环境变量 后端服务: 将后端服务当作附加资源 构建,发布,运行: 严格区分三个步骤 进程:以一个或多个无状态进程运行应用 端口绑定 并发 易处理: 快速启动和优雅终止可最大化健壮性 开发环境和线上环境等价 日志 管理进程  概念  循证架构:架构基于实践的证据、来自历史项目或亲自试验的经验(适合应用需求的架构), By Rod Johnson. ESB: 企业服务总线, SOA的组成部分. OSGi: Open Service Gateway Initiative, Java模块化技术,慎用.  资源  &amp;lt;微服务设计&amp;gt; by Sam Newman &amp;lt;微服务：从设计到部署&amp;gt;在线阅读 Chris Richardson 微服务系列 十二要素 </content>
    </entry>
    
     <entry>
        <title>利器之ZSH</title>
        <url>/blog/zsh/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 有些工具真的很能提高效率, 比如oh-my-zsh这个扩展(zsh本身比bash更强大).
纵观软件世界,一个软件系统能流行起来很大原因是其生态是不是够丰富和繁荣,比如容器docker,Spring框架.
oh-my-zsh提供了丰富的插件及主题,是我的装机必备. 在这里记录下常用设置.

安装及扩展 安装zsh和on-my-zsh sudo apt install zsh sh -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&amp;#34; 安装插件 # Ubuntu sudo apt install zsh-syntax-highlighting autojump # Mac brew install zsh-syntax-highlighting autojump 安装插件管理工具 antigen
https://github.com/zsh-users/antigen # Ubuntu sudo apt-get install zsh-antigen # Mac brew install antigen 更友好的显示 使用powerline
sudo apt install powerline # 或者用pip安装 pip install --user powerline-status 常用配置 根据偏好修改 ~/.zshrc
# 我喜欢的主题 agnoster ZSH_THEME=&amp;#34;agnoster&amp;#34; # 常用插件, git和autojump必备 plugins=(git autojump git-flow git-extras python sudo extract zsh-syntax-highlighting) # 配置默认用户 DEFAULT_USER=xulz 常用命令
# 重新加载配置以生效 source ~/.zshrc # 更新默认shell为zsh chsh -s /bin/zsh 缩短路径显示 如果文件路径层级较多,显示路径比较占视野. 可以修改为:
# cd ~/.oh-my-zsh/themes cp agnoster.zsh-theme xulz.zsh-theme vi xulz.zsh-theme # 修改 prompt_dir()方法 prompt_dir() { # 如果路径超过5个层级,只显示最后2级目录, Home显示为~ prompt_segment blue black &amp;#39;%(5~|%-1~/.../%2~|%4~)&amp;#39; }</content>
    </entry>
    
     <entry>
        <title>Go语言学习笔记</title>
        <url>/blog/golang/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 接触Go有段时间了，感觉有几个学习资源很有帮助：
 官方Go指南 : 边写边学, 最轻松简单的方式 系统的学习: 推荐书 ， 我是先看的中文电子版之后买的实体书。 官方文档&amp;rdquo;Effective Go/实效Go编程&amp;rdquo; : 理解Go的必读文档

自己的体会是如果只看不写，等写代码时会发现实际没记住多少。这些好资料有的地方需要多看几遍，再结合平时多写代码去理解。
  下面是一些Go语言学习笔记，作为学习的汇总。
本地运行Go指南 go get github.com/Go-zh/tour/gotour gotour  如果以上命令失败,访问中文在线版本
 本地运行Go文档 go get golang.org/x/tools/cmd/godoc godoc -http=:6060 //之后用浏览器访问 http://127.0.0.1:6060/doc/ new和make函数  new返回指针,make返回值
 new(T) : 为类型T的新对象申请零值内存并返回内存地址,(不初始化内存)的好处是不需要初始化函数.
 make(T, args) ： 为slice,map,channel等返回初始化类型T后的值(非指针)
   type Thing struct { Name string Num int } // 如果包里只有一个类型，函数名可以简写为New // 构造函数使用的简写格式 func NewThing(someParameter string) *Thing { return &amp;amp;Thing{someParameter, 33} } TBC&amp;hellip;
扩展阅读  Go库文档查询 Effective Go中英双语版 Go如何初始化 Effective Go: new和make的区别 </content>
    </entry>
    
     <entry>
        <title>Go网络开发笔记</title>
        <url>/blog/go-networking/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 用Go开发网络很常见,由于对系统库还不是很熟,做下简单的笔记.

系统库模块  net : TCP连接 net.Conn net/http : HTTP处理 crypto/tls : SSL/TLS处理网络数据处理 encoding/json encoding/binary  JSON的要点  Go对象与JSON转换：  Marshal : 把对象编码为JSON数据格式 Unmarshal： 把JSON数据解码为Go 对象  streams形式的JSON数据读写(Reader/Writer)：  NewDecoder 从输入读取并编码 NewEncoder 编码并写入输出   type Foo struct { Bar string } body := new(bytes.Buffer) foo1 := Foo{&amp;#34;barTest&amp;#34;} json.NewEncoder(b).Encode(foo1) res, _ := http.Post(&amp;#34;https://httpbin.org/post&amp;#34;, &amp;#34;application/json; charset=utf-8&amp;#34;, body) foo2 := new(Foo) // new返回指针 json.NewDecoder(r.Body).Decode(foo2) foo3 := Foo{} // 或者 var foo3 Foo json.NewDecoder(r.Body).Decode(&amp;amp;foo3)  *RawMessage:指针,处理嵌套json  // 接受收到json嵌套格式的响应, {&amp;#34;name&amp;#34;:{&amp;#34;first&amp;#34;:&amp;#34;Michael&amp;#34;,&amp;#34;last&amp;#34;:&amp;#34;Xu&amp;#34;},&amp;#34;gender&amp;#34;:&amp;#34;male&amp;#34;}  //var dat map[string]*json.RawMessage  var dat map[string]interface{} json.Unmarshal(response, &amp;amp;dat) r := dat[&amp;#34;name&amp;#34;].(map[string]interface{}) firstName := r[&amp;#34;first&amp;#34;].(string) 代码示例 HTTP的例子 // 忽略HTTPS证书检查,因为本地用的自签名  tr := &amp;amp;http.Transport{TLSClientConfig: &amp;amp;tls.Config{InsecureSkipVerify: true}} // 自定义客户端  client := &amp;amp;http.Client{Transport: tr} payload := `{&amp;#34;username&amp;#34;:&amp;#34;xulz&amp;#34;}` // 创建请求,注:为简单期间忽略了错误检查  req, _ := http.NewRequest(&amp;#34;POST&amp;#34;, &amp;#34;https://xulizhao.com/api/login&amp;#34;, bytes.NewBuffer([]byte(payload))) // 定制头信息  req.Header.Set(&amp;#34;Content-Type&amp;#34;, &amp;#34;application/json&amp;#34;) resp, _ := client.Do(req) // 记得关闭连接  defer resp.Body.Close() // 把响应转换为对象  var ret LoginResponse if err := json.NewDecoder(resp.Body).Decode(&amp;amp;ret); err != nil { log.Warn(&amp;#34;error in json decode&amp;#34;, err) } TCP的例子 type LoginReq struct { Username string `json:&amp;#34;username&amp;#34;` Password int `json:&amp;#34;password` } // 读数据  func handleRead(conn net.Conn) []byte { buf := make([]byte, 1024) // 注: 返回读到的字节数  rLen, err := conn.Read(buf) checkError(err) r := buf[:rLen-1] // 假设前2个字节为实际数据大小  size := binary.BigEndian.Uint32(r[:2]) log.Debug(&amp;#34;Recv:&amp;#34;, string(r)) return r } // 写数据  func handleWrite(conn net.Conn, cmd []byte) { _, err := conn.Write(cmd) log.Debug(&amp;#34;Sent:&amp;#34;, string(cmd)) checkError(err) } func main() { // 客户端忽略TLS检查  conf := &amp;amp;tls.Config{InsecureSkipVerify: true} server := ServerHost &#43; &amp;#34;:&amp;#34; &#43; ServerPort // 建立TCP连接  conn, err := tls.Dial(&amp;#34;tcp&amp;#34;, server, conf) checkError(err) defer conn.Close() auth := LoginReq(&amp;#34;xulz&amp;#34;, &amp;#34;password&amp;#34;) handleWrite(conn, auth) handleRead(conn) }
扩展阅读  json的用法讲解 官方博客, 代码示例 Go socket编程实践 </content>
    </entry>
    
     <entry>
        <title>IntelliJ IDE</title>
        <url>/blog/intellij-ide/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 接触最早最多的IDE是Eclipse,当时一有大版本我就下载更新,却总感觉变化不大.
后来时不时有人安利IntelliJ,我试用后体会不深,再说商业版很贵(早期没有社区版),没有继续使用.
做Python开发后,慢慢从Eclipse&#43;PyDev逐渐切换到PyCharm,感觉这才是IDE的样子,也就是足够智能.
之后越来越喜欢全家桶,IDEA,DataGrip,GoLand, 毕竟操作习惯了,而且我每次安装完必须给界面换成Darcula的黑色主题.

 话说最早喜欢JetBrains家的产品可以追溯到他出品的RSS阅读器:Omea Reader
 说这些只想分享鼓励更多人使用这个全球最好用的IDE系列.
下面是一些使用技巧,也许你已经知道.
运行Go代码前先格式化 问题: 做调试临时注释后,每次运行要先注释掉不用的import,真的挺烦人
解决: 先下载 File Watchers这个官方插件,之后到 [Preference]-[Tools]-[File Watchers]建立规则(程序路径根据本机情况调整):
  Go Imports  </content>
    </entry>
    
     <entry>
        <title>Go开发遇到的坑</title>
        <url>/blog/go-fix-it/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 由于之前主要用的是Python这类动态语言,切换到Go还有些不适应.
这些出错信息看的一头雾水,记下来供参考.

坑1: invalid memory address or nil pointer dereference 场景: 用http包给指定的api发送POST一段json数据
原因: 我使用的URL是自签名的https服务,需要声明忽略SSL检查
tr := &amp;amp;http.Transport{TLSClientConfig:&amp;amp;tls.Config{InsecureSkipVerify:true},} client := &amp;amp;http.Client{Transport:tr}</content>
    </entry>
    
     <entry>
        <title>Kubernetes</title>
        <url>/blog/kubernetes/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>kubernetes</tag><tag>ops</tag>
        </tags>
        <content type="html"> Kubernetes(缩写为k8s)是最流行的开源容器管理平台, 现在也是事实上的容器编排调度标准.
打算写系列的相关文章,记录自己的学习过程.
 Kubernetes部署篇:本地开发测试环境搭建 Kubernetes部署篇:Kubespray方式自动化 用kubeadm手动搭建Kubernetes集群 kubectl命令汇总 Kubernetes命名空间的应用  
一些其他笔记.
最佳实践  不要设置比必要的默认值 不要使用裸Pod, 使用Deployment,ReplicaSet,Job 使用前提前创建Service, 使用域名 善用label 容器镜像不要使用:latest标签 (默认的imagePullPolicy是IfNotPresent,即本地不存在镜像时才pull) 灵活使用目录, kubectl apply/create -f  快速创建单容器的部署/服务: kubectl run/expose  缩写    缩写 描述     CRD Custom Resource Definition, k8s 1.7引入    运行应用 Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义(declarative)方法，用来替代以前的ReplicationController 来方便的管理应用。
在新版本的Kubernetes中建议使用ReplicaSet来取代ReplicationController。
将kubectl的 &amp;ndash;record 的 flag 设置为 true可以在 annotation 中记录当前命令创建或者升级了该资源。
# 检查 Deployment 升级的历史记录 kubectl rollout history deployment/nginx-deployment # 单个变更的详情 kubectl rollout history deployment/nginx-deployment --revision=2 集群资源管理 Label  &amp;ldquo;release&amp;rdquo; : &amp;ldquo;stable&amp;rdquo;, &amp;ldquo;release&amp;rdquo; : &amp;ldquo;canary&amp;rdquo; &amp;ldquo;environment&amp;rdquo; : &amp;ldquo;dev&amp;rdquo;, &amp;ldquo;environment&amp;rdquo; : &amp;ldquo;qa&amp;rdquo;, &amp;ldquo;environment&amp;rdquo; : &amp;ldquo;production&amp;rdquo; &amp;ldquo;tier&amp;rdquo; : &amp;ldquo;frontend&amp;rdquo;, &amp;ldquo;tier&amp;rdquo; : &amp;ldquo;backend&amp;rdquo;, &amp;ldquo;tier&amp;rdquo; : &amp;ldquo;cache&amp;rdquo;  扩展阅读  Configuration Best Practices Kubernetes中文指南  注: 官方文档是学习的开始,博客文章通常有时效性,而Kubernetes的版本更新很快.
</content>
    </entry>
    
     <entry>
        <title>Docker基础</title>
        <url>/blog/docker/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>container</tag><tag>docker</tag><tag>ops</tag>
        </tags>
        <content type="html"> 最近两年随着微服务而流行起来的Docker是一种轻量级容器技术(相对于VMWare,KVM等Hypervisor解决方案).
它能给开发,测试,运维各团队提供一个统一的运行环境, 这点很实用.
Docker可以看做在内核容器技术(Cgroup和Namespace)的基础上提供更高级功能的控制工具,主要特性:
(1)跨主机部署(2)以应用为中心 (3)自动构建 (4)版本管理 (5)组建重用 (6)共享 (7)工具生态链

 补充: 关于虚拟化的主流分类
 操作系统(服务器)级别的虚拟化: 在硬件层之上做Hypervisor,内核级隔离. 常见的有VMWare vsphere, XEN,KVM, Hyper-V
 进程(容器)级别的虚拟化: Docker 和LXC(Linux Container)
   配置国内镜像 国内使用前Docker的第一件事,必须先配置国内镜像加速器,否则下载容器镜像龟速(最近安装docker也不用了)
 中科大镜像(推荐):docker CE源使用手册/Docker HUB源使用手册 Aliyun DaoCloud : 需要先注册 Docker 中国官方镜像加速:运行了几个月就不可用了,够坑爹的😤  使用示例：
# 如果想永久保存，编辑/etc/docker/daemon.json并添加  { &amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://docker.mirrors.ustc.edu.cn/&amp;#34;] } # 必须重启服务以生效  sudo service docker restart 安装  Ubuntu Guide Docker CE for Mac Docker CE for Windows  Ubuntu环境安装 # 安装Docker  sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository &amp;#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable&amp;#34; sudo apt-get -y update sudo apt-get -y install docker-ce # 安装docker-compose  sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose sudo chmod &#43;x /usr/local/bin/docker-compose CentOS离线安装 依赖库: libcgroup和device-mapper-*
# 离线包下载: http://rpmfind.net/linux/rpm2html/search.php rpm -ivh clibcgroup-* rpm -ivh device-mapper-* --force --nodeps # 追加一行到/etc/fstab none /sys/fs/cgroup cgroup defaults 0 0 # 重启以生效 shutdown -r now # 启动cgroup service cgconfig start # 下载docker: https://yum.dockerproject.org/repo/main/centos/6/Packages/ rpm -ivh docker-engine-*.rpm service docker start 基础命令  docker docker-compose : 编排 docker-machine (Docker Toolbox已过时,不推荐使用)  # 把当前用户添加到docker组  sudo usermod -aG docker xulz ## docker  docker run # 在新容器运行命令  docker start # 启动容器  # 查看所有容器  docker ps -a docker ps -a --no-trunc # 显示完整的命令  # 查看所有镜像  docker images docker stop/rm xxx # 删除  docker rm &amp;lt;container_id&amp;gt; docker rmi &amp;lt;image_id&amp;gt; # 加载镜像  docker load &amp;lt; &amp;lt;image_file&amp;gt; # 复制文件到容器  docker cp source_file &amp;lt;container_name&amp;gt;:destination # 切换到容器终端  docker exec -it container_name /bin/bash # 在后台启动  docker start `docker ps -q -l` # restart it in the background  docker attach `docker ps -q -l` # reattach the terminal &amp;amp; stdin  # Detatch: Ctrl&#43;p &#43; Ctrl&#43;q  ## 常用compose命令  docker-compose up —build docker-compose ps docker-compose stop ## docker-machine  docker-machine ip docker-machine env Docker Hub 到hub.docker.com注册自己的ID, 提供一个私有仓库及不限共有仓库．
今天为了国内访问kubernetes的学习项目方便，建立了一个镜像，步骤如下：
# 需要先在网页创建仓库  # 再命令行登录hub  docker login docker pull gcr.io/google-samples/kubernetes-bootcamp:v1 docker tag gcr.io/google-samples/kubernetes-bootcamp:v1 xulz/kubernetes-bootcamp:v1 docker push xulz/kubernetes-bootcamp:v1 用Docker部署Flask Web App的示例 主要用到的配置文件:
 Dockerfile : 存放自动化的创建镜像的全部指令&amp;gt; docker build docker-compose.yml : 创建多个容器的模板文件,主要包含services,volumns,network .env : 设置环境变量 .dockerignore : 忽略文件  扩展  Portainer : Docker管理 Web界面 docker-compose-ui: Docker Compose Web界面  与Vagrant比较  docker-compose exec CONTAINER /bin/sh == vagrant ssh docker cp == vagrant scp  资源参考  Docker从入门到实践 Docker入门教程-英文 Awesome Docker Docker Cheat Sheet </content>
    </entry>
    
     <entry>
        <title>利器之TMUX</title>
        <url>/blog/tmux/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>linux</tag>
        </tags>
        <content type="html">  用法  tmux ls : list sessions tmux attach -t 0 : -t 代表“target” , 0 是session名 tmux kill-session -t 0 : 结束会话 tmux source ~/.tmux.conf : 重新加载配置 复制和粘贴: 使用Shift临时禁用tmux,然后Ctrl&#43;Shift&#43;C  常用快捷键    Key Description     C-b (Ctrl-b) Send the prefix key   M (Alt, meta key)    prefix c new-window   prefix &amp;ldquo; split-window   prefix % split-window -h   prefix z resize-pane -Z   prefix $ Rename the current session   prefix , Rename the current window   prefix M-1 select-layout even-horizontal   prefix M-2 select-layout even-vertical   prefix M-3 select-layout main-horizontal   prefix M-4 select-layout main-vertical   prefix M-5 select-layout tiled    流行配置 如果懒得折腾，有个流行的通用配置已经够用。见一套常用配置
cd git clone https://github.com/gpakosz/.tmux.git ln -s -f .tmux/.tmux.conf cp .tmux/.tmux.conf.local . # 编辑～/.tmux.conf.local 以定制自己的新需求 使用会话保存和恢复插件 我精彩使用自动保存和恢复的功能，用到了插件管理和几个插件。 使用步骤如下：
# 1. 安装 Plugin Manager git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm # 2. 编辑 .tmux.conf 或.tmux.conf.local set -g @plugin &amp;#39;tmux-plugins/tpm&amp;#39; set -g @plugin &amp;#39;tmux-plugins/tmux-resurrect&amp;#39; set -g @plugin &amp;#39;tmux-plugins/tmux-continuum&amp;#39; set -g @continuum-restore &amp;#39;on&amp;#39; run &amp;#39;~/.tmux/plugins/tpm/tpm&amp;#39; # 3. 安装配置里的插件 prefix &#43; I # 大写的I代表Install prefix &#43; U # 更新插件  # 4. 重启后恢复会话 prefix &#43; Ctrl-s # 保存 prefix &#43; Ctrl-r # 恢复 其他插件 # .tmux.conf set -g @plugin &amp;#39;tmux-plugins/tmux-sensible&amp;#39; # 常用配置 set -g @plugin &amp;#39;tmux-plugins/tmux-yank&amp;#39; # 复制/粘贴  Vim Tmux Navigator Tmuxinator 也是用于管理会话的  小技巧 技巧1: 总是保留一个会话 终端启动时先运行 tmux attach -t base || tmux new -s base
技巧2: 多面板命令同步 把当前输入发送到当前窗口的所有面板 setw synchronise-panes
技巧3: 缩放 prefix &#43; z放大当前面板, 再次输入恢复。
资源及参考  Manual 10 Killer Tmux Tips  </content>
    </entry>
    
     <entry>
        <title>Go流行库简介</title>
        <url>/blog/go-lib/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go作为最近几年随大数据,Docker而火热起来(依然偏小众)的服务端语言,最近接触下来的感觉是第三方库/框架还是不够稳定和丰富,很多应用场景还没有一个绝对地位的首选库.
偶尔发现LibHunt还不错,可以在库选型时做些对比.

数据处理  go.uuid gjson  系统扩展  logrus  import ( // UUID生成,支持v1~v4  &amp;#34;github.com/satori/go.uuid&amp;#34; // logging/日志扩展必备  // 使用别名 log替代系统模块  log &amp;#34;github.com/sirupsen/logrus&amp;#34; //JSON Parser,尤其适用于嵌套多层的json  &amp;#34;github.com/tidwall/gjson&amp;#34; ) // UUID示例 id := uuid.NewV4().String() // 支持定义日志级别 log.SetLevel(log.DebugLevel) log.Debug(resp.StatusCode) log.WithFields(log.Fields{&amp;#34;username&amp;#34;: username}).Debug(&amp;#34;Login info:&amp;#34;) // 用内置json处理会比较繁琐 const json = `{&amp;#34;name&amp;#34;:{&amp;#34;first&amp;#34;:&amp;#34;Michael&amp;#34;,&amp;#34;last&amp;#34;:&amp;#34;Xu&amp;#34;},&amp;#34;age&amp;#34;:30}` value := gjson.Get(json, &amp;#34;name.last&amp;#34;) TBC..
</content>
    </entry>
    
     <entry>
        <title>SSH使用及扩展</title>
        <url>/blog/ssh/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 经常和Linux服务器打交道就离不开SSH.

常用命令 # 生成key ssh-keygen -t rsa -C &amp;#34;admin[at]xulizhao.com&amp;#34; # 删除无效的公钥,通常由于变更IP造成 ssh-keygen -f &amp;#34;~.ssh/known_hosts&amp;#34; -R 8.8.8.8 # 复制公钥信息到粘贴板 xclip -selection clipboard &amp;lt; ~/.ssh/id_rsa.pub # 如果服务器没有开启SSH服务, 需要先安装 apt install openssh-server # 打印DEBUG信息用以调试 ssh -v ... # 远程运行本地脚本 ssh xulz@moon bash &amp;lt; /path/to/local/script.sh 目录结构 一般ssh相关文件存放在~/.ssh目录, Windows在 %userprofile%/.ssh
 公钥: id_rsa.pub
 私钥: id_rsa
 认证公钥: authorized_keys
 配置文件: config
样例 ServerAliveInterval 60 TCPKeepAlive yes
配置别名,很有用 Host moon HostName moon.xulizhao.com user ubuntu Port 22 IdentityFile ~/.ssh/github.key
 服务端配置: /etc/ssh/sshd.config   无密码登录 # Mac需要先安装 brew install ssh-copy-id # 关键命令 ssh-copy-id username@remotehost # 有时也需要修改权限 chmod 600 ~/.ssh/authorized_keys timed out waiting for input: auto-logout echo $TMOUT vi /etc/profile export TMOUT=600 source /etc/profile 扩展应用 Mosh 更稳定的SSH,适合移动端等网络不可靠环境
sshfs 把远程服务器的路径映射为本地路径
# 安装 sudo apt-get install sshfs # 映射远程文件系统 mkdir ~/remote_code sshfs remote.xulizhao.com:/home/$USER/code ~/remote_code 客户端工具 免费/开源的:
 bitvise ssh client : Windows下最好用的
 Remmina : Linux标配
 PAC Manager
 Dropbear : 轻量级客户端和服务器端
  收费中最好用的:
 SecureCRT&#43;SecureFX </content>
    </entry>
    
     <entry>
        <title>Nginx</title>
        <url>/blog/nginx/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>ops</tag>
        </tags>
        <content type="html">  时常会用到Nginx,一直没有好好的梳理下,以后更新在这里.
基础使用 安装 照官方教程来就好,没啥好说的.
# CentOS中 $releasever替换为主版本号,比如7; $basearch 替换为架构, 用arch命令查看 # Ubuntu中 用以下命令修复错误: GPG error: http://nginx.org/packages/ubuntu xenial Release: The following signatures couldn&amp;#39;t be verified because the public key is not available: NO_PUBKEY $key; # sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys $key# CentOS sudo tee /etc/yum.repos.d/nginx.repo &amp;lt;&amp;lt;-&amp;#39;EOF&amp;#39; [nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 EOF 常用命令:
# 手动启动 /etc/init.d/nginx start # 开机启动服务 chkconfig nginx on # 修改配置文件后,验证语法正确 nginx -t # 重新加载配置让修改立即生效 sudo nginx -s reload 配置  /etc/nginx/nginx.conf 默认常用Document Root : /var/www/, /srv, /usr/share/www  指令: Location  使用正则:必须以下面2种前缀开始  &amp;ldquo;~&amp;rdquo; 大小写匹配 &amp;ldquo;~*&amp;rdquo; 忽略大小写匹配 不做匹配检查使用空block,即 &amp;ldquo;/ /&amp;rdquo;  不使用正则(literal): 逐字匹配,一旦匹配停止继续检索  = 前缀强制URI和Location参数的匹配    正则备忘: ^ 代表以xx开始, $代表以xx结尾
 location = / { # 只匹配 / 查询 } location /test { # 开启目录自动索引 autoindex on; } URL重写 rewrite (PCRE, perl兼容正则)
try_files # 首先找相应的URI # 如果没有,尝试添加/作为目录去匹配 # 如果还是找不到,转发给代理 try_files $uri $uri/ @proxy; 主要变量:  $server_name : 虚拟主机名  本地开发环境 Mac安装 brew install nginx # 以服务的形式随系统启动 brew services start nginx # 主要配置目录 /usr/local/var/www # Doc Root /usr/local/etc/nginx/nginx.conf /usr/local/etc/nginx/servers/ ## 虚拟server  Windows使用服务 借助于 winsw 可以把Nginx安装成服务.
 winsw.exe install/uninstall/start/stop/restart/status
 Troubleshooting Q: 在CentOS安装完,绑定8443端口出错: bind() to 0.0.0.0:8443 failed, Permission denied A: 原因: SELinux 阻止了连接 解决1: semanage port -a -t http_port_t -p tcp 8443 解决2: tsebool httpd_can_network_connect on -P
# 辅助调试命令 sestatus tail -f /var/log/audit/audit.log semanage port -l | grep http_port_t getsebool -a | grep httpd # 如果找不到semanage命令: yum provides /usr/sbin/semanage yum -y install policycoreutils-python 常见配置场景 端口重定向 location /test { # 重写URLs,把请求/testXXXX转换成/XXXX交给AppServer. rewrite ^/test(.*) /$1 break; proxy_pass http://127.0.0.1:8000; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $http_host; } 启用HTTPS # 利用多核 worker_processes auto; http { # 缓存ssl session以提高性能 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; server { listen 443 ssl; ssl_certificate /etc/ssl/xulizhao.com.crt; ssl_certificate_key /etc/ssl/xulizhao.com.key; # 优先采用server端算法 ssl_prefer_server_ciphers on; ... 对某路径启用认证密码保护 # 使用htpasswd工具加密密码 sudo apt-get install apache2-utils sudo htpasswd -c /etc/nginx/.htpasswd admin # 编辑配置,添加 sudo vi /etc/nginx/sites-available/default auth_basic &amp;#34;Private Property&amp;#34;; auth_basic_user_file /etc/nginx/.htpasswd; sudo service nginx reload 修改超时设置 Nginx连接Tomcat的默认超时是1分钟
vi /etc/nginx/conf.d/default.conf # 修改proxy_read_timeout的值 location / { proxy_pass http://127.0.0.1:8080; proxy_read_timeout 180; } 状态页 location /nginx_status { stub_status on; access_log off; # Security allow 192.168.1.100; deny all; } blog 二级域名与子目录映射 location / { rewrite ^/(.*)$ /blog/$1 last; } location ~* ^/blog/.*$ { proxy_pass http://127.0.0.1:8080; }  日志记录响应时间 # 在预制格式combined的最后 # 添加 $request_time 和 $upstream_response_time log_format combined_timed &amp;#39;$remote_addr - $remote_user [$time_local] &amp;#34;$request&amp;#34; &amp;#39; &amp;#39;$status $body_bytes_sent &amp;#34;$http_referer&amp;#34; &amp;#39; &amp;#39;&amp;#34;$http_user_agent&amp;#34; &amp;#34;$http_x_forwarded_for&amp;#34; $request_time $upstream_response_time&amp;#39;; access_log /var/log/nginx/access.log combined_timed; 语言支持 支持php # 添加以下内容 location ~ \.php$ { try_files $uri =404; fastcgi_split_path_info ^(.&#43;\.php)(/.&#43;)$; fastcgi_pass unix:/var/run/php/php7.0-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 资源  location指令官方文档 Nginx 配置 HTTPS 服务器 Open Resty: Nginx增强版, 使用Lua扩展功能.  特点: 可以直接访问 Redis/MemCached; 使用场景: 安全过滤模块, 数据报表; 应用: 淘宝量子统计, 去哪网  OpenResty 最佳实践  </content>
    </entry>
    
     <entry>
        <title>Python配置备忘</title>
        <url>/blog/python/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>python</tag>
        </tags>
        <content type="html"> Python开发环境问题记录.

镜像加速 在国内访问官方的库比较慢，建议使用国内的镜像站。
mkdir ~/.pip vi ~/.pip/pip.conf [global] timeout = 6000 index-url = https://pypi.douban.com/simple/ [install] use-mirrors = true mirrors = https://pypi.douban.com/ 清华镜像 # 临时使用 pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pipenv # 设为默认, 修改 # ~/pip/pip.conf (Linux) # %APPDATA%\pip\pip.ini (Windows 10) # $HOME/Library/Application Support/pip/pip.conf (macOS) [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple Anaconda镜像
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes # 第三方源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ 在Mac上同时安装Python2和Python3 缘起: 在High Sierra 10.12及更高版本,给系统自带的Python2安装一些第三方库(如gevent)会因为系统开启SIP导致失败.
 SIP即系统完整性保护,要查看SIP的状态:&amp;gt; csrutil status
受到SIP保护的路径：/System, /usr, /bin, /sbin
 比较好的方式是使用brew安装最新版的Python2/3
brew install python2 # 有问题重装 # brew reinstall python@2 brew install python3 # 安装之后也相应的安装了对应的pip2, pip3 python2 -V pip2 -V # 建立快捷方式 brew link python3 pip3安装第三方库 # 需要添加到PATH export PATH=/Users/xulz/Library/Python/3.6/bin:$PATH 安装pip3 python3 -m ensurepip 踩过的坑  版本冲突
坑: 先发布了版本1.0, 之后发布了1.0.1, 结果pip install package_name总是得不到更新
原因: pip版本判断时会认为 1.0 &amp;gt; 1.0.1
最佳实践: 命名发布版本时要遵循x.x.x的格式
  参考  清华大学开源软件镜像站 </content>
    </entry>
    
     <entry>
        <title>Jenkins持续集成工具</title>
        <url>/blog/jenkins/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>release</tag>
        </tags>
        <content type="html">  时不时会和持续集成工具Jenkins打交道.
Python API调用 无认证 import requests api_url = &amp;#34;http://jenkins.xulizhao.com/job/test_job/api/json?tree=lastSuccessfulBuild[number]&amp;#34; r = requests.get(api_url) build_number = r.json()[&amp;#39;lastSuccessfulBuild&amp;#39;][&amp;#39;number&amp;#39;] 需要认证 # 先安装依赖库 pip install python-jenkins # 代码示例 import jenkins server = jenkins.Jenkins(&amp;#39;http://jenkins.xulizhao.com&amp;#39;, username=&amp;#39;user&amp;#39;, password=&amp;#39;password&amp;#39;) last_build_number = server.get_job_info(&amp;#39;test_job&amp;#39;)[&amp;#39;lastSuccessfulBuild&amp;#39;][&amp;#39;number&amp;#39;] curl方式 # 检索最近变更记录 curl -u xulz:0f945a8f -s &amp;#34;http://jenkins.xulizhao.com/job/test-job/123/api/xml?wrapper=changes&amp;amp;xpath=//changeSet//comment&amp;#34; 比较遗憾的是Jenkins 的API Token只适用于构建job,其他接口需要用户名/密码登录.
 build_job_url(name, parameters=None, token=None) build_job(name, parameters=None, token=None)  常用设置 Android 构建 android update project -p &amp;lt;project_path&amp;gt; # 更新SDK ./tools/android update sdk --no-ui 修改时区 -Duser.timezone=&amp;ldquo;Asia/Chongqing&amp;rdquo;
修复错误 stderr: Host key verification failed 复制ssh公钥到 .ssh文件夹, 对于Ubuntu在/var/lib/jenkins/.ssh, 可能需要相应的修改文件夹权限.
常用插件  Email Extension Plugin: 邮件增强扩展 Extended Choice Parameter Plug-In: 参数选择扩展  扩展阅读  Jenkins API使用文档 python-jenkins文档  </content>
    </entry>
    
     <entry>
        <title>Golang开发环境</title>
        <url>/blog/go-basic/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 简单记录下Go语言开发环境的搭建和基本用法.

安装 如果要使用系统命令安装:
# Ubuntu apt install golang # Mac brew install golang 如果想安装最新版本的话,可以直接到镜像站下载系统对应版本或者参考Ubuntu安装最新版.
如果在Linux的话解压缩之后需要设置下环境变量:
# vi ~/.zshrc 添加 export GOPATH=$HOME/go export GOBIN=$HOME/go/bin export PATH=$GOPATH/bin:$PATH  注: 在新版命令行安装之后, GOROOT(设置安装路径)和GOPATH都不用设置.
GOPATH 默认位置为 $HOME/go, 该目录用来在标准Go目录之外存放get, build和install等下载的依赖包.
go env 查看当前环境变量
 Go扩展包的下载 如果要编译一个开源项目,在国内的环境下, go get 的方式通常会因为访问 golang.org/x 而失败.
绕过方式为手动下载依赖:
cd $GOPATH/src mkdir -p golang.org/x cd golang.org/x # 通常下边几个库就够用了,具体以错误提示相应的下载  git clone https://github.com/golang/net.git git clone https://github.com/golang/sys.git git clone https://github.com/golang/crypto.git 常用命令 # 运行  go run hello.go # 编译并指定运行环境  GOOS=linux GOARCH=amd64 go build -o hello hello.go # 打包  go install hello.go # 格式化, -w:直接覆盖原代码,不输出到控制台  gofmt -w hello.go ## 查看文档  godoc fmt 依赖管理 可以通过Dep这个工具来管理项目依赖.
# Mac安装 brew install dep # 或者Linux curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh dep init # 会在项目目录创建依赖配置文件Gopkg.toml [[constraint]] branch = &amp;#34;master&amp;#34; name = &amp;#34;golang.org/x/net&amp;#34;</content>
    </entry>
    
     <entry>
        <title>Git备忘</title>
        <url>/blog/git/</url>
        <categories>
          <category>Tech</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 学习资源 如果是新手,强烈推荐阅读Git简明教程, 进阶必读 Pro Git中文版
Git常用命令 
新建项目仓库 # 把当前项目加入git版本管理  git init # 提交文件变更  echo &amp;#34;xulz&amp;#34; &amp;gt;&amp;gt; contributors.txt git add contributors.txt git commit -m &amp;#39;Initial commit with contributors&amp;#39; 推送变更 # 关联远程仓库  git remote add origin git@github.com:xulz/test.git # 推送本地变更到远程仓库  git push -u origin master # 以上简写为$ git push  git push -u origin --all # pushes up the repo and its refs for the first time  git push -u origin --tags # pushes up any tags# push遇到错误 ! [rejected] master -&amp;gt; master (non-fast-forward) # 风险: 可能会造成remote丢失提交 git push --force --set-upstream origin master 基本配置 # 列出当前项目主要配置  git config --list # 编辑当前项目配置文件  vi .git/config # 修改全局配置  vi ~/.gitconfig  Branch 分支 分支的习惯用法:
origin/master 应该始终保持生产环境可用的状态,即可部署.
origin/develop 代表最新的code, 是nightly测试的重点. 如果稳定到可以release,需要为新发布创建新tag,并merge回 master.
常用命令 # 同步远程分支  git fetch # 列出所有分支  git branch -a # 切换分支  git checkout new_branch # push到远程  git push --set-upstream origin new_branch Fork同步上游仓库 # 查看当前远程仓库 git remote -v git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git # 获取更新 git fetch upstream git checkout master git merge upstream/master Tag 标签 推荐为每次软件发布创建标签.
# 为当前版本创建tag git tag v1.0.0 ## Git工作流
 Git 工作流程 </content>
    </entry>
    
     <entry>
        <title>新博客</title>
        <url>/play/blog-ghost/</url>
        <categories>
          <category>Play</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 本博客基于Ghost开源博客平台搭建,系统基于Node.js开发.
主要看中她的简洁和轻量,编辑器使用Markdown,资源占用比较低(性能比WordPress好很多).

说下安装完需要定制的部分,供参考:
代码高亮 由于经常使用代码片段,用PrismJS添加了代码高亮,主要使用了Code injection功能,可参考网上这篇文章.
开启评论 系统没有评论功能,集成了第三方的Disqus,整合方式参考这里.
使用HTTPS 最近关联域名后启用了HTTPS.
ghost config url https://xulizhao.com ghost setup nginx ssl # 之后需要更新Ngxin的配置并reload  # 使用Let&amp;#39;s Encrypt的免费证书,这个自动获取证书acme.sh脚本太好用了 文章目录 折腾了多半天,添加了文章目录(TOC).
主要使用了jQuery-TOC插件,并仿照floating-header做了一个新图层
cd &amp;lt;GHOST_DIR&amp;gt;/content/themes/casper/assets/js wget https://github.com/idiotWu/jQuery-TOC/raw/master/dist/jquery.toc.min.js cd ../.. // 修改 default.hbs,在fitvids以下添加一行引入  &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;{{asset &amp;#34;js/jquery.fitvids.js&amp;#34;}}&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;{{asset &amp;#34;js/jquery.toc.min.js&amp;#34;}}&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; // vi assets/css/screen.css .sidebar { visibility: visible; position: fixed; right: 0; top: 300px; z-index: 1000; display: flex; align-items: center; width: 300px; border-bottom: rgba(0,0,0,0.06) 1px solid; background: rgba(255,255,255,0.95); } // 手机不显示文章目录 @media screen and (max-width: 600px) { #toc { visibility: hidden; } } // vi post.hbs &amp;lt;div id=&amp;#34;toc&amp;#34; class=&amp;#34;sidebar&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; // 在结束标记前添加{{/post}} // 在脚本部分的ready部分添加 $(document).ready(function () {  $(&amp;#39;#toc&amp;#39;).initTOC({ selector: &amp;#39;h1, h2, h3, h4&amp;#39;, scope: &amp;#39;.post-full-content&amp;#39;, overwrite: false, prefix: &amp;#39;toc&amp;#39; });  PS:
从博客开始流行时的第三方博客平台到后来自己搭建Wordpress,最近几年又流行的基于github静态建站都有所尝试, 可是似乎脱离了建站的初心: 记录成长历程,练习表达.
希望在这坚持下去.
</content>
    </entry>
    
     <entry>
        <title>Flask开发笔记</title>
        <url>/blog/flask/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>web</tag><tag>python</tag>
        </tags>
        <content type="html">  开发基础 创建 Flask Starter Project pip3 install cookiecutter cookiecutter https://github.com/realpython/cookiecutter-flask-skeleton.git 具体使用参考 项目地址
常用第三方 # requirements.txt Flask Flask-Bcrypt Flask-Login Flask-WTF Flask-Bootstrap Flask-DebugToolbar Flask-Testing Flask-Migrate Flask-SQLAlchemy celery 例子 # -- coding: utf-8 -- from flask import Flask, request, make_response, redirect, abort app = Flask(__name__) # route建立请求路径和函数之间的映射 # 等同于 app.add_url_rule() # app.url_map 存放所以映射 @app.route(&amp;#34;/&amp;#34;) # 视图函数 def index(): return &amp;#34;&amp;lt;h1&amp;gt;Hello World!&amp;lt;/h1&amp;gt;&amp;#34; # route支持类型: int, fload, path, 比如 &amp;lt;int:id&amp;gt; @app.route(&amp;#34;/user/&amp;lt;name&amp;gt;&amp;#34;) def greeting(name): return &amp;#34;Hello, %s&amp;#34; % name @app.route(&amp;#34;ua&amp;#34;) def user_agent(): ua = request.headers.get(&amp;#34;User-Agent&amp;#34;) return &amp;#34;Your UA:%s&amp;#34; %ua @app.route(&amp;#34;/error/400&amp;#34;) def error400(): return &amp;#34;&amp;lt;h1&amp;gt;Bad Request&amp;lt;/h1&amp;gt;&amp;#34;, 400 # 第三个参数可以传入其他headers @app.route(&amp;#34;/cookie&amp;#34;) def respone_with_cookie(): response = make_response(&amp;#34;Response with Cookie&amp;#34;) response.set_cookie(&amp;#39;user&amp;#39;, &amp;#39;xulz&amp;#39;) return response # 302 Response @app.route(&amp;#34;/redirect&amp;#34;) def redirect_test(): return redirect(&amp;#34;http://127.0.0.1:5000&amp;#34;) # abort 会把控制权交给web server然后抛出异常 @app.route(&amp;#34;/abort&amp;#34;) def abort_test(): abort(404) if __name__ == &amp;#34;__main__&amp;#34;: # 激活 debugger和reloader app.run(debug=True) Context    变量名 Context 描述     current_app 应用上下文 当前活跃的应用实例   g 应用上下文 用于一个request的临时存储,每次会重置   request 请求上下文 request对象   session 请求上下文 回话,requests间可访问    request Hooks  before_first_request before_request after_request: 没有发生异常时,注册 teardown_request 每次request之后注册,即使发生异常   一般把hook和functions view的共享数据存放在g应用上下文
 Flask 扩展 偶然发现一个增强版Flask项目,提供了更好的安全和自动CRUD操作等许多常用特性(有点学习Django的意思), 强烈推荐.
Flask App Builder
技巧 禁止控制台输出 log = logging.getLogger(&amp;#39;werkzeug&amp;#39;) log.setLevel(logging.ERROR) 增加响应延迟 def get_fake_latency(): return random.uniform(0.1, 0.2) @app.after_request def apply_latency(response): time.sleep(get_fake_latency()) return response 部署 生产环境  不要使用｀app.run()｀方式运行 使用gunicorn  python实现，简单易用 运行: gunicorn app:app  使用uWsgi  C实现，CPU占用低 通常与Nginx反向代理一起使用   链接  Patterns for Flask 官方进阶 Explore Flask 教程 Flask Web Development 作者博客 使用Docker部署Flask应用  </content>
    </entry>
    
     <entry>
        <title>ZooKeeper</title>
        <url>/blog/zookeeper/</url>
        <categories>
          <category>tech</category>
        </categories>
        <tags>
          <tag>distributed</tag>
        </tags>
        <content type="html">  作用及原理 作用: 分布式协调, 提供操作API
 配置管理 集群管理:  群主选举 资源定位  同步状态 统一命名服务  使用案例:
 HBase Hadoop Kafka  选举算法 一个Leader,其他节点为Follower
Leader选举算法 (分布式选举算法使用ZAB,是Paxos的变种)
一致性保证:
 数据变更先写磁盘再读入内存 读写原子 同步消息原子性 事务日志和快照是持久化存储.  写请求连接Leader, 读请求连接任意节点读取本地的复制.
配置 设置根目录： ZOOKEEPER_HOME
日志文件： zookeeper.out
集群推荐不少于3台，推荐奇数个节点,只要超过半数的节点OK(有效参与选举的节点数过半), ZooKeeper就能正常服务. 最好分布在不同的物理机上。
# server.N, 在zoo.cfg指定的dataDir目录下建立以服务器节点对应的myid文件,并更新内容为N  initLimit=5 syncLimit=2 server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888# Ubuntu 随系统启动 apt-get install zookeeperd 性能 性能: 在读大于写时性能更好(读写10:1)
注：来自腾讯广告团队分享
问题：如果读写操作频繁，则Zookeeper server很容易不堪重负。
workaround：用C&#43;&#43;写了一个proxy，定期load Zookeeper数据，代替Zookeeper处理读操作，把写操作proxy给后面的Zookeeper。
替代方案：etcd </content>
    </entry>
    
     <entry>
        <title>reborn</title>
        <url>/read/reborn/</url>
        <categories>
          <category>essay</category>
        </categories>
        <tags>
          <tag>read</tag>
        </tags>
        <content type="html"> &amp;ldquo;书籍是人类的好朋友&amp;rdquo;,这是句真理. 在如今信息爆炸,碎片充斥的年代,一年读十几/几十本书已成奢谈.
在手机上碎片阅读李笑来老师的书可追溯到几年前的&amp;lt;把时间当作朋友&amp;gt;,去年是&amp;lt;成长-YC创业课读书笔记&amp;gt;, 最近还在读的是&amp;lt;新生-七年就是一辈子&amp;gt;.
笑来老师的书部部精品,还有正版免费可读,你还奢求什么.

新生里的话题有的在成长已经提过,最近读到人成长和计算机升级的类比,觉得很是经典.
计算机硬件的升级对应人身体的锻炼,保持健康更新; 而更频繁的软件升级则对应人脑的学习成长提高. 如果人拒绝学习提高,和老古董电脑就没啥区别了,想来也是每个人不乐意看到的.
近十几年的计算机行业高速发展,极大的改变了人的生活方式,带来了社会的巨大进步. 这个行业汇聚着许多顶级聪明的人, 有优秀的产品可用, 开源的代码可学习.
没有理由不更新自己,去关注自己实质的成长. 而不是活在信息过载里,碎片虚无里.
工作的有趣有意义,自身的提升和价值的提高, 进一步改善生活, 应该生活在一个正循环里.
</content>
    </entry>
    
     <entry>
        <title>Go In Action</title>
        <url>/play/blog-hugo/</url>
        <categories>
          <category>play</category>
        </categories>
        <tags>
          <tag>blog</tag>
        </tags>
        <content type="html"> 更新下关于静态博客Hugo的旧文, 本博客现在就是使用Hugo生成.
最早知道Hugo是在听完&amp;rsquo;内核恐慌&amp;rsquo;播客的一期节目,其实之前已经通过Github Pages试用过几个静态博客系统.
最近几个月一直强迫自己用Github和Markdown做学习记录.
BTW,喜欢折腾的同学, 可以通过StaticGen这个汇总站点进一步了解更多静态博客.
</content>
    </entry>
    
     <entry>
        <title>Posts</title>
        <url>/post/</url>
        <categories>
          
        </categories>
        <tags>
          
        </tags>
        <content type="html"> </content>
    </entry>
    
</search>